# ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´ä¼˜åŒ–æ–¹æ¡ˆ
## åŸºäºCPUæ ¸å¿ƒæ•°å’Œå®æ—¶è´Ÿè½½çš„æ™ºèƒ½èµ„æºç®¡ç†

### ğŸ“Š ç°æœ‰CPUè‡ªé€‚åº”æœºåˆ¶åˆ†æ

#### å½“å‰å®ç°çŠ¶å†µ
```python
# âœ… ç°æœ‰çš„åŸºç¡€CPUè‡ªé€‚åº”ï¼ˆHealthDataOptimizer V4.0ï¼‰
class HealthDataOptimizer:
    def __init__(self):
        self.cpu_cores = psutil.cpu_count(logical=True)
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        
        # é™æ€å…¬å¼è®¡ç®—
        self.batch_size = max(50, min(500, self.cpu_cores * 25))
        max_workers = max(4, min(32, int(self.cpu_cores * 2.5)))
```

#### å‘ç°çš„å±€é™æ€§

1. **é™æ€é…ç½®é—®é¢˜**
   - åªåœ¨åˆå§‹åŒ–æ—¶è®¡ç®—ä¸€æ¬¡
   - æ— æ³•å“åº”å®æ—¶è´Ÿè½½å˜åŒ–
   - å›ºå®šçš„CPUå€æ•°ç³»æ•°ï¼ˆ25å€ã€2.5å€ï¼‰

2. **ç¼ºä¹æ™ºèƒ½è°ƒæ•´**
   - ä¸è€ƒè™‘å†…å­˜ä½¿ç”¨ç‡
   - ä¸ç›‘æ§é˜Ÿåˆ—æ·±åº¦
   - ä¸å“åº”ç³»ç»Ÿè´Ÿè½½å˜åŒ–

3. **èµ„æºåˆ©ç”¨ä¸å……åˆ†**
   - æœªè€ƒè™‘ä¸åŒç±»å‹ä»»åŠ¡çš„èµ„æºéœ€æ±‚
   - ç¼ºä¹åŠ¨æ€æ‰©ç¼©å®¹æœºåˆ¶

### ğŸš€ æ™ºèƒ½åŠ¨æ€èµ„æºè°ƒæ•´æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šå®æ—¶æ€§èƒ½ç›‘æ§å’ŒåŠ¨æ€è°ƒæ•´

```python
import psutil
import threading
import time
import queue
from dataclasses import dataclass
from typing import Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor
import asyncio

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    cpu_usage: float          # CPUä½¿ç”¨ç‡ %
    memory_usage: float       # å†…å­˜ä½¿ç”¨ç‡ %
    cpu_cores: int           # CPUæ ¸å¿ƒæ•°
    available_memory: float   # å¯ç”¨å†…å­˜ GB
    queue_depth: int         # é˜Ÿåˆ—æ·±åº¦
    processing_rate: float   # å¤„ç†é€Ÿç‡ records/sec
    avg_response_time: float # å¹³å‡å“åº”æ—¶é—´ ms
    error_rate: float        # é”™è¯¯ç‡ %

@dataclass 
class ResourceConfig:
    """èµ„æºé…ç½®å‚æ•°"""
    batch_size: int          # æ‰¹å¤„ç†å¤§å°
    worker_count: int        # å·¥ä½œçº¿ç¨‹æ•°
    queue_size: int          # é˜Ÿåˆ—å¤§å°
    timeout: float           # è¶…æ—¶æ—¶é—´
    
class SmartResourceManager:
    """æ™ºèƒ½èµ„æºç®¡ç†å™¨ - åŸºäºå®æ—¶è´Ÿè½½åŠ¨æ€è°ƒæ•´"""
    
    def __init__(self):
        # åŸºç¡€ç³»ç»Ÿä¿¡æ¯
        self.cpu_cores = psutil.cpu_count(logical=True)
        self.cpu_cores_physical = psutil.cpu_count(logical=False) 
        self.memory_total = psutil.virtual_memory().total / (1024**3)
        
        # åŠ¨æ€é…ç½®å‚æ•°
        self.current_config = self._calculate_initial_config()
        self.min_config = self._get_min_config()
        self.max_config = self._get_max_config()
        
        # æ€§èƒ½ç›‘æ§
        self.metrics_history = []
        self.monitoring_window = 60  # ç›‘æ§çª—å£60ç§’
        self.adjustment_interval = 10  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
        self.last_adjustment = time.time()
        
        # è‡ªé€‚åº”å‚æ•°
        self.cpu_target_usage = 70.0  # ç›®æ ‡CPUä½¿ç”¨ç‡70%
        self.memory_target_usage = 80.0  # ç›®æ ‡å†…å­˜ä½¿ç”¨ç‡80%
        self.queue_depth_threshold = 0.8  # é˜Ÿåˆ—æ·±åº¦é˜ˆå€¼80%
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        logger.info(f"ğŸ§  SmartResourceManager åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   CPU: {self.cpu_cores}é€»è¾‘æ ¸å¿ƒ/{self.cpu_cores_physical}ç‰©ç†æ ¸å¿ƒ")
        logger.info(f"   å†…å­˜: {self.memory_total:.1f}GB")
        logger.info(f"   åˆå§‹é…ç½®: {self.current_config}")
    
    def _calculate_initial_config(self) -> ResourceConfig:
        """è®¡ç®—åˆå§‹é…ç½® - åŸºäºç³»ç»Ÿç¡¬ä»¶"""
        # ğŸš€ æ™ºèƒ½CPUç³»æ•°è®¡ç®—
        if self.cpu_cores <= 4:
            # ä½ç«¯ç³»ç»Ÿï¼šä¿å®ˆé…ç½®
            batch_multiplier = 20
            worker_multiplier = 2.0
        elif self.cpu_cores <= 8:
            # ä¸­ç«¯ç³»ç»Ÿï¼šå‡è¡¡é…ç½®  
            batch_multiplier = 25
            worker_multiplier = 2.5
        elif self.cpu_cores <= 16:
            # é«˜ç«¯ç³»ç»Ÿï¼šæ¿€è¿›é…ç½®
            batch_multiplier = 30
            worker_multiplier = 3.0
        else:
            # æœåŠ¡å™¨çº§åˆ«ï¼šæœ€å¤§æ€§èƒ½
            batch_multiplier = 35
            worker_multiplier = 3.5
            
        # ğŸ¯ å†…å­˜å½±å“å› å­
        memory_factor = min(2.0, max(0.5, self.memory_total / 8.0))  # 8GBä¸ºåŸºå‡†
        
        batch_size = int(self.cpu_cores * batch_multiplier * memory_factor)
        batch_size = max(50, min(1000, batch_size))
        
        worker_count = int(self.cpu_cores * worker_multiplier)
        worker_count = max(4, min(64, worker_count))
        
        queue_size = batch_size * 10  # é˜Ÿåˆ—å¤§å°ä¸ºæ‰¹æ¬¡å¤§å°çš„10å€
        
        return ResourceConfig(
            batch_size=batch_size,
            worker_count=worker_count, 
            queue_size=queue_size,
            timeout=2.0
        )
    
    def _get_min_config(self) -> ResourceConfig:
        """æœ€å°èµ„æºé…ç½®"""
        return ResourceConfig(
            batch_size=max(25, self.cpu_cores * 10),
            worker_count=max(2, self.cpu_cores // 2),
            queue_size=500,
            timeout=5.0
        )
    
    def _get_max_config(self) -> ResourceConfig:
        """æœ€å¤§èµ„æºé…ç½®"""
        return ResourceConfig(
            batch_size=min(2000, self.cpu_cores * 50),
            worker_count=min(128, self.cpu_cores * 4),
            queue_size=20000,
            timeout=1.0
        )
    
    def collect_metrics(self, queue_depth: int, processing_rate: float, 
                       avg_response_time: float, error_rate: float) -> SystemMetrics:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        
        metrics = SystemMetrics(
            cpu_usage=cpu_percent,
            memory_usage=memory.percent,
            cpu_cores=self.cpu_cores,
            available_memory=memory.available / (1024**3),
            queue_depth=queue_depth,
            processing_rate=processing_rate,
            avg_response_time=avg_response_time,
            error_rate=error_rate
        )
        
        # ä¿æŒæœ€è¿‘60ç§’çš„æŒ‡æ ‡
        now = time.time()
        self.metrics_history.append((now, metrics))
        self.metrics_history = [
            (t, m) for t, m in self.metrics_history 
            if now - t <= self.monitoring_window
        ]
        
        return metrics
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯ - å®šæœŸæ£€æŸ¥å¹¶è°ƒæ•´èµ„æºé…ç½®"""
        while self.monitoring_active:
            try:
                time.sleep(self.adjustment_interval)
                
                if len(self.metrics_history) < 3:
                    continue  # æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è°ƒæ•´
                    
                should_adjust, new_config = self._should_adjust_resources()
                
                if should_adjust:
                    self._apply_config_change(new_config)
                    
            except Exception as e:
                logger.error(f"èµ„æºç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
    
    def _should_adjust_resources(self) -> Tuple[bool, ResourceConfig]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´èµ„æºé…ç½®"""
        if not self.metrics_history:
            return False, self.current_config
            
        # è®¡ç®—æœ€è¿‘æŒ‡æ ‡çš„å¹³å‡å€¼
        recent_metrics = [m for _, m in self.metrics_history[-6:]]  # æœ€è¿‘6æ¬¡
        
        avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        avg_queue_ratio = sum(m.queue_depth / self.current_config.queue_size for m in recent_metrics) / len(recent_metrics)
        avg_processing_rate = sum(m.processing_rate for m in recent_metrics) / len(recent_metrics)
        
        logger.debug(f"ğŸ“Š ç³»ç»ŸæŒ‡æ ‡ - CPU: {avg_cpu:.1f}%, å†…å­˜: {avg_memory:.1f}%, é˜Ÿåˆ—: {avg_queue_ratio:.1f}, å¤„ç†ç‡: {avg_processing_rate:.1f}/s")
        
        # ğŸš€ åŠ¨æ€è°ƒæ•´é€»è¾‘
        new_config = ResourceConfig(
            batch_size=self.current_config.batch_size,
            worker_count=self.current_config.worker_count,
            queue_size=self.current_config.queue_size,
            timeout=self.current_config.timeout
        )
        
        config_changed = False
        
        # 1. CPUä½¿ç”¨ç‡è°ƒæ•´
        if avg_cpu < 50.0 and avg_queue_ratio > 0.7:
            # CPUç©ºé—²ä½†é˜Ÿåˆ—ç§¯å‹ -> å¢åŠ å·¥ä½œçº¿ç¨‹å’Œæ‰¹æ¬¡å¤§å°
            new_config.worker_count = min(
                self.max_config.worker_count,
                int(self.current_config.worker_count * 1.3)
            )
            new_config.batch_size = min(
                self.max_config.batch_size,
                int(self.current_config.batch_size * 1.2)
            )
            config_changed = True
            logger.info(f"ğŸš€ æ£€æµ‹åˆ°CPUç©ºé—²ä¸”é˜Ÿåˆ—ç§¯å‹ï¼Œå¢åŠ å¤„ç†èƒ½åŠ›")
            
        elif avg_cpu > 85.0:
            # CPUè¿‡è½½ -> å‡å°‘å·¥ä½œçº¿ç¨‹
            new_config.worker_count = max(
                self.min_config.worker_count,
                int(self.current_config.worker_count * 0.8)
            )
            config_changed = True
            logger.info(f"âš ï¸ æ£€æµ‹åˆ°CPUè¿‡è½½ï¼Œå‡å°‘å·¥ä½œçº¿ç¨‹")
            
        # 2. å†…å­˜ä½¿ç”¨ç‡è°ƒæ•´  
        if avg_memory > 90.0:
            # å†…å­˜ç´§å¼  -> å‡å°‘æ‰¹æ¬¡å¤§å°å’Œé˜Ÿåˆ—å¤§å°
            new_config.batch_size = max(
                self.min_config.batch_size,
                int(self.current_config.batch_size * 0.7)
            )
            new_config.queue_size = max(
                self.min_config.queue_size,
                int(self.current_config.queue_size * 0.8)
            )
            config_changed = True
            logger.info(f"âš ï¸ æ£€æµ‹åˆ°å†…å­˜ç´§å¼ ï¼Œå‡å°‘æ‰¹æ¬¡å’Œé˜Ÿåˆ—å¤§å°")
            
        # 3. é˜Ÿåˆ—æ·±åº¦è°ƒæ•´
        if avg_queue_ratio > 0.9:
            # é˜Ÿåˆ—æ¥è¿‘æ»¡è½½ -> æ‰©å¤§é˜Ÿåˆ—å¹¶å¢åŠ å¤„ç†èƒ½åŠ›
            new_config.queue_size = min(
                self.max_config.queue_size,
                int(self.current_config.queue_size * 1.5)
            )
            if avg_cpu < 70.0:  # åªåœ¨CPUä¸ç¹å¿™æ—¶å¢åŠ å·¥ä½œçº¿ç¨‹
                new_config.worker_count = min(
                    self.max_config.worker_count,
                    int(self.current_config.worker_count * 1.2)
                )
            config_changed = True
            logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ°é˜Ÿåˆ—æ¥è¿‘æ»¡è½½ï¼Œæ‰©å±•å¤„ç†èƒ½åŠ›")
            
        # 4. å¤„ç†æ•ˆç‡ä¼˜åŒ–
        if avg_processing_rate < 10.0 and avg_cpu < 60.0:
            # å¤„ç†ç‡ä½ä¸”CPUç©ºé—² -> è°ƒæ•´è¶…æ—¶å’Œæ‰¹æ¬¡ç­–ç•¥
            new_config.timeout = max(0.5, self.current_config.timeout * 0.8)
            new_config.batch_size = min(
                self.max_config.batch_size, 
                int(self.current_config.batch_size * 1.1)
            )
            config_changed = True
            logger.info(f"âš¡ æ£€æµ‹åˆ°å¤„ç†æ•ˆç‡ä½ï¼Œä¼˜åŒ–æ‰¹æ¬¡ç­–ç•¥")
        
        return config_changed, new_config
    
    def _apply_config_change(self, new_config: ResourceConfig):
        """åº”ç”¨é…ç½®æ›´æ”¹"""
        old_config = self.current_config
        self.current_config = new_config
        self.last_adjustment = time.time()
        
        logger.info(f"ğŸ”§ èµ„æºé…ç½®å·²è°ƒæ•´:")
        logger.info(f"   æ‰¹æ¬¡å¤§å°: {old_config.batch_size} â†’ {new_config.batch_size}")
        logger.info(f"   å·¥ä½œçº¿ç¨‹: {old_config.worker_count} â†’ {new_config.worker_count}")  
        logger.info(f"   é˜Ÿåˆ—å¤§å°: {old_config.queue_size} â†’ {new_config.queue_size}")
        logger.info(f"   è¶…æ—¶æ—¶é—´: {old_config.timeout} â†’ {new_config.timeout}")
        
        # è§¦å‘é…ç½®æ›´æ–°å›è°ƒï¼ˆç”±ä½¿ç”¨è€…å®ç°ï¼‰
        self._notify_config_change(old_config, new_config)
        
    def _notify_config_change(self, old_config: ResourceConfig, new_config: ResourceConfig):
        """é€šçŸ¥é…ç½®å˜æ›´ - ç”±å­ç±»æˆ–å›è°ƒå®ç°"""
        pass
    
    def get_current_config(self) -> ResourceConfig:
        """è·å–å½“å‰èµ„æºé…ç½®"""
        return self.current_config
        
    def get_metrics_summary(self) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡æ‘˜è¦"""
        if not self.metrics_history:
            return {}
            
        recent_metrics = [m for _, m in self.metrics_history[-10:]]
        
        return {
            'cpu_usage': {
                'current': recent_metrics[-1].cpu_usage,
                'avg_10min': sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics),
                'max_10min': max(m.cpu_usage for m in recent_metrics)
            },
            'memory_usage': {
                'current': recent_metrics[-1].memory_usage,
                'avg_10min': sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
            },
            'processing_rate': {
                'current': recent_metrics[-1].processing_rate,
                'avg_10min': sum(m.processing_rate for m in recent_metrics) / len(recent_metrics)
            },
            'queue_utilization': recent_metrics[-1].queue_depth / self.current_config.queue_size,
            'config': {
                'batch_size': self.current_config.batch_size,
                'worker_count': self.current_config.worker_count,
                'queue_size': self.current_config.queue_size
            }
        }
        
    def shutdown(self):
        """å…³é—­èµ„æºç®¡ç†å™¨"""
        self.monitoring_active = False
        if self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=5.0)
```

#### æ–¹æ¡ˆ2ï¼šé›†æˆåˆ°ç°æœ‰å¥åº·æ•°æ®å¤„ç†å™¨

```python
class SmartHealthDataOptimizer(HealthDataOptimizer):
    """é›†æˆæ™ºèƒ½èµ„æºç®¡ç†çš„å¥åº·æ•°æ®ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–èµ„æºç®¡ç†å™¨
        self.resource_manager = SmartResourceManager()
        
        # ä½¿ç”¨åŠ¨æ€é…ç½®åˆå§‹åŒ–
        initial_config = self.resource_manager.get_current_config()
        
        # åŸæœ‰åˆå§‹åŒ–é€»è¾‘
        self.cpu_cores = self.resource_manager.cpu_cores
        self.memory_gb = self.resource_manager.memory_total
        self.batch_size = initial_config.batch_size
        self.batch_timeout = initial_config.timeout
        
        # åŠ¨æ€çº¿ç¨‹æ±  - æ”¯æŒé‡æ–°é…ç½®
        self.executor = DynamicThreadPoolExecutor(
            max_workers=initial_config.worker_count,
            resource_manager=self.resource_manager
        )
        
        self.batch_queue = queue.Queue(maxsize=initial_config.queue_size)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_tracker = PerformanceTracker()
        
        # è®¾ç½®é…ç½®å˜æ›´å›è°ƒ
        self.resource_manager._notify_config_change = self._on_config_change
        
        logger.info(f"ğŸ§  SmartHealthDataOptimizer åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   åŠ¨æ€æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        logger.info(f"   åŠ¨æ€å·¥ä½œçº¿ç¨‹: {initial_config.worker_count}")
        
    def _on_config_change(self, old_config: ResourceConfig, new_config: ResourceConfig):
        """å“åº”é…ç½®å˜æ›´"""
        # 1. è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if new_config.batch_size != old_config.batch_size:
            self.batch_size = new_config.batch_size
            
        # 2. è°ƒæ•´è¶…æ—¶æ—¶é—´
        if new_config.timeout != old_config.timeout:
            self.batch_timeout = new_config.timeout
            
        # 3. è°ƒæ•´é˜Ÿåˆ—å¤§å°ï¼ˆéœ€è¦é‡å»ºé˜Ÿåˆ—ï¼‰
        if new_config.queue_size != old_config.queue_size:
            self._resize_queue(new_config.queue_size)
            
        # 4. è°ƒæ•´çº¿ç¨‹æ± ï¼ˆç”±DynamicThreadPoolExecutorå¤„ç†ï¼‰
        self.executor.adjust_workers(new_config.worker_count)
    
    def _batch_processor(self):
        """å¢å¼ºçš„æ‰¹å¤„ç†å™¨ - åŒ…å«æ€§èƒ½ç›‘æ§"""
        batch_data = []
        last_flush = time.time()
        last_metrics_update = time.time()
        
        while self.running:
            try:
                # ä½¿ç”¨åŠ¨æ€è¶…æ—¶æ—¶é—´
                current_config = self.resource_manager.get_current_config()
                timeout = max(0.1, current_config.timeout - (time.time() - last_flush))
                
                item = self.batch_queue.get(timeout=timeout)
                batch_data.append(item)
                
                # æ€§èƒ½æŒ‡æ ‡æ”¶é›†
                processing_start = time.time()
                
                # æ‰¹æ¬¡å¤„ç†é€»è¾‘
                if (len(batch_data) >= current_config.batch_size or 
                    (time.time() - last_flush) >= current_config.timeout):
                    
                    if batch_data:
                        self._flush_batch(batch_data)
                        
                        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                        processing_time = time.time() - processing_start
                        self.performance_tracker.record_batch(
                            batch_size=len(batch_data),
                            processing_time=processing_time
                        )
                        
                        batch_data = []
                        last_flush = time.time()
                
                # å®šæœŸæ›´æ–°ç³»ç»ŸæŒ‡æ ‡
                if time.time() - last_metrics_update > 5.0:
                    self._update_system_metrics()
                    last_metrics_update = time.time()
                    
            except queue.Empty:
                if batch_data and (time.time() - last_flush) >= current_config.timeout:
                    self._flush_batch(batch_data)
                    batch_data = []
                    last_flush = time.time()
            except Exception as e:
                logger.error(f"åŠ¨æ€æ‰¹å¤„ç†å™¨å¼‚å¸¸: {e}")
    
    def _update_system_metrics(self):
        """æ›´æ–°ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        try:
            queue_depth = self.batch_queue.qsize()
            processing_rate = self.performance_tracker.get_current_rate()
            avg_response_time = self.performance_tracker.get_avg_response_time()
            error_rate = self.performance_tracker.get_error_rate()
            
            self.resource_manager.collect_metrics(
                queue_depth=queue_depth,
                processing_rate=processing_rate,
                avg_response_time=avg_response_time,
                error_rate=error_rate
            )
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")

class DynamicThreadPoolExecutor:
    """åŠ¨æ€çº¿ç¨‹æ± æ‰§è¡Œå™¨ - æ”¯æŒè¿è¡Œæ—¶è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°"""
    
    def __init__(self, max_workers: int, resource_manager: SmartResourceManager):
        self.current_workers = max_workers
        self.resource_manager = resource_manager
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self._lock = threading.Lock()
        
    def adjust_workers(self, new_worker_count: int):
        """åŠ¨æ€è°ƒæ•´å·¥ä½œçº¿ç¨‹æ•°"""
        with self._lock:
            if new_worker_count == self.current_workers:
                return
                
            old_executor = self.executor
            
            # åˆ›å»ºæ–°çš„çº¿ç¨‹æ± 
            self.executor = ThreadPoolExecutor(max_workers=new_worker_count)
            self.current_workers = new_worker_count
            
            # ä¼˜é›…å…³é—­æ—§çº¿ç¨‹æ± 
            threading.Thread(
                target=self._graceful_shutdown,
                args=(old_executor,),
                daemon=True
            ).start()
            
            logger.info(f"ğŸ”„ çº¿ç¨‹æ± å·²è°ƒæ•´è‡³ {new_worker_count} ä¸ªå·¥ä½œçº¿ç¨‹")
    
    def _graceful_shutdown(self, old_executor):
        """ä¼˜é›…å…³é—­æ—§çº¿ç¨‹æ± """
        try:
            old_executor.shutdown(wait=True, timeout=30.0)
        except Exception as e:
            logger.error(f"å…³é—­æ—§çº¿ç¨‹æ± å¼‚å¸¸: {e}")
    
    def submit(self, *args, **kwargs):
        """æäº¤ä»»åŠ¡åˆ°å½“å‰çº¿ç¨‹æ± """
        return self.executor.submit(*args, **kwargs)
        
    def shutdown(self, wait=True):
        """å…³é—­çº¿ç¨‹æ± """
        return self.executor.shutdown(wait=wait)

class PerformanceTracker:
    """æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.batch_records = []
        self.error_count = 0
        self.total_count = 0
        self._lock = threading.Lock()
        
    def record_batch(self, batch_size: int, processing_time: float):
        """è®°å½•æ‰¹æ¬¡å¤„ç†æ€§èƒ½"""
        with self._lock:
            record = {
                'timestamp': time.time(),
                'batch_size': batch_size,
                'processing_time': processing_time,
                'rate': batch_size / processing_time if processing_time > 0 else 0
            }
            
            self.batch_records.append(record)
            self.total_count += batch_size
            
            # ä¿æŒçª—å£å¤§å°
            if len(self.batch_records) > self.window_size:
                self.batch_records = self.batch_records[-self.window_size:]
    
    def record_error(self):
        """è®°å½•é”™è¯¯"""
        with self._lock:
            self.error_count += 1
    
    def get_current_rate(self) -> float:
        """è·å–å½“å‰å¤„ç†é€Ÿç‡"""
        with self._lock:
            if not self.batch_records:
                return 0.0
                
            recent_records = self.batch_records[-10:]
            total_processed = sum(r['batch_size'] for r in recent_records)
            total_time = sum(r['processing_time'] for r in recent_records)
            
            return total_processed / total_time if total_time > 0 else 0.0
    
    def get_avg_response_time(self) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        with self._lock:
            if not self.batch_records:
                return 0.0
                
            recent_records = self.batch_records[-20:]
            avg_time = sum(r['processing_time'] for r in recent_records) / len(recent_records)
            
            return avg_time * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    
    def get_error_rate(self) -> float:
        """è·å–é”™è¯¯ç‡"""
        with self._lock:
            if self.total_count == 0:
                return 0.0
            return (self.error_count / self.total_count) * 100
```

### ğŸ“Š åŠ¨æ€è°ƒæ•´ç­–ç•¥è¯¦è§£

#### 1. **CPUä½¿ç”¨ç‡è‡ªé€‚åº”**
```python
# ğŸ¯ æ™ºèƒ½CPUè°ƒæ•´ç­–ç•¥
if avg_cpu < 50% and queue_ratio > 70%:
    # CPUç©ºé—²ä½†é˜Ÿåˆ—ç§¯å‹ â†’ å¢åŠ å¤„ç†èƒ½åŠ›
    workers *= 1.3
    batch_size *= 1.2
    
elif avg_cpu > 85%:
    # CPUè¿‡è½½ â†’ å‡å°‘å·¥ä½œçº¿ç¨‹é˜²æ­¢ç³»ç»Ÿå´©æºƒ
    workers *= 0.8
```

#### 2. **å†…å­˜å‹åŠ›å“åº”**
```python
# âš ï¸ å†…å­˜å‹åŠ›è‡ªåŠ¨ç¼“è§£
if memory_usage > 90%:
    batch_size *= 0.7    # å‡å°‘æ‰¹æ¬¡å¤§å°
    queue_size *= 0.8    # å‡å°‘é˜Ÿåˆ—ç¼“å­˜
```

#### 3. **é˜Ÿåˆ—æ·±åº¦ç®¡ç†**
```python
# ğŸ“ˆ é˜Ÿåˆ—ç§¯å‹æ™ºèƒ½å¤„ç†
if queue_ratio > 90%:
    queue_size *= 1.5    # æ‰©å¤§é˜Ÿåˆ—å®¹é‡
    if cpu_usage < 70%:
        workers *= 1.2   # CPUå…è®¸æ—¶å¢åŠ å¤„ç†çº¿ç¨‹
```

### ğŸ”§ å®é™…åº”ç”¨ç¤ºä¾‹

```python
# ä½¿ç”¨ç¤ºä¾‹
smart_optimizer = SmartHealthDataOptimizer()

# ç³»ç»Ÿä¼šè‡ªåŠ¨ç›‘æ§å¹¶è°ƒæ•´ï¼š
# - 4æ ¸å¿ƒç³»ç»Ÿï¼šæ‰¹æ¬¡100ï¼Œçº¿ç¨‹10
# - 8æ ¸å¿ƒç³»ç»Ÿï¼šæ‰¹æ¬¡200ï¼Œçº¿ç¨‹20  
# - 16æ ¸å¿ƒç³»ç»Ÿï¼šæ‰¹æ¬¡400ï¼Œçº¿ç¨‹40
# - 32æ ¸å¿ƒç³»ç»Ÿï¼šæ‰¹æ¬¡800ï¼Œçº¿ç¨‹80

# å®æ—¶ç›‘æ§å’Œè°ƒæ•´
metrics = smart_optimizer.resource_manager.get_metrics_summary()
print(f"å½“å‰é…ç½®: {metrics['config']}")
print(f"CPUä½¿ç”¨ç‡: {metrics['cpu_usage']['current']:.1f}%")
print(f"å¤„ç†é€Ÿç‡: {metrics['processing_rate']['current']:.1f} records/s")
```

### ğŸ“ˆ é¢„æœŸæ•ˆæœ

#### é™æ€é…ç½® vs åŠ¨æ€è°ƒæ•´

| åœºæ™¯ | é™æ€é…ç½® | åŠ¨æ€è°ƒæ•´ | æ€§èƒ½æå‡ |
|-----|---------|---------|----------|
| **ä½è´Ÿè½½æ—¶æ®µ** | å›ºå®šèµ„æºå ç”¨ | è‡ªåŠ¨é™ä½èµ„æºæ¶ˆè€— | **èŠ‚çœ30-50%èµ„æº** |
| **é«˜å³°æ—¶æ®µ** | å¯èƒ½ç“¶é¢ˆ | è‡ªåŠ¨æ‰©å±•å¤„ç†èƒ½åŠ› | **æå‡40-80%ååé‡** |
| **å†…å­˜ç´§å¼ ** | å¯èƒ½OOM | è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å° | **é¿å…ç³»ç»Ÿå´©æºƒ** |
| **CPUè¿‡è½½** | ç³»ç»Ÿå¡é¡¿ | è‡ªåŠ¨å‡å°‘å·¥ä½œçº¿ç¨‹ | **ä¿æŒç³»ç»Ÿç¨³å®š** |

#### ä¸åŒç¡¬ä»¶é…ç½®çš„è‡ªé€‚åº”æ•ˆæœ

```python
# ğŸ–¥ï¸ ä½ç«¯ç³»ç»Ÿ (4æ ¸å¿ƒ, 8GBå†…å­˜)
åˆå§‹é…ç½®: batch_size=80, workers=8, queue_size=800
é«˜è´Ÿè½½æ—¶: batch_size=60, workers=6, queue_size=600  # è‡ªåŠ¨é™çº§
ä½è´Ÿè½½æ—¶: batch_size=100, workers=10, queue_size=1000  # é€‚åº¦æå‡

# ğŸ’» ä¸­ç«¯ç³»ç»Ÿ (8æ ¸å¿ƒ, 16GBå†…å­˜)  
åˆå§‹é…ç½®: batch_size=200, workers=20, queue_size=2000
é«˜è´Ÿè½½æ—¶: batch_size=240, workers=24, queue_size=2400  # é€‚åº¦æå‡
ä½è´Ÿè½½æ—¶: batch_size=160, workers=16, queue_size=1600  # èŠ‚çº¦èµ„æº

# ğŸ–¥ï¸ é«˜ç«¯ç³»ç»Ÿ (16æ ¸å¿ƒ, 32GBå†…å­˜)
åˆå§‹é…ç½®: batch_size=480, workers=48, queue_size=4800
é«˜è´Ÿè½½æ—¶: batch_size=600, workers=60, queue_size=6000  # å¤§å¹…æå‡
ä½è´Ÿè½½æ—¶: batch_size=320, workers=32, queue_size=3200  # èŠ‚çº¦èµ„æº
```

è¿™ä¸ªæ™ºèƒ½åŠ¨æ€è°ƒæ•´ç³»ç»Ÿå°†ä½¿å¥åº·æ•°æ®å¤„ç†å™¨èƒ½å¤Ÿï¼š

1. **è‡ªåŠ¨é€‚åº”ä¸åŒç¡¬ä»¶ç¯å¢ƒ** - ä»4æ ¸åˆ°64æ ¸è‡ªåŠ¨ä¼˜åŒ–
2. **å®æ—¶å“åº”è´Ÿè½½å˜åŒ–** - é«˜å³°è‡ªåŠ¨æ‰©å®¹ï¼Œä½è°·è‡ªåŠ¨ç¼©å®¹  
3. **é˜²æ­¢ç³»ç»Ÿè¿‡è½½** - å†…å­˜/CPUä¿æŠ¤æœºåˆ¶
4. **æœ€å¤§åŒ–èµ„æºåˆ©ç”¨** - åœ¨ç¨³å®šæ€§å’Œæ€§èƒ½é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡

è¿™æ ·çš„ç³»ç»Ÿèƒ½å¤Ÿåœ¨å„ç§ç¯å¢ƒä¸‹éƒ½ä¿æŒæœ€ä½³æ€§èƒ½ï¼