# çµå¢ƒä¸‡è±¡å¥åº·ç®¡ç†ç³»ç»Ÿ - å‘Šè­¦ä¼˜åŒ–æ–¹æ¡ˆï¼šæ¶ˆæ¯æœºåˆ¶ä¸å‘Šè­¦æœºåˆ¶

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†çµå¢ƒä¸‡è±¡å¥åº·ç®¡ç†ç³»ç»Ÿä¸­å‘Šè­¦æœºåˆ¶å’Œæ¶ˆæ¯é€šçŸ¥æœºåˆ¶çš„æ·±åº¦åˆ†æä¸å…¨é¢ä¼˜åŒ–æ–¹æ¡ˆã€‚åŸºäºå¯¹ç°æœ‰ä»£ç çš„æ·±å…¥ç ”ç©¶ï¼Œæä¾›å¯æ“ä½œæ€§å¼ºçš„æ”¹è¿›å»ºè®®ï¼Œæ—¨åœ¨æ„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é ã€æ›´é«˜æ•ˆçš„å‘Šè­¦å¤„ç†ä½“ç³»ã€‚

### ğŸ¯ ä¼˜åŒ–ç›®æ ‡

- **æ™ºèƒ½åŒ–å‘Šè­¦**ï¼šä»ç®€å•é˜ˆå€¼æ£€æµ‹å‡çº§ä¸ºæ™ºèƒ½åˆ†æå¼•æ“
- **é«˜å¯é é€šçŸ¥**ï¼šæ„å»ºå¤šå±‚æ¬¡ã€å¤šæ¸ é“çš„é€šçŸ¥ä¿éšœæœºåˆ¶  
- **é«˜æ•ˆå¤„ç†**ï¼šæå‡å‘Šè­¦å¤„ç†æ•ˆç‡ï¼Œé™ä½äººå·¥å¹²é¢„æˆæœ¬
- **ç²¾å‡†åˆ†çº§**ï¼šå»ºç«‹ç§‘å­¦çš„ä¼˜å…ˆçº§ä½“ç³»ï¼Œç¡®ä¿é‡è¦å‘Šè­¦å¾—åˆ°åŠæ—¶å¤„ç†

---

## ğŸ” ç°çŠ¶æ·±åº¦åˆ†æ

### 1. å‘Šè­¦æ•°æ®è¡¨ç»“æ„åˆ†æ

#### å½“å‰è¡¨ç»“æ„
```sql
-- t_alert_info æ ¸å¿ƒè¡¨
CREATE TABLE t_alert_info (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    rule_id BIGINT,                    -- å…³è”å‘Šè­¦è§„åˆ™
    alert_type VARCHAR(100),           -- å‘Šè­¦ç±»å‹
    device_sn VARCHAR(20),            -- è®¾å¤‡åºåˆ—å·
    alert_timestamp DATETIME,         -- å‘Šè­¦æ—¶é—´
    alert_desc VARCHAR(2000),         -- å‘Šè­¦æè¿°  
    severity_level VARCHAR(50),       -- ä¸¥é‡çº§åˆ« (critical/high/medium/low)
    alert_status VARCHAR(50),         -- çŠ¶æ€ (pending/responded)
    user_id BIGINT,                   -- ç”¨æˆ·ID
    org_id BIGINT,                    -- ç»„ç»‡ID
    customer_id BIGINT,               -- ç§Ÿæˆ·ID
    health_id BIGINT,                 -- å¥åº·æ•°æ®ID
    -- æ³¨æ„ï¼šå½“å‰ç¼ºå°‘ priority å­—æ®µ
);

-- t_alert_action_log æ“ä½œæ—¥å¿—è¡¨
CREATE TABLE t_alert_action_log (
    log_id BIGINT PRIMARY KEY,
    alert_id BIGINT,                  -- å…³è”å‘Šè­¦ID
    action VARCHAR(50),               -- æ“ä½œç±»å‹
    action_user VARCHAR(255),         -- æ“ä½œç”¨æˆ·
    action_timestamp DATETIME,        -- æ“ä½œæ—¶é—´
    details TEXT,                     -- æ“ä½œè¯¦æƒ…
    customer_id BIGINT                -- ç§Ÿæˆ·ID
);
```

#### å‘ç°çš„é—®é¢˜
1. **ç¼ºå°‘ä¼˜å…ˆçº§å­—æ®µ**ï¼šæ— æ³•ç²¾ç¡®æ’åºå¤„ç†ä¼˜å…ˆçº§
2. **çŠ¶æ€ç²’åº¦å¤ªç²—**ï¼špending/responded æ— æ³•åæ˜ å¤„ç†è¿›åº¦
3. **ç¼ºå°‘å¤„ç†æœŸé™**ï¼šæ— è‡ªåŠ¨å‡çº§æœºåˆ¶
4. **ç´¢å¼•ä¸å¤Ÿä¼˜åŒ–**ï¼šé«˜é¢‘æŸ¥è¯¢åœºæ™¯ç´¢å¼•è¦†ç›–ä¸è¶³

### 2. æ¶ˆæ¯é€šçŸ¥æœºåˆ¶æ·±åº¦åˆ†æ

#### Message ç³»ç»Ÿå†…éƒ¨é€šä¿¡æ¶æ„
```sql
-- t_device_message ä¸»æ¶ˆæ¯è¡¨  
CREATE TABLE t_device_message (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    device_sn VARCHAR(255),           -- è®¾å¤‡åºåˆ—å·
    message TEXT,                     -- æ¶ˆæ¯å†…å®¹
    user_id VARCHAR(50),              -- æ¥æ”¶ç”¨æˆ·ID  
    message_type VARCHAR(50),         -- æ¶ˆæ¯ç±»å‹ ('warning', 'alarm', 'notification')
    sender_type VARCHAR(50),          -- å‘é€è€…ç±»å‹ ('system', 'admin', 'user')
    receiver_type VARCHAR(50),        -- æ¥æ”¶è€…ç±»å‹ ('user', 'manager', 'admin')  
    message_status VARCHAR(50),       -- æ¶ˆæ¯çŠ¶æ€ ('pending', '1'=å·²è¯»)
    customer_id BIGINT,               -- ç§Ÿæˆ·ID
    create_time DATETIME,             -- åˆ›å»ºæ—¶é—´
    responded_number INT DEFAULT 0    -- å“åº”è®¡æ•°
);
```

#### å±‚çº§é€šçŸ¥æœºåˆ¶åˆ†æ
åŸºäº `alert.py:892-940` çš„ä»£ç åˆ†æï¼Œå‘ç°äº†å®Œå–„çš„ä¸‰çº§é€šçŸ¥ä½“ç³»ï¼š

```python
# å½“å‰å±‚çº§é€šçŸ¥æµç¨‹
def _insert_device_messages_enhanced(device_sn, alert_type, severity_level, user_name, alert_severity_level):
    # ç¬¬1çº§ï¼šè®¾å¤‡ç”¨æˆ·é€šçŸ¥
    user_message = DeviceMessage(
        device_sn=device_sn,
        message=f"è®¾å¤‡{device_sn}å‘ç”Ÿ{alert_type}å‘Šè­¦ï¼Œä¸¥é‡çº§åˆ«ï¼š{severity_level}",
        user_id=str(user_id),
        receiver_type='user'
    )
    
    # ç¬¬2çº§ï¼šéƒ¨é—¨ä¸»ç®¡é€šçŸ¥  
    principals = UserOrg.query.filter_by(org_id=org_id, principal='1').all()
    for principal in principals:
        manager_message = DeviceMessage(
            message=f"è®¾å¤‡{device_sn}å‘ç”Ÿ{alert_type}å‘Šè­¦ï¼ˆè®¾å¤‡ç”¨æˆ·ï¼š{user_name}ï¼‰",
            user_id=str(principal.user_id), 
            receiver_type='manager'
        )
    
    # ç¬¬3çº§ï¼šCriticalçº§åˆ«å‘Šè­¦æ¨é€ç»™ç§Ÿæˆ·ç®¡ç†å‘˜
    if alert_severity_level == 'critical':
        admin_message = DeviceMessage(
            message=f"ç´§æ€¥å‘Šè­¦ï¼šè®¾å¤‡{device_sn}å‘ç”Ÿ{alert_type}",
            receiver_type='admin'
        )
```

#### Messageæœºåˆ¶ä¼˜åŠ¿
- âœ… **ç¦»çº¿å¯ç”¨**ï¼šä¸ä¾èµ–å¤–éƒ¨ç½‘ç»œï¼Œç³»ç»Ÿå†…éƒ¨é€šä¿¡
- âœ… **å¤šç§Ÿæˆ·æ”¯æŒ**ï¼šé€šè¿‡customer_idå®ç°ç§Ÿæˆ·éš”ç¦»
- âœ… **å±‚çº§é€šçŸ¥**ï¼šç”¨æˆ·â†’ä¸»ç®¡â†’ç®¡ç†å‘˜ä¸‰çº§ä½“ç³»
- âœ… **çŠ¶æ€è¿½è¸ª**ï¼šæ”¯æŒå·²è¯»/æœªè¯»çŠ¶æ€ç®¡ç†

#### å‘ç°çš„é—®é¢˜
1. **æ¶ˆæ¯å»é‡ä¸è¶³**ï¼šçŸ­æ—¶é—´å†…å¯èƒ½äº§ç”Ÿé‡å¤æ¶ˆæ¯
2. **ä¼˜å…ˆçº§ç¼ºå¤±**ï¼šæ¶ˆæ¯æ— ä¼˜å…ˆçº§æ’åºæœºåˆ¶
3. **æ‰¹é‡å¤„ç†èƒ½åŠ›å¼±**ï¼šæ— æ‰¹é‡ç¡®è®¤ã€æ‰¹é‡åˆ†å‘æœºåˆ¶
4. **é€šçŸ¥ç­–ç•¥å›ºåŒ–**ï¼šç¼ºä¹åŸºäºæ—¶é—´ã€ç”¨æˆ·åå¥½çš„æ™ºèƒ½è°ƒæ•´

### 3. å‘Šè­¦ç”Ÿæˆé“¾è·¯åˆ†æ

#### å½“å‰å‘Šè­¦ç”Ÿæˆæµç¨‹
```
ljwx-watch â†’ upload_common_event â†’ ljwx-bigscreen â†’ è§„åˆ™åŒ¹é… â†’ å‘Šè­¦ç”Ÿæˆ
     â†“              â†“                    â†“             â†“
 è®¾å¤‡äº‹ä»¶      å¥åº·æ•°æ®ä¸Šä¼         bigscreenå¤„ç†    æ’å…¥t_alert_info
     â†“              â†“                    â†“             â†“
 SOS/æ‘”å€’      heart_rateç­‰        åŒ¹é…t_alert_rules  ç”Ÿæˆå‘Šè­¦è®°å½•
```

#### è§„åˆ™åŒ¹é…é€»è¾‘é—®é¢˜
å½“å‰è§„åˆ™åŒ¹é…è¿‡äºç®€å•ï¼š
```python
# å½“å‰ç®€åŒ–çš„è§„åˆ™åŒ¹é…ï¼ˆä»ä»£ç åˆ†ææ¨æ–­ï¼‰
if heart_rate > threshold_max or heart_rate < threshold_min:
    generate_alert(severity='high')
```

**å­˜åœ¨é—®é¢˜ï¼š**
- ç¼ºä¹ä¸Šä¸‹æ–‡åˆ†æ
- æ— ä¸ªäººåŸºçº¿å¯¹æ¯”
- ç¼ºä¹è¶‹åŠ¿åˆ¤æ–­
- è¯¯æŠ¥ç‡è¾ƒé«˜

---

## ğŸš€ æ ¸å¿ƒä¼˜åŒ–æ–¹æ¡ˆ

### 1. å‘Šè­¦ä¼˜å…ˆçº§(Priority)å­—æ®µè®¾è®¡ä¸å®ç°

#### 1.1 æ•°æ®åº“ç»“æ„å‡çº§
```sql
-- æ·»åŠ ä¼˜å…ˆçº§ç›¸å…³å­—æ®µ
ALTER TABLE t_alert_info 
ADD COLUMN priority TINYINT DEFAULT 5 COMMENT 'ä¼˜å…ˆçº§(1-10, 1æœ€é«˜, 10æœ€ä½)' AFTER severity_level,
ADD COLUMN due_time DATETIME COMMENT 'å¤„ç†æˆªæ­¢æ—¶é—´' AFTER priority,
ADD COLUMN escalation_level TINYINT DEFAULT 0 COMMENT 'å‡çº§çº§åˆ«(0-3)' AFTER due_time,
ADD COLUMN auto_close_time DATETIME COMMENT 'è‡ªåŠ¨å…³é—­æ—¶é—´' AFTER escalation_level;

-- ä¼˜åŒ–ç´¢å¼•
CREATE INDEX idx_alert_priority_processing ON t_alert_info(customer_id, priority, alert_status, due_time);
CREATE INDEX idx_alert_escalation ON t_alert_info(customer_id, escalation_level, alert_timestamp);
```

#### 1.2 æ™ºèƒ½ä¼˜å…ˆçº§è®¡ç®—ç®—æ³•
```python
class AlertPriorityCalculator:
    """å‘Šè­¦ä¼˜å…ˆçº§æ™ºèƒ½è®¡ç®—å¼•æ“"""
    
    def __init__(self):
        # åŸºç¡€ä¼˜å…ˆçº§æ˜ å°„
        self.base_priority_map = {
            'critical': 1,    # ç´§æ€¥å‘Šè­¦
            'high': 3,        # é«˜çº§å‘Šè­¦  
            'medium': 5,      # ä¸­çº§å‘Šè­¦
            'low': 7          # ä½çº§å‘Šè­¦
        }
        
        # å‘Šè­¦ç±»å‹æƒé‡
        self.alert_type_weights = {
            'SOS': -2,                    # SOSæœ€é«˜ä¼˜å…ˆçº§
            'fall_detection': -1,         # æ‘”å€’æ£€æµ‹é«˜ä¼˜å…ˆçº§
            'heart_rate_abnormal': 0,     # å¿ƒç‡å¼‚å¸¸æ ‡å‡†ä¼˜å…ˆçº§
            'blood_pressure_high': 0,     # é«˜è¡€å‹æ ‡å‡†ä¼˜å…ˆçº§  
            'device_offline': +1,         # è®¾å¤‡ç¦»çº¿ç›¸å¯¹è¾ƒä½
            'battery_low': +2,            # ç”µé‡ä½æœ€ä½ä¼˜å…ˆçº§
            'data_anomaly': +1            # æ•°æ®å¼‚å¸¸è¾ƒä½ä¼˜å…ˆçº§
        }
    
    def calculate_priority(self, alert_info, user_profile=None, context=None):
        """
        è®¡ç®—å‘Šè­¦ä¼˜å…ˆçº§
        :param alert_info: å‘Šè­¦ä¿¡æ¯å¯¹è±¡
        :param user_profile: ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯
        :param context: ä¸Šä¸‹æ–‡ä¿¡æ¯(æ—¶é—´ã€åœ°ç‚¹ã€å†å²ç­‰)
        :return: è®¡ç®—åçš„ä¼˜å…ˆçº§ (1-10)
        """
        # 1. åŸºç¡€ä¼˜å…ˆçº§
        base_priority = self.base_priority_map.get(alert_info.severity_level, 5)
        
        # 2. å‘Šè­¦ç±»å‹è°ƒæ•´
        type_adjustment = self.alert_type_weights.get(alert_info.alert_type, 0)
        
        # 3. æ—¶é—´å› å­è°ƒæ•´
        time_adjustment = self._calculate_time_factor(alert_info.alert_timestamp)
        
        # 4. ç”¨æˆ·ç‰¹å¾è°ƒæ•´
        user_adjustment = self._calculate_user_factor(user_profile) if user_profile else 0
        
        # 5. å†å²é¢‘ç‡è°ƒæ•´ (é¿å…ç‹¼æ¥äº†æ•ˆåº”)
        frequency_adjustment = self._calculate_frequency_factor(
            alert_info.device_sn, alert_info.alert_type, hours=24
        )
        
        # 6. åœ°ç†ä½ç½®è°ƒæ•´ (åè¿œåœ°åŒºä¼˜å…ˆçº§æå‡)
        location_adjustment = self._calculate_location_factor(
            alert_info.latitude, alert_info.longitude
        ) if alert_info.latitude and alert_info.longitude else 0
        
        # ç»¼åˆè®¡ç®—
        total_adjustment = (type_adjustment + time_adjustment + 
                          user_adjustment + frequency_adjustment + location_adjustment)
        
        final_priority = max(1, min(10, base_priority + total_adjustment))
        
        # 7. è®¡ç®—å¤„ç†æœŸé™
        due_time = self._calculate_due_time(final_priority, alert_info.alert_type)
        
        return {
            'priority': final_priority,
            'due_time': due_time,
            'calculation_details': {
                'base': base_priority,
                'type_adj': type_adjustment,
                'time_adj': time_adjustment,
                'user_adj': user_adjustment,
                'freq_adj': frequency_adjustment,
                'location_adj': location_adjustment,
                'total_adj': total_adjustment
            }
        }
    
    def _calculate_time_factor(self, alert_timestamp):
        """è®¡ç®—æ—¶é—´å› å­è°ƒæ•´"""
        hour = alert_timestamp.hour
        day_of_week = alert_timestamp.weekday()
        
        adjustment = 0
        
        # å¤œé—´æ—¶æ®µ (22:00-06:00) ä¼˜å…ˆçº§æå‡
        if 22 <= hour or hour <= 6:
            adjustment -= 1
        
        # å‘¨æœ«ä¼˜å…ˆçº§æå‡
        if day_of_week >= 5:  # å‘¨å…­ã€å‘¨æ—¥
            adjustment -= 1
            
        # èŠ‚å‡æ—¥ä¼˜å…ˆçº§æå‡ (éœ€è¦èŠ‚å‡æ—¥APIæ”¯æŒ)
        # if is_holiday(alert_timestamp.date()):
        #     adjustment -= 1
            
        return adjustment
    
    def _calculate_user_factor(self, user_profile):
        """è®¡ç®—ç”¨æˆ·ç‰¹å¾è°ƒæ•´"""
        adjustment = 0
        
        # å¹´é¾„å› å­
        age = user_profile.get('age', 0)
        if age >= 70:
            adjustment -= 2  # 70å²ä»¥ä¸Šé«˜ä¼˜å…ˆçº§
        elif age >= 60:
            adjustment -= 1  # 60å²ä»¥ä¸Šä¸­ä¼˜å…ˆçº§
        elif age <= 18:
            adjustment -= 1  # æœªæˆå¹´äººé«˜ä¼˜å…ˆçº§
            
        # å¥åº·çŠ¶å†µå› å­
        health_risk_level = user_profile.get('health_risk_level', 'normal')
        if health_risk_level == 'high':
            adjustment -= 2
        elif health_risk_level == 'medium':
            adjustment -= 1
            
        # VIPç”¨æˆ·å› å­
        if user_profile.get('is_vip', False):
            adjustment -= 1
            
        return adjustment
    
    def _calculate_frequency_factor(self, device_sn, alert_type, hours=24):
        """è®¡ç®—å†å²é¢‘ç‡è°ƒæ•´ (é¿å…è¯¯æŠ¥ç‹¼æ¥äº†æ•ˆåº”)"""
        from datetime import datetime, timedelta
        
        # æŸ¥è¯¢æœ€è¿‘24å°æ—¶å†…ç›¸åŒç±»å‹å‘Šè­¦æ•°é‡
        recent_count = AlertInfo.query.filter(
            AlertInfo.device_sn == device_sn,
            AlertInfo.alert_type == alert_type,
            AlertInfo.alert_timestamp >= datetime.now() - timedelta(hours=hours)
        ).count()
        
        # é¢‘ç¹å‘Šè­¦é™ä½ä¼˜å…ˆçº§
        if recent_count >= 10:
            return +3  # ä¸¥é‡é™ä½ä¼˜å…ˆçº§
        elif recent_count >= 5:
            return +2  # ä¸­åº¦é™ä½ä¼˜å…ˆçº§  
        elif recent_count >= 3:
            return +1  # è½»å¾®é™ä½ä¼˜å…ˆçº§
        else:
            return 0   # ä¸è°ƒæ•´
            
    def _calculate_location_factor(self, latitude, longitude):
        """è®¡ç®—åœ°ç†ä½ç½®è°ƒæ•´"""
        # åè¿œåœ°åŒºåˆ¤æ–­é€»è¾‘ (éœ€è¦åœ°ç†APIæ”¯æŒ)
        # è¿™é‡Œæä¾›ç¤ºä¾‹é€»è¾‘
        
        # å¦‚æœæ˜¯åè¿œåœ°åŒºï¼Œä¼˜å…ˆçº§æå‡ 
        # if is_remote_area(latitude, longitude):
        #     return -1
        
        return 0
    
    def _calculate_due_time(self, priority, alert_type):
        """æ ¹æ®ä¼˜å…ˆçº§è®¡ç®—å¤„ç†æœŸé™"""
        from datetime import datetime, timedelta
        
        # å¤„ç†æ—¶é™æ˜ å°„ (åˆ†é’Ÿ)
        time_limits = {
            1: 5,      # æœ€é«˜ä¼˜å…ˆçº§ 5åˆ†é’Ÿ
            2: 15,     # é«˜ä¼˜å…ˆçº§ 15åˆ†é’Ÿ
            3: 30,     # ä¸­é«˜ä¼˜å…ˆçº§ 30åˆ†é’Ÿ
            4: 60,     # ä¸­ä¼˜å…ˆçº§ 1å°æ—¶
            5: 120,    # æ ‡å‡†ä¼˜å…ˆçº§ 2å°æ—¶
            6: 240,    # ä¸­ä½ä¼˜å…ˆçº§ 4å°æ—¶
            7: 480,    # ä½ä¼˜å…ˆçº§ 8å°æ—¶
            8: 960,    # è¾ƒä½ä¼˜å…ˆçº§ 16å°æ—¶
            9: 1440,   # æœ€ä½ä¼˜å…ˆçº§ 24å°æ—¶
            10: 2880   # æä½ä¼˜å…ˆçº§ 48å°æ—¶
        }
        
        # SOSç±»å‹å‘Šè­¦ç‰¹æ®Šå¤„ç†
        if alert_type == 'SOS':
            limit_minutes = 3  # SOSå‘Šè­¦3åˆ†é’Ÿå†…å¿…é¡»å¤„ç†
        else:
            limit_minutes = time_limits.get(priority, 120)
            
        return datetime.now() + timedelta(minutes=limit_minutes)
```

#### 1.3 ä¼˜å…ˆçº§åº”ç”¨å®ä¾‹
```python
# åœ¨å‘Šè­¦ç”Ÿæˆæ—¶ä½¿ç”¨ä¼˜å…ˆçº§è®¡ç®—
def create_alert_with_smart_priority(alert_data, user_profile=None):
    """åˆ›å»ºå¸¦æ™ºèƒ½ä¼˜å…ˆçº§çš„å‘Šè­¦"""
    
    # åˆ›å»ºåŸºç¡€å‘Šè­¦å¯¹è±¡
    alert = AlertInfo(**alert_data)
    
    # è®¡ç®—æ™ºèƒ½ä¼˜å…ˆçº§
    calculator = AlertPriorityCalculator()
    priority_result = calculator.calculate_priority(alert, user_profile)
    
    # åº”ç”¨è®¡ç®—ç»“æœ
    alert.priority = priority_result['priority']
    alert.due_time = priority_result['due_time']
    
    # è®°å½•è®¡ç®—è¯¦æƒ…(ç”¨äºè°ƒè¯•å’Œä¼˜åŒ–)
    alert.priority_calculation_log = json.dumps(
        priority_result['calculation_details']
    )
    
    db.session.add(alert)
    db.session.commit()
    
    return alert
```

### 2. æ™ºèƒ½è§„åˆ™å¼•æ“å‡çº§

#### 2.1 å¤šç»´åº¦è§„åˆ™åŒ¹é…å¼•æ“
```python
class SmartAlertRuleEngine:
    """æ™ºèƒ½å‘Šè­¦è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.context_analyzer = ContextAnalyzer()
        self.baseline_analyzer = BaselineAnalyzer()
        self.trend_analyzer = TrendAnalyzer()
        self.ml_predictor = MLHealthPredictor()  # æœºå™¨å­¦ä¹ é¢„æµ‹å™¨
        
    def evaluate_health_data(self, health_data, user_profile, historical_data):
        """
        å¤šç»´åº¦å¥åº·æ•°æ®è¯„ä¼°
        :param health_data: å½“å‰å¥åº·æ•°æ®
        :param user_profile: ç”¨æˆ·æ¡£æ¡ˆ
        :param historical_data: å†å²æ•°æ®
        :return: å‘Šè­¦è¯„ä¼°ç»“æœ
        """
        evaluation_results = []
        
        # 1. åŸºç¡€é˜ˆå€¼æ£€æŸ¥
        basic_alerts = self._check_basic_thresholds(health_data, user_profile)
        evaluation_results.extend(basic_alerts)
        
        # 2. ä¸ªäººåŸºçº¿åˆ†æ  
        baseline_alerts = self._analyze_personal_baseline(
            health_data, user_profile, historical_data
        )
        evaluation_results.extend(baseline_alerts)
        
        # 3. è¶‹åŠ¿åˆ†æ
        trend_alerts = self._analyze_health_trends(historical_data)
        evaluation_results.extend(trend_alerts)
        
        # 4. æœºå™¨å­¦ä¹ é¢„æµ‹
        ml_alerts = self._ml_anomaly_detection(health_data, historical_data)
        evaluation_results.extend(ml_alerts)
        
        # 5. æ™ºèƒ½è¿‡æ»¤
        filtered_alerts = self._intelligent_filter(evaluation_results)
        
        return filtered_alerts
    
    def _check_basic_thresholds(self, health_data, user_profile):
        """åŸºç¡€é˜ˆå€¼æ£€æŸ¥ - ä¼˜åŒ–åçš„ç‰ˆæœ¬"""
        alerts = []
        
        # åŠ¨æ€é˜ˆå€¼ (æ ¹æ®ç”¨æˆ·å¹´é¾„ã€æ€§åˆ«ã€ä½“è´¨è°ƒæ•´)
        dynamic_thresholds = self._calculate_dynamic_thresholds(user_profile)
        
        # å¿ƒç‡æ£€æŸ¥
        if health_data.heart_rate:
            hr = health_data.heart_rate
            hr_min, hr_max = dynamic_thresholds['heart_rate']
            
            if hr > hr_max:
                severity = 'critical' if hr > hr_max * 1.2 else 'high'
                alerts.append({
                    'type': 'heart_rate_high',
                    'severity': severity,
                    'value': hr,
                    'threshold': hr_max,
                    'message': f'å¿ƒç‡è¿‡é«˜: {hr} bpm (æ­£å¸¸èŒƒå›´: {hr_min}-{hr_max})'
                })
            elif hr < hr_min:
                severity = 'critical' if hr < hr_min * 0.8 else 'high'  
                alerts.append({
                    'type': 'heart_rate_low',
                    'severity': severity,
                    'value': hr,
                    'threshold': hr_min,
                    'message': f'å¿ƒç‡è¿‡ä½: {hr} bpm (æ­£å¸¸èŒƒå›´: {hr_min}-{hr_max})'
                })
        
        # è¡€å‹æ£€æŸ¥ (ç±»ä¼¼ä¼˜åŒ–é€»è¾‘)
        if health_data.pressure_high and health_data.pressure_low:
            bp_alerts = self._check_blood_pressure(
                health_data.pressure_high, 
                health_data.pressure_low, 
                dynamic_thresholds['blood_pressure']
            )
            alerts.extend(bp_alerts)
            
        return alerts
    
    def _analyze_personal_baseline(self, current_data, user_profile, historical_data):
        """ä¸ªäººåŸºçº¿åˆ†æ - åŸºäºä¸ªäººå†å²å»ºç«‹åŸºçº¿"""
        alerts = []
        
        if len(historical_data) < 7:  # éœ€è¦è‡³å°‘ä¸€å‘¨æ•°æ®å»ºç«‹åŸºçº¿
            return alerts
            
        # è®¡ç®—ä¸ªäººåŸºçº¿
        personal_baseline = self.baseline_analyzer.calculate_baseline(
            historical_data, user_profile
        )
        
        # æ£€æŸ¥ä¸åŸºçº¿çš„åå·®
        for metric in ['heart_rate', 'pressure_high', 'pressure_low', 'blood_oxygen']:
            current_value = getattr(current_data, metric, None)
            if current_value is None:
                continue
                
            baseline_info = personal_baseline.get(metric)
            if not baseline_info:
                continue
                
            deviation = abs(current_value - baseline_info['mean'])
            threshold = baseline_info['std'] * 2  # 2ä¸ªæ ‡å‡†å·®
            
            if deviation > threshold:
                severity = 'high' if deviation > threshold * 1.5 else 'medium'
                alerts.append({
                    'type': f'{metric}_baseline_deviation',
                    'severity': severity,
                    'value': current_value,
                    'baseline_mean': baseline_info['mean'],
                    'deviation': deviation,
                    'message': f'{metric}åç¦»ä¸ªäººåŸºçº¿: {current_value} (åŸºçº¿: {baseline_info["mean"]:.1f}Â±{baseline_info["std"]:.1f})'
                })
        
        return alerts
    
    def _analyze_health_trends(self, historical_data):
        """å¥åº·è¶‹åŠ¿åˆ†æ"""
        alerts = []
        
        if len(historical_data) < 10:  # éœ€è¦è¶³å¤Ÿæ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
            return alerts
            
        # åˆ†æå„é¡¹æŒ‡æ ‡çš„è¶‹åŠ¿
        trend_results = self.trend_analyzer.analyze_trends(historical_data)
        
        for metric, trend_info in trend_results.items():
            if trend_info['trend_type'] == 'deteriorating':
                severity = self._assess_trend_severity(trend_info)
                alerts.append({
                    'type': f'{metric}_trend_warning',
                    'severity': severity,
                    'trend_direction': trend_info['direction'],
                    'trend_strength': trend_info['strength'],
                    'message': f'{metric}å‘ˆæ¶åŒ–è¶‹åŠ¿: {trend_info["description"]}'
                })
        
        return alerts
    
    def _intelligent_filter(self, raw_alerts):
        """æ™ºèƒ½è¿‡æ»¤ - å‡å°‘è¯¯æŠ¥"""
        if not raw_alerts:
            return []
            
        # 1. å»é‡å’Œåˆå¹¶ç›¸ä¼¼å‘Šè­¦
        merged_alerts = self._merge_similar_alerts(raw_alerts)
        
        # 2. åŸºäºç½®ä¿¡åº¦è¿‡æ»¤
        high_confidence_alerts = [
            alert for alert in merged_alerts 
            if alert.get('confidence', 1.0) >= 0.7
        ]
        
        # 3. åŸºäºå†å²å‡†ç¡®æ€§è¿‡æ»¤
        filtered_alerts = self._filter_by_historical_accuracy(high_confidence_alerts)
        
        return filtered_alerts
```

#### 2.2 æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
```python
class MLHealthPredictor:
    """åŸºäºæœºå™¨å­¦ä¹ çš„å¥åº·å¼‚å¸¸æ£€æµ‹"""
    
    def __init__(self):
        self.isolation_forest = None
        self.lstm_model = None
        self.trained = False
    
    def train_models(self, training_data):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        from sklearn.ensemble import IsolationForest
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import LSTM, Dense
        
        # 1. è®­ç»ƒå­¤ç«‹æ£®æ—å¼‚å¸¸æ£€æµ‹æ¨¡å‹
        self.isolation_forest = IsolationForest(
            contamination=0.1,  # å‡è®¾10%ä¸ºå¼‚å¸¸
            random_state=42
        )
        self.isolation_forest.fit(training_data['features'])
        
        # 2. è®­ç»ƒLSTMæ—¶åºé¢„æµ‹æ¨¡å‹
        self.lstm_model = self._build_lstm_model(training_data['sequences'])
        
        self.trained = True
    
    def detect_anomalies(self, health_data, historical_sequences):
        """æ£€æµ‹å¥åº·æ•°æ®å¼‚å¸¸"""
        if not self.trained:
            return []
            
        alerts = []
        
        # 1. å­¤ç«‹æ£®æ—æ£€æµ‹
        features = self._extract_features(health_data)
        isolation_score = self.isolation_forest.decision_function([features])[0]
        
        if isolation_score < -0.1:  # å¼‚å¸¸é˜ˆå€¼
            alerts.append({
                'type': 'ml_anomaly_detected',
                'severity': 'medium',
                'confidence': abs(isolation_score),
                'message': f'æœºå™¨å­¦ä¹ æ£€æµ‹åˆ°å¼‚å¸¸æ¨¡å¼ (å¼‚å¸¸åº¦: {abs(isolation_score):.3f})'
            })
        
        # 2. LSTMæ—¶åºå¼‚å¸¸æ£€æµ‹
        if len(historical_sequences) >= 10:
            prediction = self.lstm_model.predict([historical_sequences[-10:]])
            actual = self._extract_features(health_data)
            
            mse = np.mean((prediction[0] - actual) ** 2)
            if mse > self.anomaly_threshold:
                alerts.append({
                    'type': 'sequence_anomaly_detected',
                    'severity': 'medium',
                    'confidence': min(mse / self.anomaly_threshold, 1.0),
                    'message': f'æ—¶åºæ¨¡å¼å¼‚å¸¸ (åå·®: {mse:.3f})'
                })
        
        return alerts
```

### 3. æ¶ˆæ¯é€šçŸ¥ç³»ç»Ÿå…¨é¢ä¼˜åŒ–

#### 3.1 æ™ºèƒ½æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿ
```python
class SmartMessageQueue:
    """æ™ºèƒ½æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿ"""
    
    def __init__(self):
        self.priority_queues = {
            1: deque(),  # æœ€é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
            2: deque(),  # é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—
            3: deque(),  # ä¸­ä¼˜å…ˆçº§é˜Ÿåˆ—
            4: deque(),  # ä½ä¼˜å…ˆçº§é˜Ÿåˆ—
        }
        self.message_dedup_cache = {}  # æ¶ˆæ¯å»é‡ç¼“å­˜
        self.delivery_attempts = {}    # æŠ•é€’é‡è¯•è®°å½•
        
    def enqueue_message(self, message_data, priority=3):
        """æ™ºèƒ½å…¥é˜Ÿæ¶ˆæ¯"""
        
        # 1. æ¶ˆæ¯å»é‡æ£€æŸ¥
        message_key = self._generate_message_key(message_data)
        if self._is_duplicate_message(message_key):
            self._update_duplicate_count(message_key)
            return False
        
        # 2. æ¶ˆæ¯ä¼˜åŒ–å¤„ç†
        optimized_message = self._optimize_message_content(message_data)
        
        # 3. åŠ å…¥ä¼˜å…ˆçº§é˜Ÿåˆ—
        queue_item = {
            'message': optimized_message,
            'timestamp': datetime.now(),
            'priority': priority,
            'attempts': 0,
            'message_key': message_key,
            'user_preferences': self._get_user_notification_preferences(
                optimized_message.get('user_id')
            )
        }
        
        self.priority_queues[priority].append(queue_item)
        
        # 4. ç¼“å­˜æ¶ˆæ¯é”®ç”¨äºå»é‡
        self.message_dedup_cache[message_key] = {
            'first_time': datetime.now(),
            'count': 1
        }
        
        return True
    
    def dequeue_message(self):
        """æŒ‰ä¼˜å…ˆçº§å‡ºé˜Ÿæ¶ˆæ¯"""
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºå¤„ç†
        for priority in [1, 2, 3, 4]:
            if self.priority_queues[priority]:
                return self.priority_queues[priority].popleft()
        return None
    
    def _is_duplicate_message(self, message_key, time_window=300):
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤æ¶ˆæ¯ (5åˆ†é’Ÿå†…)"""
        if message_key not in self.message_dedup_cache:
            return False
            
        cached_info = self.message_dedup_cache[message_key]
        time_diff = (datetime.now() - cached_info['first_time']).total_seconds()
        
        return time_diff < time_window
    
    def _generate_message_key(self, message_data):
        """ç”Ÿæˆæ¶ˆæ¯å»é‡é”®"""
        key_parts = [
            message_data.get('device_sn', ''),
            message_data.get('alert_type', ''),
            message_data.get('user_id', ''),
            message_data.get('message_type', '')
        ]
        return hashlib.md5('|'.join(key_parts).encode()).hexdigest()
    
    def _optimize_message_content(self, message_data):
        """ä¼˜åŒ–æ¶ˆæ¯å†…å®¹"""
        optimized = message_data.copy()
        
        # 1. æ¶ˆæ¯å†…å®¹æ™ºèƒ½ç²¾ç®€
        if len(optimized.get('message', '')) > 200:
            optimized['message'] = optimized['message'][:200] + '...'
            
        # 2. æ·»åŠ ç´§æ€¥ç¨‹åº¦æ ‡è¯†
        severity = message_data.get('severity_level', 'medium')
        urgency_prefix = {
            'critical': 'ğŸš¨ç´§æ€¥ ',
            'high': 'âš ï¸é‡è¦ ',
            'medium': 'ğŸ“¢é€šçŸ¥ ',
            'low': 'ğŸ’¬æé†’ '
        }.get(severity, '')
        
        optimized['message'] = urgency_prefix + optimized.get('message', '')
        
        return optimized
    
    def _get_user_notification_preferences(self, user_id):
        """è·å–ç”¨æˆ·é€šçŸ¥åå¥½è®¾ç½®"""
        # è¿™é‡Œåº”è¯¥ä»ç”¨æˆ·è®¾ç½®è¡¨è·å–åå¥½
        # ç¤ºä¾‹è¿”å›é»˜è®¤åå¥½
        return {
            'quiet_hours': {'start': '22:00', 'end': '07:00'},
            'max_frequency': 5,  # æ¯å°æ—¶æœ€å¤š5æ¡
            'preferred_channels': ['message', 'wechat'],
            'severity_filter': 'medium'  # åªæ¥æ”¶mediumåŠä»¥ä¸Šçº§åˆ«
        }
```

#### 3.2 æ™ºèƒ½é€šçŸ¥ç­–ç•¥å¼•æ“
```python
class SmartNotificationStrategy:
    """æ™ºèƒ½é€šçŸ¥ç­–ç•¥å¼•æ“"""
    
    def __init__(self):
        self.channel_manager = NotificationChannelManager()
        self.user_behavior_analyzer = UserBehaviorAnalyzer()
        
    def determine_notification_plan(self, alert, user_preferences=None):
        """ç¡®å®šé€šçŸ¥è®¡åˆ’"""
        
        plan = NotificationPlan()
        current_time = datetime.now()
        
        # 1. åŸºç¡€é€šçŸ¥æ¸ é“é€‰æ‹©
        base_channels = self._select_base_channels(alert, user_preferences)
        plan.primary_channels = base_channels
        
        # 2. æ—¶é—´ç­–ç•¥è°ƒæ•´
        if self._is_quiet_hours(current_time, user_preferences):
            if alert.severity_level in ['critical', 'high']:
                plan.override_quiet_hours = True
                plan.escalation_delay = 60  # 1åˆ†é’Ÿåå‡çº§
            else:
                plan.delay_until = self._get_quiet_hours_end(user_preferences)
                
        # 3. é¢‘ç‡æ§åˆ¶ç­–ç•¥
        recent_count = self._get_recent_notification_count(
            alert.user_id, hours=1
        )
        if recent_count >= user_preferences.get('max_frequency', 5):
            if alert.severity_level == 'critical':
                plan.force_delivery = True  # ç´§æ€¥æ¶ˆæ¯å¼ºåˆ¶æŠ•é€’
            else:
                plan.batch_delivery = True  # æ‰¹é‡æŠ•é€’
                
        # 4. å‡çº§ç­–ç•¥
        plan.escalation_chain = self._build_escalation_chain(alert)
        
        # 5. å›è°ƒç¡®è®¤ç­–ç•¥
        if alert.severity_level in ['critical', 'high']:
            plan.require_acknowledgment = True
            plan.acknowledgment_timeout = 300 if alert.severity_level == 'critical' else 900
            
        return plan
    
    def _select_base_channels(self, alert, user_preferences):
        """é€‰æ‹©åŸºç¡€é€šçŸ¥æ¸ é“"""
        channels = []
        
        # æ ¹æ®å‘Šè­¦çº§åˆ«é€‰æ‹©æ¸ é“
        if alert.severity_level == 'critical':
            channels = ['message', 'wechat', 'websocket']  # å…¨æ¸ é“
        elif alert.severity_level == 'high':
            channels = ['message', 'wechat']
        else:
            channels = ['message']
        
        # åº”ç”¨ç”¨æˆ·åå¥½è¿‡æ»¤
        if user_preferences and 'preferred_channels' in user_preferences:
            preferred = user_preferences['preferred_channels']
            channels = [ch for ch in channels if ch in preferred]
            
        return channels
    
    def _build_escalation_chain(self, alert):
        """æ„å»ºå‡çº§é“¾"""
        chain = []
        
        # è·å–è®¾å¤‡ç»‘å®šä¿¡æ¯
        device_info = self._get_device_binding_info(alert.device_sn)
        if not device_info:
            return chain
        
        # ç¬¬1çº§ï¼šè®¾å¤‡ç”¨æˆ·
        chain.append({
            'level': 1,
            'target_type': 'user',
            'target_id': device_info['user_id'],
            'delay_minutes': 0
        })
        
        # ç¬¬2çº§ï¼šéƒ¨é—¨ä¸»ç®¡ (5åˆ†é’Ÿåå‡çº§)
        managers = self._get_department_managers(device_info['org_id'])
        if managers:
            chain.append({
                'level': 2,
                'target_type': 'manager', 
                'target_ids': [m['user_id'] for m in managers],
                'delay_minutes': 5
            })
        
        # ç¬¬3çº§ï¼šç§Ÿæˆ·ç®¡ç†å‘˜ (15åˆ†é’Ÿåå‡çº§ï¼Œä»…Critical)
        if alert.severity_level == 'critical':
            admins = self._get_tenant_admins(alert.customer_id)
            if admins:
                chain.append({
                    'level': 3,
                    'target_type': 'admin',
                    'target_ids': [a['user_id'] for a in admins],
                    'delay_minutes': 15
                })
        
        return chain
```

#### 3.3 æ¶ˆæ¯çŠ¶æ€è¿½è¸ªä¸åˆ†æ
```python
class MessageTrackingSystem:
    """æ¶ˆæ¯çŠ¶æ€è¿½è¸ªä¸åˆ†æç³»ç»Ÿ"""
    
    def __init__(self):
        self.redis_client = redis.Redis()
        self.delivery_stats = DeliveryStatistics()
        
    def track_message_lifecycle(self, message_id, status, metadata=None):
        """è¿½è¸ªæ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸ"""
        
        tracking_data = {
            'message_id': message_id,
            'status': status,
            'timestamp': datetime.now().isoformat(),
            'metadata': metadata or {}
        }
        
        # 1. è®°å½•åˆ°Redis (å®æ—¶æŸ¥è¯¢)
        redis_key = f"message_track:{message_id}"
        self.redis_client.lpush(redis_key, json.dumps(tracking_data))
        self.redis_client.expire(redis_key, 7 * 24 * 3600)  # 7å¤©è¿‡æœŸ
        
        # 2. è®°å½•åˆ°æ•°æ®åº“ (æŒä¹…åŒ–)
        log_entry = MessageTrackingLog(
            message_id=message_id,
            status=status,
            timestamp=datetime.now(),
            metadata=json.dumps(metadata) if metadata else None
        )
        db.session.add(log_entry)
        db.session.commit()
        
        # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.delivery_stats.update_stats(status, metadata)
        
        # 4. è§¦å‘çŠ¶æ€å˜æ›´å¤„ç†
        self._handle_status_change(message_id, status, metadata)
    
    def get_message_delivery_report(self, time_range=24):
        """è·å–æ¶ˆæ¯æŠ•é€’æŠ¥å‘Š"""
        return {
            'time_range_hours': time_range,
            'total_messages': self._count_messages(time_range),
            'delivery_success_rate': self._calculate_success_rate(time_range),
            'average_delivery_time': self._calculate_avg_delivery_time(time_range),
            'channel_performance': self._analyze_channel_performance(time_range),
            'user_engagement': self._analyze_user_engagement(time_range),
            'escalation_statistics': self._analyze_escalation_stats(time_range)
        }
    
    def _handle_status_change(self, message_id, status, metadata):
        """å¤„ç†çŠ¶æ€å˜æ›´"""
        
        if status == 'delivered':
            # æ¶ˆæ¯å·²æŠ•é€’ï¼Œå¼€å§‹ç­‰å¾…ç”¨æˆ·ç¡®è®¤
            self._schedule_acknowledgment_check(message_id)
            
        elif status == 'acknowledged':
            # ç”¨æˆ·å·²ç¡®è®¤ï¼Œå–æ¶ˆåç»­å‡çº§
            self._cancel_escalation(message_id)
            
        elif status == 'failed':
            # æŠ•é€’å¤±è´¥ï¼Œå°è¯•å¤‡é€‰æ¸ é“
            self._trigger_fallback_delivery(message_id, metadata)
            
        elif status == 'escalated':
            # å‡çº§åˆ°ä¸‹ä¸€çº§ï¼Œè®°å½•å‡çº§åŸå› 
            self._log_escalation(message_id, metadata)
```

### 4. è‡ªåŠ¨åŒ–å¤„ç†æœºåˆ¶å‡çº§

#### 4.1 æ™ºèƒ½è‡ªåŠ¨ç¡®è®¤å¼•æ“
```python
class AutoAcknowledgeEngine:
    """æ™ºèƒ½è‡ªåŠ¨ç¡®è®¤å¼•æ“"""
    
    def __init__(self):
        self.pattern_recognizer = PatternRecognizer()
        self.safety_checker = SafetyChecker()
        self.ml_classifier = MLFalsePositiveClassifier()
        
    def evaluate_auto_acknowledge(self, alert):
        """è¯„ä¼°æ˜¯å¦å¯è‡ªåŠ¨ç¡®è®¤å‘Šè­¦"""
        
        # å®‰å…¨æ£€æŸ¥ - æŸäº›ç±»å‹ç»ä¸è‡ªåŠ¨ç¡®è®¤
        if not self.safety_checker.is_safe_for_auto_ack(alert):
            return {
                'can_auto_ack': False,
                'reason': 'å‘Šè­¦ç±»å‹ä¸å…è®¸è‡ªåŠ¨ç¡®è®¤',
                'safety_level': 'high_risk'
            }
        
        # 1. æ£€æŸ¥åç»­æ•°æ®æ˜¯å¦æ­£å¸¸
        subsequent_normal = self._check_subsequent_data_normal(alert)
        if subsequent_normal['is_normal']:
            return {
                'can_auto_ack': True,
                'reason': 'åç»­æ•°æ®å·²æ¢å¤æ­£å¸¸',
                'confidence': subsequent_normal['confidence'],
                'evidence': subsequent_normal['evidence']
            }
        
        # 2. æ£€æŸ¥å·²çŸ¥è¯¯æŠ¥æ¨¡å¼
        false_positive_check = self._check_false_positive_patterns(alert)
        if false_positive_check['is_false_positive']:
            return {
                'can_auto_ack': True,
                'reason': 'åŒ¹é…å·²çŸ¥è¯¯æŠ¥æ¨¡å¼',
                'confidence': false_positive_check['confidence'],
                'pattern': false_positive_check['pattern_name']
            }
        
        # 3. è®¾å¤‡ç»´æŠ¤æ¨¡å¼æ£€æŸ¥
        maintenance_check = self._check_maintenance_mode(alert)
        if maintenance_check['in_maintenance']:
            return {
                'can_auto_ack': True,
                'reason': 'è®¾å¤‡å¤„äºç»´æŠ¤æ¨¡å¼',
                'maintenance_info': maintenance_check['info']
            }
        
        # 4. æœºå™¨å­¦ä¹ è¯¯æŠ¥è¯†åˆ«
        ml_result = self.ml_classifier.predict_false_positive(alert)
        if ml_result['is_false_positive'] and ml_result['confidence'] > 0.8:
            return {
                'can_auto_ack': True,
                'reason': 'MLæ¨¡å‹è¯†åˆ«ä¸ºè¯¯æŠ¥',
                'confidence': ml_result['confidence'],
                'ml_features': ml_result['key_features']
            }
        
        return {
            'can_auto_ack': False,
            'reason': 'ä¸æ»¡è¶³è‡ªåŠ¨ç¡®è®¤æ¡ä»¶',
            'details': {
                'subsequent_normal': subsequent_normal,
                'false_positive_check': false_positive_check,
                'maintenance_check': maintenance_check,
                'ml_result': ml_result
            }
        }
    
    def _check_subsequent_data_normal(self, alert, check_duration_minutes=10):
        """æ£€æŸ¥åç»­æ•°æ®æ˜¯å¦æ­£å¸¸"""
        
        if not alert.health_id:
            return {'is_normal': False, 'reason': 'æ— å…³è”å¥åº·æ•°æ®'}
        
        # è·å–å‘Šè­¦åçš„å¥åº·æ•°æ®
        from datetime import timedelta
        start_time = alert.alert_timestamp
        end_time = start_time + timedelta(minutes=check_duration_minutes)
        
        subsequent_data = UserHealthData.query.filter(
            UserHealthData.device_sn == alert.device_sn,
            UserHealthData.timestamp.between(start_time, end_time)
        ).order_by(UserHealthData.timestamp).all()
        
        if len(subsequent_data) < 3:  # éœ€è¦è‡³å°‘3ä¸ªæ•°æ®ç‚¹
            return {'is_normal': False, 'reason': 'åç»­æ•°æ®ä¸è¶³'}
        
        # åŸºäºå‘Šè­¦ç±»å‹æ£€æŸ¥ç›¸åº”æŒ‡æ ‡
        if alert.alert_type == 'heart_rate_abnormal':
            return self._check_heart_rate_recovery(subsequent_data)
        elif alert.alert_type == 'blood_pressure_high':
            return self._check_blood_pressure_recovery(subsequent_data)
        
        return {'is_normal': False, 'reason': 'æœªçŸ¥å‘Šè­¦ç±»å‹'}
    
    def _check_false_positive_patterns(self, alert):
        """æ£€æŸ¥å·²çŸ¥è¯¯æŠ¥æ¨¡å¼"""
        
        # æ¨¡å¼1ï¼šè®¾å¤‡åˆšå¯åŠ¨åçš„å¼‚å¸¸è¯»æ•°
        if self._is_device_startup_anomaly(alert):
            return {
                'is_false_positive': True,
                'confidence': 0.9,
                'pattern_name': 'device_startup_anomaly'
            }
        
        # æ¨¡å¼2ï¼šæç«¯ç¯å¢ƒå¯¼è‡´çš„ä¼ æ„Ÿå™¨å¼‚å¸¸
        if self._is_environmental_interference(alert):
            return {
                'is_false_positive': True, 
                'confidence': 0.8,
                'pattern_name': 'environmental_interference'
            }
        
        # æ¨¡å¼3ï¼šç”¨æˆ·è¿åŠ¨çŠ¶æ€ä¸‹çš„è¯¯æŠ¥
        if self._is_exercise_false_positive(alert):
            return {
                'is_false_positive': True,
                'confidence': 0.85,
                'pattern_name': 'exercise_false_positive'  
            }
        
        return {'is_false_positive': False}
    
    def auto_acknowledge_with_logging(self, alert, evaluation_result):
        """æ‰§è¡Œè‡ªåŠ¨ç¡®è®¤å¹¶è®°å½•"""
        
        # æ›´æ–°å‘Šè­¦çŠ¶æ€
        alert.alert_status = 'auto_acknowledged'
        alert.responded_time = datetime.now()
        alert.auto_ack_reason = evaluation_result['reason']
        alert.auto_ack_confidence = evaluation_result.get('confidence', 1.0)
        
        # è®°å½•è‡ªåŠ¨å¤„ç†æ—¥å¿—
        auto_log = AlertActionLog(
            alert_id=alert.id,
            action='auto_acknowledge',
            action_timestamp=datetime.now(),
            action_user='system_auto',
            action_user_id=0,
            details=json.dumps({
                'reason': evaluation_result['reason'],
                'confidence': evaluation_result.get('confidence'),
                'evaluation_details': evaluation_result
            }),
            result='success'
        )
        
        db.session.add(auto_log)
        db.session.commit()
        
        return True
```

#### 4.2 æ‰¹é‡å¤„ç†ç³»ç»Ÿå¢å¼º
```python
class EnhancedBatchProcessor:
    """å¢å¼ºå‹æ‰¹é‡å¤„ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.task_queue = Queue()
        self.worker_pool = ThreadPoolExecutor(max_workers=5)
        self.batch_size = 50
        
    def batch_process_alerts(self, alert_ids, action, processor_info, options=None):
        """æ‰¹é‡å¤„ç†å‘Šè­¦ - å¢å¼ºç‰ˆ"""
        
        if not alert_ids:
            return {'success': False, 'message': 'æ— å‘Šè­¦ID'}
        
        # åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®
        batches = [
            alert_ids[i:i + self.batch_size] 
            for i in range(0, len(alert_ids), self.batch_size)
        ]
        
        results = {
            'total_alerts': len(alert_ids),
            'processed_batches': 0,
            'successful_alerts': 0,
            'failed_alerts': 0,
            'batch_results': [],
            'processing_time': 0,
            'start_time': datetime.now()
        }
        
        try:
            with db.session.begin():
                for batch_idx, batch_ids in enumerate(batches):
                    batch_start_time = time.time()
                    
                    # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
                    batch_result = self._process_alert_batch(
                        batch_ids, action, processor_info, options
                    )
                    
                    batch_end_time = time.time()
                    batch_result['processing_time'] = batch_end_time - batch_start_time
                    batch_result['batch_index'] = batch_idx
                    
                    results['batch_results'].append(batch_result)
                    results['successful_alerts'] += batch_result['successful_count']
                    results['failed_alerts'] += batch_result['failed_count']
                    results['processed_batches'] += 1
                    
                    # å®æ—¶è¿›åº¦æ›´æ–°
                    progress = {
                        'completed_batches': batch_idx + 1,
                        'total_batches': len(batches),
                        'successful_alerts': results['successful_alerts'],
                        'failed_alerts': results['failed_alerts']
                    }
                    self._update_batch_progress(processor_info['session_id'], progress)
                
                results['processing_time'] = (
                    datetime.now() - results['start_time']
                ).total_seconds()
                results['success'] = True
                
        except Exception as e:
            db.session.rollback()
            results['success'] = False
            results['error'] = str(e)
            
        return results
    
    def _process_alert_batch(self, alert_ids, action, processor_info, options):
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        
        batch_result = {
            'alert_ids': alert_ids,
            'successful_count': 0,
            'failed_count': 0,
            'successful_ids': [],
            'failed_ids': [],
            'error_details': []
        }
        
        # æŸ¥è¯¢å¹¶é”å®šå‘Šè­¦è®°å½•
        alerts = AlertInfo.query.filter(
            AlertInfo.id.in_(alert_ids)
        ).with_for_update().all()
        
        # å¤„ç†æ¯ä¸ªå‘Šè­¦
        for alert in alerts:
            try:
                if action == 'acknowledge':
                    result = self._batch_acknowledge_alert(alert, processor_info, options)
                elif action == 'assign':
                    result = self._batch_assign_alert(alert, processor_info, options)
                elif action == 'escalate':
                    result = self._batch_escalate_alert(alert, processor_info, options)
                elif action == 'close':
                    result = self._batch_close_alert(alert, processor_info, options)
                else:
                    raise ValueError(f'æœªçŸ¥æ“ä½œç±»å‹: {action}')
                
                if result['success']:
                    batch_result['successful_count'] += 1
                    batch_result['successful_ids'].append(alert.id)
                else:
                    batch_result['failed_count'] += 1
                    batch_result['failed_ids'].append(alert.id)
                    batch_result['error_details'].append({
                        'alert_id': alert.id,
                        'error': result.get('error', 'æœªçŸ¥é”™è¯¯')
                    })
                    
            except Exception as e:
                batch_result['failed_count'] += 1
                batch_result['failed_ids'].append(alert.id)
                batch_result['error_details'].append({
                    'alert_id': alert.id,
                    'error': str(e)
                })
        
        # æ‰¹é‡åˆ›å»ºæ“ä½œæ—¥å¿—
        self._bulk_create_action_logs(alerts, action, processor_info, batch_result)
        
        return batch_result
    
    def _bulk_create_action_logs(self, alerts, action, processor_info, batch_result):
        """æ‰¹é‡åˆ›å»ºæ“ä½œæ—¥å¿—"""
        
        logs = []
        current_time = datetime.now()
        
        for alert in alerts:
            log_entry = AlertActionLog(
                alert_id=alert.id,
                action=f'batch_{action}',
                action_timestamp=current_time,
                action_user=processor_info['user_name'],
                action_user_id=processor_info['user_id'],
                details=json.dumps({
                    'batch_session': processor_info['session_id'],
                    'batch_size': len(alerts),
                    'processing_options': processor_info.get('options'),
                    'success': alert.id in batch_result['successful_ids']
                }),
                result='success' if alert.id in batch_result['successful_ids'] else 'failed'
            )
            logs.append(log_entry)
        
        # æ‰¹é‡æ’å…¥æ—¥å¿—
        db.session.bulk_save_objects(logs)
```

### 5. ç›‘æ§åˆ†æä¸ä¼˜åŒ–å»ºè®®ç³»ç»Ÿ

#### 5.1 å‘Šè­¦è´¨é‡ç›‘æ§ä»ªè¡¨æ¿
```python
class AlertQualityMonitor:
    """å‘Šè­¦è´¨é‡ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.metrics_calculator = MetricsCalculator()
        self.trend_analyzer = TrendAnalyzer()
        
    def generate_quality_report(self, time_range_hours=24, customer_id=None):
        """ç”Ÿæˆå‘Šè­¦è´¨é‡æŠ¥å‘Š"""
        
        base_query = AlertInfo.query
        if customer_id:
            base_query = base_query.filter(AlertInfo.customer_id == customer_id)
            
        time_filter = datetime.now() - timedelta(hours=time_range_hours)
        alerts = base_query.filter(
            AlertInfo.alert_timestamp >= time_filter
        ).all()
        
        report = {
            'report_period': {
                'start_time': time_filter.isoformat(),
                'end_time': datetime.now().isoformat(),
                'duration_hours': time_range_hours
            },
            'overview': self._calculate_overview_metrics(alerts),
            'quality_metrics': self._calculate_quality_metrics(alerts),
            'performance_metrics': self._calculate_performance_metrics(alerts),
            'trend_analysis': self._analyze_trends(alerts),
            'recommendations': self._generate_recommendations(alerts)
        }
        
        return report
    
    def _calculate_quality_metrics(self, alerts):
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        
        total_alerts = len(alerts)
        if total_alerts == 0:
            return {}
        
        # åˆ†æå·²å¤„ç†å‘Šè­¦çš„åç»­éªŒè¯
        processed_alerts = [a for a in alerts if a.alert_status == 'responded']
        false_positive_count = self._estimate_false_positives(processed_alerts)
        
        # è®¡ç®—å“åº”æ—¶é—´åˆ†å¸ƒ
        response_times = []
        for alert in processed_alerts:
            if alert.responded_time and alert.alert_timestamp:
                response_time = (alert.responded_time - alert.alert_timestamp).total_seconds() / 60
                response_times.append(response_time)
        
        # å‡çº§ç‡è®¡ç®—
        escalated_alerts = [a for a in alerts if a.escalation_level > 0]
        escalation_rate = len(escalated_alerts) / total_alerts if total_alerts > 0 else 0
        
        return {
            'false_positive_rate': false_positive_count / total_alerts if total_alerts > 0 else 0,
            'false_positive_count': false_positive_count,
            'avg_response_time_minutes': np.mean(response_times) if response_times else 0,
            'median_response_time_minutes': np.median(response_times) if response_times else 0,
            'response_time_95th_percentile': np.percentile(response_times, 95) if response_times else 0,
            'escalation_rate': escalation_rate,
            'escalated_count': len(escalated_alerts),
            'auto_resolve_rate': self._calculate_auto_resolve_rate(alerts),
            'priority_distribution': self._calculate_priority_distribution(alerts)
        }
    
    def _generate_recommendations(self, alerts):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        
        recommendations = []
        metrics = self._calculate_quality_metrics(alerts)
        
        # è¯¯æŠ¥ç‡å»ºè®®
        if metrics.get('false_positive_rate', 0) > 0.15:
            recommendations.append({
                'type': 'rule_optimization',
                'priority': 'high',
                'title': 'é™ä½è¯¯æŠ¥ç‡',
                'description': f'è¯¯æŠ¥ç‡{metrics["false_positive_rate"]:.1%}åé«˜ï¼Œå»ºè®®è°ƒæ•´å‘Šè­¦è§„åˆ™é˜ˆå€¼',
                'suggested_actions': [
                    'åˆ†æé«˜è¯¯æŠ¥çš„å‘Šè­¦ç±»å‹å’Œè®¾å¤‡',
                    'è°ƒæ•´ç›¸åº”å‘Šè­¦è§„åˆ™çš„é˜ˆå€¼',
                    'å¯ç”¨æ™ºèƒ½è¿‡æ»¤ç®—æ³•',
                    'å¢åŠ ä¸ªäººåŸºçº¿åˆ†æ'
                ]
            })
        
        # å“åº”æ—¶é—´å»ºè®®
        avg_response = metrics.get('avg_response_time_minutes', 0)
        if avg_response > 30:  # å¹³å‡å“åº”æ—¶é—´è¶…è¿‡30åˆ†é’Ÿ
            recommendations.append({
                'type': 'response_optimization',
                'priority': 'medium',
                'title': 'æå‡å“åº”é€Ÿåº¦',
                'description': f'å¹³å‡å“åº”æ—¶é—´{avg_response:.1f}åˆ†é’Ÿè¾ƒé•¿',
                'suggested_actions': [
                    'ä¼˜åŒ–é€šçŸ¥æ¸ é“é…ç½®',
                    'å¢åŠ è‡ªåŠ¨å¤„ç†è§„åˆ™',
                    'ä¼˜åŒ–äººå‘˜å€¼ç­å®‰æ’',
                    'å¯ç”¨æ™ºèƒ½å‡çº§æœºåˆ¶'
                ]
            })
        
        # å‡çº§ç‡å»ºè®®
        escalation_rate = metrics.get('escalation_rate', 0)
        if escalation_rate > 0.2:  # å‡çº§ç‡è¶…è¿‡20%
            recommendations.append({
                'type': 'escalation_optimization',
                'priority': 'medium', 
                'title': 'å‡å°‘å‘Šè­¦å‡çº§',
                'description': f'å‘Šè­¦å‡çº§ç‡{escalation_rate:.1%}è¾ƒé«˜',
                'suggested_actions': [
                    'å¢å¼ºä¸€çº¿äººå‘˜å¤„ç†èƒ½åŠ›',
                    'ä¼˜åŒ–å‘Šè­¦åˆ†é…ç­–ç•¥',
                    'å®Œå–„å¤„ç†æŒ‡å¯¼æ–‡æ¡£',
                    'è°ƒæ•´å‡çº§æ—¶é—´é˜ˆå€¼'
                ]
            })
        
        return recommendations
```

#### 5.2 é¢„æµ‹åˆ†æç³»ç»Ÿ
```python
class PredictiveAnalytics:
    """å‘Šè­¦é¢„æµ‹åˆ†æç³»ç»Ÿ"""
    
    def __init__(self):
        self.time_series_model = None
        self.anomaly_predictor = None
        self.trained = False
        
    def predict_alert_trends(self, customer_id, prediction_days=7):
        """é¢„æµ‹å‘Šè­¦è¶‹åŠ¿"""
        
        # è·å–å†å²æ•°æ®
        historical_data = self._get_historical_alert_data(customer_id, days=30)
        
        if len(historical_data) < 14:  # éœ€è¦è‡³å°‘2å‘¨æ•°æ®
            return {
                'success': False,
                'message': 'å†å²æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘2å‘¨æ•°æ®è¿›è¡Œé¢„æµ‹'
            }
        
        # æ—¶é—´åºåˆ—é¢„æµ‹
        forecast = self._time_series_forecast(historical_data, prediction_days)
        
        # å¼‚å¸¸æ¨¡å¼è¯†åˆ«
        anomaly_patterns = self._identify_anomaly_patterns(historical_data)
        
        # é£é™©è¯„ä¼°
        risk_assessment = self._assess_future_risks(forecast, anomaly_patterns)
        
        return {
            'success': True,
            'prediction_period': f'{prediction_days}å¤©',
            'forecast': forecast,
            'anomaly_patterns': anomaly_patterns,
            'risk_assessment': risk_assessment,
            'recommendations': self._generate_predictive_recommendations(
                forecast, risk_assessment
            )
        }
    
    def _time_series_forecast(self, historical_data, prediction_days):
        """æ—¶é—´åºåˆ—é¢„æµ‹"""
        
        # æ•°æ®é¢„å¤„ç†
        df = pd.DataFrame(historical_data)
        df['date'] = pd.to_datetime(df['alert_timestamp']).dt.date
        daily_counts = df.groupby(['date', 'severity_level']).size().unstack(fill_value=0)
        
        # ä½¿ç”¨ARIMAæ¨¡å‹è¿›è¡Œé¢„æµ‹
        from statsmodels.tsa.arima.model import ARIMA
        
        forecasts = {}
        for severity in daily_counts.columns:
            try:
                model = ARIMA(daily_counts[severity], order=(1, 1, 1))
                fitted_model = model.fit()
                forecast = fitted_model.forecast(steps=prediction_days)
                forecasts[severity] = forecast.tolist()
            except Exception as e:
                forecasts[severity] = [daily_counts[severity].mean()] * prediction_days
        
        # ç”Ÿæˆé¢„æµ‹æ—¥æœŸ
        last_date = daily_counts.index[-1]
        future_dates = pd.date_range(
            start=last_date + pd.Timedelta(days=1),
            periods=prediction_days,
            freq='D'
        ).strftime('%Y-%m-%d').tolist()
        
        return {
            'dates': future_dates,
            'predicted_counts': forecasts,
            'total_predicted': [
                sum(forecasts[sev][i] for sev in forecasts.keys())
                for i in range(prediction_days)
            ]
        }
    
    def _assess_future_risks(self, forecast, anomaly_patterns):
        """è¯„ä¼°æœªæ¥é£é™©"""
        
        total_predicted = forecast['total_predicted']
        avg_daily_alerts = np.mean(total_predicted)
        
        # é£é™©çº§åˆ«è¯„ä¼°
        if avg_daily_alerts > 100:
            risk_level = 'high'
            risk_description = 'é¢„æµ‹å‘Šè­¦é‡è¾ƒé«˜ï¼Œéœ€è¦æå‰å‡†å¤‡å¤„ç†èµ„æº'
        elif avg_daily_alerts > 50:
            risk_level = 'medium' 
            risk_description = 'é¢„æµ‹å‘Šè­¦é‡é€‚ä¸­ï¼Œå»ºè®®ä¿æŒå½“å‰å¤„ç†èƒ½åŠ›'
        else:
            risk_level = 'low'
            risk_description = 'é¢„æµ‹å‘Šè­¦é‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘èµ„æºä¼˜åŒ–è°ƒé…'
        
        # è¯†åˆ«é«˜é£é™©æ—¥æœŸ
        high_risk_dates = []
        for i, count in enumerate(total_predicted):
            if count > avg_daily_alerts * 1.5:  # è¶…è¿‡å¹³å‡å€¼50%
                high_risk_dates.append({
                    'date': forecast['dates'][i],
                    'predicted_count': count,
                    'risk_factor': count / avg_daily_alerts
                })
        
        return {
            'overall_risk_level': risk_level,
            'risk_description': risk_description,
            'avg_daily_predicted': avg_daily_alerts,
            'high_risk_dates': high_risk_dates,
            'capacity_recommendations': self._generate_capacity_recommendations(
                avg_daily_alerts, high_risk_dates
            )
        }
```

---

## ğŸ› ï¸ å®æ–½è·¯çº¿å›¾

### Phase 1: åŸºç¡€ä¼˜åŒ– (2-3å‘¨)
1. **Priorityå­—æ®µå®ç°**
   - æ•°æ®åº“å­—æ®µæ·»åŠ 
   - åŸºç¡€è®¡ç®—ç®—æ³•å®ç°
   - ç°æœ‰æ•°æ®è¿ç§»

2. **æ¶ˆæ¯å»é‡ä¼˜åŒ–**
   - å®ç°æ™ºèƒ½æ¶ˆæ¯é˜Ÿåˆ—
   - æ·»åŠ å»é‡æœºåˆ¶
   - ä¼˜åŒ–æ‰¹é‡å¤„ç†

### Phase 2: æ™ºèƒ½åŒ–å‡çº§ (3-4å‘¨)
1. **æ™ºèƒ½è§„åˆ™å¼•æ“**
   - å¤šç»´åº¦åˆ†æç®—æ³•
   - ä¸ªäººåŸºçº¿å­¦ä¹ 
   - MLå¼‚å¸¸æ£€æµ‹

2. **é€šçŸ¥ç­–ç•¥ä¼˜åŒ–**
   - æ™ºèƒ½é€šçŸ¥ç­–ç•¥
   - ç”¨æˆ·åå¥½ç®¡ç†
   - å‡çº§é“¾ä¼˜åŒ–

### Phase 3: ç›‘æ§ä¸é¢„æµ‹ (2-3å‘¨)
1. **è´¨é‡ç›‘æ§ç³»ç»Ÿ**
   - å‘Šè­¦è´¨é‡ä»ªè¡¨æ¿
   - æ€§èƒ½æŒ‡æ ‡ç›‘æ§
   - ä¼˜åŒ–å»ºè®®å¼•æ“

2. **é¢„æµ‹åˆ†æç³»ç»Ÿ**
   - è¶‹åŠ¿é¢„æµ‹ç®—æ³•
   - é£é™©è¯„ä¼°æ¨¡å‹
   - å®¹é‡è§„åˆ’å»ºè®®

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### é‡åŒ–æŒ‡æ ‡æ”¹å–„ç›®æ ‡
- **è¯¯æŠ¥ç‡é™ä½**: ä»å½“å‰15-20% é™ä½åˆ° < 8%
- **å“åº”æ—¶é—´æå‡**: å¹³å‡å“åº”æ—¶é—´ä»30åˆ†é’Ÿé™ä½åˆ° < 15åˆ†é’Ÿ  
- **å¤„ç†æ•ˆç‡æå‡**: è‡ªåŠ¨å¤„ç†æ¯”ä¾‹ä»20%æå‡åˆ°50%
- **ç”¨æˆ·æ»¡æ„åº¦**: å‘Šè­¦å¤„ç†æ»¡æ„åº¦ä»80%æå‡åˆ°95%

### æŠ€æœ¯æŒ‡æ ‡æ”¹å–„
- **ç³»ç»Ÿæ€§èƒ½**: å‘Šè­¦å¤„ç†ååé‡æå‡200%
- **å¯æ‰©å±•æ€§**: æ”¯æŒ10ä¸‡+è®¾å¤‡å¹¶å‘å‘Šè­¦å¤„ç†
- **å¯é æ€§**: å‘Šè­¦ä¸¢å¤±ç‡ < 0.1%
- **æ™ºèƒ½åŒ–**: 70%çš„å‘Šè­¦æ”¯æŒæ™ºèƒ½åˆ†æå’Œå¤„ç†

---

## ğŸ”§ æŠ€æœ¯å®æ–½æ³¨æ„äº‹é¡¹

### 1. æ•°æ®è¿ç§»ç­–ç•¥
- åˆ†æ‰¹è¿ç§»ç°æœ‰å‘Šè­¦æ•°æ®
- ä¿æŒç³»ç»ŸæœåŠ¡å¯ç”¨æ€§
- å®Œæ•´çš„å›æ»šæ–¹æ¡ˆ

### 2. å…¼å®¹æ€§ä¿è¯
- å‘åå…¼å®¹ç°æœ‰API
- æ¸è¿›å¼åŠŸèƒ½ä¸Šçº¿
- A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

### 3. æ€§èƒ½ç›‘æ§
- å®æ—¶æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- å‘Šè­¦å¤„ç†é“¾è·¯è¿½è¸ª
- å®¹é‡é¢„è­¦æœºåˆ¶

è¿™ä»½ä¼˜åŒ–æ–¹æ¡ˆå°†å‘Šè­¦æœºåˆ¶ä»è¢«åŠ¨å“åº”å‡çº§ä¸ºä¸»åŠ¨é¢„é˜²çš„æ™ºèƒ½ç³»ç»Ÿï¼Œå¤§å¹…æå‡å‘Šè­¦å¤„ç†çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚