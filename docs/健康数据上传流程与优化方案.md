# å¥åº·æ•°æ®ä¸Šä¼ æµç¨‹åˆ†æä¸5000+å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆ

## 1. å½“å‰æ•°æ®æµæ¶æ„åˆ†æ

### 1.1 æ•´ä½“æ•°æ®æµå‘

```mermaid
graph TB
    A[ljwx-watch è®¾å¤‡æ•°æ®é‡‡é›†] -->|upload_health_data POST| B[ljwx-bigscreen æ•°æ®æ¥æ”¶]
    B --> C[HealthDataOptimizer é˜Ÿåˆ—å¤„ç†]
    C --> D[æ‰¹é‡æ•°æ®åº“å†™å…¥]
    C --> E[æ‰¹é‡å‘Šè­¦æ£€æµ‹]
    D --> F[ljwx-boot å®šæ—¶ä»»åŠ¡å¤„ç†]
    F --> G[ç”Ÿæˆå¥åº·åŸºçº¿ baseline]
    F --> H[ç”Ÿæˆå¥åº·è¯„åˆ† score]
    F --> I[ç”Ÿæˆå¥åº·ç”»åƒ profile]
    G --> J[ljwx-bigscreen å¤§å±å±•ç¤º]
    H --> J
    I --> J
    J --> K[ä¸ªäººå¥åº·é¡µé¢å±•ç¤º]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style F fill:#e8f5e8
    style J fill:#fff8e1
```

### 1.2 æ ¸å¿ƒç»„ä»¶åŠŸèƒ½åˆ†æ

#### ljwx-watch (æ•°æ®é‡‡é›†ç«¯)
- **åŠŸèƒ½**: ä»æ™ºèƒ½ç©¿æˆ´è®¾å¤‡é‡‡é›†å¥åº·æ•°æ®
- **æ•°æ®æ ¼å¼**: JSONæ ¼å¼åŒ…å«å¿ƒç‡ã€è¡€æ°§ã€è¡€å‹ã€ä½“æ¸©ã€æ­¥æ•°ç­‰æŒ‡æ ‡
- **ä¸Šä¼ æ–¹å¼**: HTTP POSTè¯·æ±‚åˆ°ljwx-bigscreençš„`/upload_health_data`æ¥å£
- **å½“å‰èƒ½åŠ›**: æ”¯æŒå•è®¾å¤‡æ•°æ®é‡‡é›†å’Œä¸Šä¼ 

#### ljwx-bigscreen (æ•°æ®å¤„ç†å¼•æ“)
- **æ¥æ”¶æ¨¡å—**: Flaskåº”ç”¨æ¥æ”¶å¥åº·æ•°æ®HTTPè¯·æ±‚
- **æ ¸å¿ƒç»„ä»¶**: `HealthDataOptimizer V4.0` - CPUè‡ªé€‚åº”æ‰¹å¤„ç†ä¼˜åŒ–å™¨
  - **æ‰¹å¤„ç†æœºåˆ¶**: åŸºäºCPUæ ¸å¿ƒæ•°åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°(æ ¸å¿ƒæ•°Ã—25ï¼Œé™åˆ¶50-500)
  - **çº¿ç¨‹æ± é…ç½®**: CPUæ ¸å¿ƒæ•°Ã—2.5ä¸ªå·¥ä½œçº¿ç¨‹(é™åˆ¶4-32)
  - **é˜Ÿåˆ—å®¹é‡**: 5000æ¡è®°å½•çš„æ‰¹å¤„ç†é˜Ÿåˆ—
  - **æ€§èƒ½ç›‘æ§**: å®æ—¶æ€§èƒ½çª—å£å’Œè‡ªåŠ¨è°ƒä¼˜æœºåˆ¶
- **æ•°æ®å¤„ç†æµç¨‹**:
  1. æ•°æ®éªŒè¯å’Œå­—æ®µæ˜ å°„
  2. è®¾å¤‡ç”¨æˆ·å…³ç³»æŸ¥è¯¢
  3. é‡å¤æ•°æ®æ£€æµ‹
  4. æ‰¹é‡æ•°æ®åº“æ’å…¥
  5. æ‰¹é‡å‘Šè­¦è§„åˆ™åŒ¹é…
- **å‘Šè­¦å¤„ç†**: é›†æˆæ™ºèƒ½å‘Šè­¦ç³»ç»Ÿï¼Œæ”¯æŒå¾®ä¿¡ã€çŸ­ä¿¡ç­‰å¤šæ¸ é“æ¨é€

#### ljwx-boot (åå°ä»»åŠ¡è°ƒåº¦)
- **å®šæ—¶ä»»åŠ¡ä½“ç³»**: åŸºäºSpring Boot Schedulerçš„8ä¸ªæ ¸å¿ƒä»»åŠ¡
  1. **00:00** - æŒ‰æœˆåˆ†è¡¨å½’æ¡£ä»»åŠ¡
  2. **02:00** - ç”Ÿæˆç”¨æˆ·å¥åº·åŸºçº¿
  3. **02:05** - ç”Ÿæˆéƒ¨é—¨å¥åº·åŸºçº¿èšåˆ(åŸºäºé—­åŒ…è¡¨)
  4. **02:10** - ç”Ÿæˆç»„ç»‡å¥åº·åŸºçº¿
  5. **02:15** - ç”Ÿæˆéƒ¨é—¨å¥åº·è¯„åˆ†
  6. **04:00** - ç”Ÿæˆç”¨æˆ·å¥åº·è¯„åˆ†
  7. **04:10** - ç”Ÿæˆç»„ç»‡å¥åº·è¯„åˆ†  
  8. **05:00** - æ•°æ®æ¸…ç†ä»»åŠ¡
- **é—­åŒ…è¡¨ä¼˜åŒ–**: åˆ©ç”¨`sys_org_closure`è¡¨å®ç°O(1)å¤æ‚åº¦çš„ç»„ç»‡æŸ¥è¯¢
- **å¤šè¡¨æ”¯æŒ**: æ”¯æŒä¸»è¡¨+åˆ†è¡¨çš„å¥åº·æ•°æ®æŸ¥è¯¢å’Œèšåˆ

#### ljwx-bigscreen å¤§å±å±•ç¤º
- **ä¸»è¦é¡µé¢**:
  - `bigscreen_main.html` - ç»¼åˆå¥åº·ç›‘æ§å¤§å±
  - `personal.html` - ä¸ªäººå¥åº·è¯¦æƒ…é¡µé¢
- **å±•ç¤ºæ•°æ®**:
  - å¥åº·åŸºçº¿è¶‹åŠ¿å›¾
  - å¥åº·è¯„åˆ†æ’è¡Œ
  - ä¸ªäººå¥åº·ç”»åƒ
  - å®æ—¶å‘Šè­¦ä¿¡æ¯

### 1.3 å½“å‰æ€§èƒ½æŒ‡æ ‡

- **æ‰¹å¤„ç†èƒ½åŠ›**: 50-500æ¡è®°å½•/æ‰¹æ¬¡
- **å¹¶å‘çº¿ç¨‹**: 4-32ä¸ªå·¥ä½œçº¿ç¨‹(CPUè‡ªé€‚åº”)
- **é˜Ÿåˆ—å®¹é‡**: 5000æ¡è®°å½•
- **ç›®æ ‡QPS**: 200æ¬¡/ç§’(é…ç½®ä¸­)
- **æ•°æ®åº“è¿æ¥æ± **: 20åŸºç¡€è¿æ¥+30æº¢å‡ºè¿æ¥

## 2. å½“å‰æ¶æ„çš„æ€§èƒ½ç“¶é¢ˆåˆ†æ

### 2.1 ä¸»è¦ç“¶é¢ˆè¯†åˆ«

#### æ•°æ®åº“å±‚ç“¶é¢ˆ
- **è¿æ¥æ± é™åˆ¶**: å½“å‰50ä¸ªæœ€å¤§è¿æ¥åœ¨5000+å¹¶å‘ä¸‹ä¸¥é‡ä¸è¶³
- **å†™å…¥æ€§èƒ½**: å•è¡¨å†™å…¥åœ¨é«˜å¹¶å‘ä¸‹å­˜åœ¨é”ç«äº‰
- **æŸ¥è¯¢ä¼˜åŒ–**: è®¾å¤‡ç”¨æˆ·å…³ç³»æŸ¥è¯¢å¯èƒ½æˆä¸ºçƒ­ç‚¹

#### åº”ç”¨å±‚ç“¶é¢ˆ  
- **å•å®ä¾‹å¤„ç†**: å½“å‰ljwx-bigscreenä¸ºå•å®ä¾‹éƒ¨ç½²
- **å†…å­˜é™åˆ¶**: 5000é˜Ÿåˆ—å®¹é‡åœ¨æé«˜å¹¶å‘ä¸‹å¯èƒ½æº¢å‡º
- **GILé™åˆ¶**: Pythonå…¨å±€è§£é‡Šå™¨é”é™åˆ¶çœŸæ­£çš„å¹¶è¡Œå¤„ç†

#### ç½‘ç»œå±‚ç“¶é¢ˆ
- **HTTPè¿æ¥**: å¤§é‡å¹¶å‘HTTPè¿æ¥å¯èƒ½å¯¼è‡´ç«¯å£è€—å°½
- **æ•°æ®ä¼ è¾“**: JSONæ ¼å¼åœ¨é«˜é¢‘ä¼ è¾“ä¸‹å¸¦å®½å ç”¨è¾ƒå¤§

### 2.2 ç°æœ‰ä¼˜åŒ–æªæ–½è¯„ä¼°

#### å·²å®ç°ä¼˜åŒ–
âœ… **CPUè‡ªé€‚åº”æ‰¹å¤„ç†** - æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨è°ƒä¼˜  
âœ… **é—­åŒ…è¡¨ç»„ç»‡æŸ¥è¯¢** - 100å€æŸ¥è¯¢æ€§èƒ½æå‡  
âœ… **Redisç¼“å­˜æœºåˆ¶** - å‡å°‘æ•°æ®åº“æŸ¥è¯¢å‹åŠ›  
âœ… **å¼‚æ­¥å‘Šè­¦å¤„ç†** - éé˜»å¡å‘Šè­¦æ¨é€  
âœ… **é‡å¤æ•°æ®æ£€æµ‹** - é¿å…é‡å¤å†™å…¥  

#### ä¼˜åŒ–æ•ˆæœæœ‰é™çš„æªæ–½
âš ï¸ **çº¿ç¨‹æ± æ‰©å±•** - å—Python GILé™åˆ¶ï¼Œå®é™…å¹¶è¡Œåº¦æœ‰é™  
âš ï¸ **æ‰¹å¤„ç†ä¼˜åŒ–** - åœ¨æé«˜å¹¶å‘ä¸‹ä»å¯èƒ½é€ æˆç§¯å‹  
âš ï¸ **å•å®ä¾‹ä¼˜åŒ–** - æ— æ³•çªç ´å•æœºæ€§èƒ½ä¸Šé™  

## 3. 5000+å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆè®¾è®¡

### 3.1 æ¶æ„å‡çº§æ–¹æ¡ˆ

#### æ–¹æ¡ˆä¸€ï¼šå¾®æœåŠ¡é›†ç¾¤æ¶æ„ (æ¨è)

```mermaid
graph TB
    A[è´Ÿè½½å‡è¡¡å™¨ Nginx] --> B[ljwx-bigscreen å®ä¾‹1]
    A --> C[ljwx-bigscreen å®ä¾‹2] 
    A --> D[ljwx-bigscreen å®ä¾‹3]
    A --> E[ljwx-bigscreen å®ä¾‹N]
    
    B --> F[Redis é›†ç¾¤]
    C --> F
    D --> F
    E --> F
    
    B --> G[MySQL ä¸»ä»é›†ç¾¤]
    C --> G
    D --> G
    E --> G
    
    F --> H[æ¶ˆæ¯é˜Ÿåˆ— RabbitMQ]
    H --> I[å‘Šè­¦å¤„ç†æœåŠ¡]
    H --> J[æ•°æ®åˆ†ææœåŠ¡]
    
    G --> K[ljwx-boot å®šæ—¶ä»»åŠ¡]
    K --> L[åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦]
```

**æ ¸å¿ƒæ”¹è¿›**:
- **æ°´å¹³æ‰©å±•**: æ”¯æŒNä¸ªljwx-bigscreenå®ä¾‹
- **è´Ÿè½½å‡è¡¡**: Nginxå®ç°è¯·æ±‚åˆ†å‘å’Œæ•…éšœè½¬ç§»
- **æ•°æ®åº“é›†ç¾¤**: MySQLä¸€ä¸»å¤šä»ï¼Œè¯»å†™åˆ†ç¦»
- **ç¼“å­˜é›†ç¾¤**: Redis Clusteræä¾›é«˜å¯ç”¨ç¼“å­˜
- **æ¶ˆæ¯é˜Ÿåˆ—**: RabbitMQè§£è€¦æ•°æ®å¤„ç†å’Œä¸šåŠ¡é€»è¾‘

#### æ–¹æ¡ˆäºŒï¼šæµå¼å¤„ç†æ¶æ„

```mermaid
graph TB
    A[æ•°æ®æ¥å…¥å±‚] --> B[Apache Kafka]
    B --> C[Kafka Streams / Flink]
    C --> D[å®æ—¶æ•°æ®å¤„ç†]
    C --> E[æ‰¹é‡æ•°æ®å†™å…¥]
    D --> F[ClickHouse æ—¶åºæ•°æ®åº“]
    E --> G[MySQL ä¸šåŠ¡æ•°æ®åº“]
    F --> H[å®æ—¶å¤§å±å±•ç¤º]
    G --> I[ljwx-boot å®šæ—¶ä»»åŠ¡]
```

**æ ¸å¿ƒæ”¹è¿›**:
- **æµå¼æ¶æ„**: Kafka+Flinkå®ç°çœŸæ­£çš„å®æ—¶æµå¤„ç†  
- **æ—¶åºæ•°æ®åº“**: ClickHouseä¸“é—¨ä¼˜åŒ–æ—¶åºæ•°æ®æŸ¥è¯¢æ€§èƒ½
- **æ•°æ®åˆ†å±‚**: çƒ­æ•°æ®å’Œå†·æ•°æ®åˆ†ç¦»å­˜å‚¨
- **äº‹ä»¶é©±åŠ¨**: åŸºäºäº‹ä»¶æµçš„æ¾è€¦åˆæ¶æ„

### 3.2 å…·ä½“ä¼˜åŒ–æªæ–½

#### 3.2.1 æ•°æ®æ¥å…¥å±‚ä¼˜åŒ–

**HTTPæ¥å…¥ä¼˜åŒ–**
```python
# ä½¿ç”¨å¼‚æ­¥æ¡†æ¶ FastAPI æ›¿æ¢ Flask
from fastapi import FastAPI
from pydantic import BaseModel
import asyncio
import aioredis
import aiomysql

app = FastAPI()

class HealthDataBatch(BaseModel):
    devices: List[HealthData]  # æ”¯æŒæ‰¹é‡ä¸Šä¼ 

@app.post("/upload_health_data_batch")
async def upload_batch(batch: HealthDataBatch):
    # å¼‚æ­¥æ‰¹é‡å¤„ç†
    tasks = [process_health_data(data) for data in batch.devices]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return {"processed": len(results), "errors": sum(1 for r in results if isinstance(r, Exception))}
```

**è¿æ¥æ± ä¼˜åŒ–**
```python
# æ•°æ®åº“è¿æ¥æ± é…ç½®
DB_POOL_CONFIG = {
    'pool_size': 100,          # åŸºç¡€è¿æ¥æ±  100
    'max_overflow': 200,       # æœ€å¤§æº¢å‡º 200  
    'pool_timeout': 5,         # è¿æ¥è¶…æ—¶ 5ç§’
    'pool_recycle': 1800,      # è¿æ¥å›æ”¶ 30åˆ†é’Ÿ
    'pool_pre_ping': True,     # é¢„æ£€æŸ¥è¿æ¥
}

# Redis è¿æ¥æ± 
REDIS_POOL_CONFIG = {
    'max_connections': 500,    # æœ€å¤§è¿æ¥ 500
    'retry_on_timeout': True,  # è¶…æ—¶é‡è¯•
    'socket_keepalive': True,  # ä¿æŒè¿æ¥
}
```

#### 3.2.2 æ•°æ®å¤„ç†å±‚ä¼˜åŒ–

**æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ**
```python
# ä½¿ç”¨ RabbitMQ å®ç°å¼‚æ­¥å¤„ç†
import pika
import json

class HealthDataProcessor:
    def __init__(self):
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters('localhost'))
        self.channel = self.connection.channel()
        
        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue='health_data', durable=True)
        self.channel.queue_declare(queue='alert_processing', durable=True)
        
    def publish_health_data(self, data):
        """å‘å¸ƒå¥åº·æ•°æ®åˆ°é˜Ÿåˆ—"""
        self.channel.basic_publish(
            exchange='',
            routing_key='health_data',
            body=json.dumps(data),
            properties=pika.BasicProperties(delivery_mode=2)  # æŒä¹…åŒ–
        )
        
    def consume_health_data(self):
        """æ¶ˆè´¹å¥åº·æ•°æ®é˜Ÿåˆ—"""
        def callback(ch, method, properties, body):
            try:
                data = json.loads(body)
                self.process_single_record(data)
                ch.basic_ack(delivery_tag=method.delivery_tag)
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {e}")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
                
        self.channel.basic_qos(prefetch_count=100)  # æ¯æ¬¡å¤„ç†100æ¡
        self.channel.basic_consume(queue='health_data', on_message_callback=callback)
        self.channel.start_consuming()
```

**æ‰¹é‡å†™å…¥ä¼˜åŒ–**
```python
class OptimizedBatchWriter:
    def __init__(self, batch_size=1000):
        self.batch_size = batch_size
        self.batch_data = []
        
    async def bulk_insert_optimized(self, data_list):
        """ä¼˜åŒ–çš„æ‰¹é‡æ’å…¥"""
        # ä½¿ç”¨ INSERT IGNORE é¿å…é‡å¤æ’å…¥
        sql = """
        INSERT IGNORE INTO t_user_health_data 
        (user_id, device_sn, heart_rate, blood_oxygen, temperature, 
         pressure_high, pressure_low, stress, step, distance, calorie, 
         latitude, longitude, sleep, timestamp, customer_id, org_id, create_time)
        VALUES %s
        """
        
        # æ„é€ æ‰¹é‡æ•°æ®
        values = []
        for data in data_list:
            values.append(tuple(data.values()))
            
        # ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥
        async with self.get_async_connection() as conn:
            async with conn.cursor() as cursor:
                affected_rows = await cursor.executemany(sql, values)
                await conn.commit()
                return affected_rows
```

#### 3.2.3 æ•°æ®åº“ä¼˜åŒ–

**åˆ†è¡¨ç­–ç•¥**
```sql
-- æŒ‰è®¾å¤‡åˆ†è¡¨ç­–ç•¥
CREATE TABLE t_user_health_data_device_001 (
    -- ç›¸åŒç»“æ„
) PARTITION BY RANGE (UNIX_TIMESTAMP(timestamp)) (
    PARTITION p2025_01 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01')),
    PARTITION p2025_02 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01')),
    -- ç»§ç»­æŒ‰æœˆåˆ†åŒº
);

-- åˆ›å»ºè®¾å¤‡è·¯ç”±è¡¨
CREATE TABLE device_routing (
    device_sn VARCHAR(64) PRIMARY KEY,
    table_suffix VARCHAR(10) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**ç´¢å¼•ä¼˜åŒ–**
```sql
-- é’ˆå¯¹é«˜å¹¶å‘æŸ¥è¯¢çš„å¤åˆç´¢å¼•
CREATE INDEX idx_device_timestamp ON t_user_health_data (device_sn, timestamp DESC);
CREATE INDEX idx_user_timestamp ON t_user_health_data (user_id, timestamp DESC);
CREATE INDEX idx_customer_org_time ON t_user_health_data (customer_id, org_id, timestamp DESC);

-- è¦†ç›–ç´¢å¼•å‡å°‘å›è¡¨æŸ¥è¯¢
CREATE INDEX idx_cover_basic_info ON t_user_health_data (device_sn, timestamp) 
INCLUDE (user_id, heart_rate, blood_oxygen, temperature);
```

#### 3.2.4 ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

**å¤šçº§ç¼“å­˜æ¶æ„**
```python
class MultiLevelCache:
    def __init__(self):
        # L1: æœ¬åœ°å†…å­˜ç¼“å­˜ (æœ€å¿«)
        self.l1_cache = {}
        self.l1_max_size = 10000
        
        # L2: Redis ç¼“å­˜ (å¿«é€Ÿ)
        self.redis = aioredis.Redis()
        
        # L3: æ•°æ®åº“ (æœ€æ…¢ä½†æƒå¨)
        self.db = AsyncDatabase()
        
    async def get_device_user_mapping(self, device_sn):
        """è®¾å¤‡ç”¨æˆ·æ˜ å°„æŸ¥è¯¢ - ä¸‰çº§ç¼“å­˜"""
        
        # L1: å†…å­˜ç¼“å­˜æŸ¥è¯¢
        if device_sn in self.l1_cache:
            return self.l1_cache[device_sn]
            
        # L2: Redis ç¼“å­˜æŸ¥è¯¢  
        cached = await self.redis.get(f"device_user:{device_sn}")
        if cached:
            user_info = json.loads(cached)
            self.l1_cache[device_sn] = user_info
            return user_info
            
        # L3: æ•°æ®åº“æŸ¥è¯¢
        user_info = await self.db.query_device_user(device_sn)
        if user_info:
            # å†™å…¥å„çº§ç¼“å­˜
            await self.redis.setex(f"device_user:{device_sn}", 3600, json.dumps(user_info))
            self.l1_cache[device_sn] = user_info
            
        return user_info
```

### 3.3 ç³»ç»Ÿç›‘æ§å’Œè¿ç»´ä¼˜åŒ–

#### 3.3.1 æ€§èƒ½ç›‘æ§ä½“ç³»

```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'requests_per_second': 0,
            'average_response_time': 0,
            'error_rate': 0,
            'queue_depth': 0,
            'database_connections': 0,
            'memory_usage': 0,
            'cpu_usage': 0
        }
        
    async def collect_metrics(self):
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        while True:
            # æ”¶é›†å„é¡¹æŒ‡æ ‡
            self.metrics['requests_per_second'] = await self.get_rps()
            self.metrics['queue_depth'] = await self.get_queue_depth()
            self.metrics['error_rate'] = await self.get_error_rate()
            
            # è‡ªåŠ¨æ‰©ç¼©å®¹è§¦å‘
            if self.metrics['requests_per_second'] > 4000:
                await self.trigger_scale_up()
            elif self.metrics['requests_per_second'] < 1000:
                await self.trigger_scale_down()
                
            await asyncio.sleep(10)  # 10ç§’ç›‘æ§ä¸€æ¬¡
```

#### 3.3.2 æ•…éšœæ¢å¤æœºåˆ¶

```python
class CircuitBreaker:
    """ç†”æ–­å™¨æ¨¡å¼ - é˜²æ­¢ç³»ç»Ÿé›ªå´©"""
    def __init__(self, failure_threshold=5, recovery_timeout=60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
        
    async def call(self, func, *args, **kwargs):
        if self.state == 'OPEN':
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = 'HALF_OPEN'
            else:
                raise Exception("Circuit breaker is OPEN")
                
        try:
            result = await func(*args, **kwargs)
            if self.state == 'HALF_OPEN':
                self.state = 'CLOSED'
                self.failure_count = 0
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = 'OPEN'
            raise e
```

## 4. ä¼˜åŒ–æ–¹æ¡ˆå®æ–½è·¯çº¿å›¾

### 4.1 ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¼˜åŒ– (1-2å‘¨)

**ç›®æ ‡**: æå‡è‡³2000å¹¶å‘
- âœ… å‡çº§æ•°æ®åº“è¿æ¥æ± é…ç½®  
- âœ… ä¼˜åŒ–æ‰¹å¤„ç†å‚æ•°
- âœ… å®æ–½Redisç¼“å­˜ç­–ç•¥
- âœ… æ·»åŠ åŸºç¡€ç›‘æ§æŒ‡æ ‡

### 4.2 ç¬¬äºŒé˜¶æ®µï¼šæ¶æ„ä¼˜åŒ– (3-4å‘¨)

**ç›®æ ‡**: æå‡è‡³3500å¹¶å‘  
- ğŸ”„ éƒ¨ç½²å¤šå®ä¾‹ljwx-bigscreen
- ğŸ”„ é…ç½®Nginxè´Ÿè½½å‡è¡¡
- ğŸ”„ å®æ–½MySQLè¯»å†™åˆ†ç¦»
- ğŸ”„ é›†æˆRabbitMQå¼‚æ­¥å¤„ç†

### 4.3 ç¬¬ä¸‰é˜¶æ®µï¼šé«˜å¹¶å‘ä¼˜åŒ– (4-6å‘¨)

**ç›®æ ‡**: æ”¯æŒ5000+å¹¶å‘
- ğŸ†• å¼•å…¥ClickHouseæ—¶åºæ•°æ®åº“
- ğŸ†• å®æ–½æ•°æ®åˆ†è¡¨ç­–ç•¥  
- ğŸ†• éƒ¨ç½²Redisé›†ç¾¤
- ğŸ†• å®Œå–„ç›‘æ§å’Œè¿ç»´ä½“ç³»

### 4.4 ç¬¬å››é˜¶æ®µï¼šæé™ä¼˜åŒ– (6-8å‘¨)

**ç›®æ ‡**: æ”¯æŒ10000+å¹¶å‘
- ğŸš€ å¼•å…¥Apache Kafkaæµå¼å¤„ç†
- ğŸš€ å®æ–½å¾®æœåŠ¡æ¶æ„æ‹†åˆ†
- ğŸš€ éƒ¨ç½²Kuberneteså®¹å™¨åŒ–
- ğŸš€ å»ºç«‹è‡ªåŠ¨æ‰©ç¼©å®¹æœºåˆ¶

## 5. æ€§èƒ½æµ‹è¯•éªŒè¯æ–¹æ¡ˆ

### 5.1 å‹æµ‹åœºæ™¯è®¾è®¡

```python
# 5000å¹¶å‘å‹æµ‹è„šæœ¬
class HighConcurrencyTester:
    def __init__(self):
        self.target_url = "http://ljwx-bigscreen/upload_health_data"
        self.concurrent_users = 5000
        self.test_duration = 300  # 5åˆ†é’Ÿ
        
    async def generate_test_data(self):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        return {
            "deviceSn": f"TEST_{random.randint(1, 1000)}",
            "heartRate": random.randint(60, 120),
            "bloodOxygen": random.randint(95, 100),
            "temperature": round(random.uniform(36.0, 37.5), 1),
            "timestamp": int(time.time())
        }
        
    async def run_load_test(self):
        """æ‰§è¡Œè´Ÿè½½æµ‹è¯•"""
        async with aiohttp.ClientSession() as session:
            tasks = []
            for _ in range(self.concurrent_users):
                task = asyncio.create_task(self.send_requests(session))
                tasks.append(task)
                
            results = await asyncio.gather(*tasks, return_exceptions=True)
            return self.analyze_results(results)
```

### 5.2 å…³é”®æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰å€¼ | ä¼˜åŒ–åé¢„æœŸ |
|-----|--------|--------|-----------|
| å¹¶å‘å¤„ç†èƒ½åŠ› | 5000+ req/s | 200 req/s | 6000 req/s |
| å¹³å‡å“åº”æ—¶é—´ | <100ms | ~500ms | <80ms |
| 99%å“åº”æ—¶é—´ | <500ms | ~2000ms | <300ms |
| é”™è¯¯ç‡ | <0.1% | ~2% | <0.05% |
| æ•°æ®åº“è¿æ¥åˆ©ç”¨ç‡ | <80% | ~95% | <60% |
| å†…å­˜ä½¿ç”¨ç‡ | <70% | ~85% | <50% |
| CPUä½¿ç”¨ç‡ | <80% | ~90% | <60% |

### 5.3 éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½éªŒæ”¶**:
- âœ… æ‰€æœ‰å¥åº·æ•°æ®æˆåŠŸå†™å…¥æ•°æ®åº“
- âœ… å‘Šè­¦è§„åˆ™æ­£ç¡®è§¦å‘å’Œæ¨é€  
- âœ… å®šæ—¶ä»»åŠ¡æ­£å¸¸ç”ŸæˆåŸºçº¿ã€è¯„åˆ†ã€ç”»åƒ
- âœ… å¤§å±é¡µé¢æ­£å¸¸å±•ç¤ºæ•°æ®

**æ€§èƒ½éªŒæ”¶**:
- âœ… æŒç»­5åˆ†é’Ÿ5000+å¹¶å‘è¯·æ±‚
- âœ… å¹³å‡å“åº”æ—¶é—´<100ms
- âœ… é”™è¯¯ç‡<0.1%
- âœ… ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡åˆç†

**ç¨³å®šæ€§éªŒæ”¶**:
- âœ… 7Ã—24å°æ—¶ç¨³å®šè¿è¡Œ
- âœ… æ•…éšœè‡ªåŠ¨æ¢å¤èƒ½åŠ›
- âœ… æ•°æ®ä¸€è‡´æ€§ä¿è¯
- âœ… ç›‘æ§å‘Šè­¦å®Œæ•´è¦†ç›–

## 6. é£é™©è¯„ä¼°ä¸åº”å¯¹æªæ–½

### 6.1 æŠ€æœ¯é£é™©

**æ•°æ®ä¸€è‡´æ€§é£é™©**
- é£é™©: é«˜å¹¶å‘ä¸‹å¯èƒ½å‡ºç°æ•°æ®ä¸ä¸€è‡´
- åº”å¯¹: å®æ–½åˆ†å¸ƒå¼äº‹åŠ¡ã€æœ€ç»ˆä¸€è‡´æ€§æ¨¡å¼
- ç›‘æ§: æ•°æ®æ ¡éªŒä»»åŠ¡ã€ä¸€è‡´æ€§æ£€æŸ¥

**ç³»ç»Ÿå¤æ‚åº¦é£é™©**  
- é£é™©: å¾®æœåŠ¡æ¶æ„å¢åŠ è¿ç»´å¤æ‚åº¦
- åº”å¯¹: å®Œå–„æ–‡æ¡£ã€è‡ªåŠ¨åŒ–éƒ¨ç½²ã€ç›‘æ§ä½“ç³»
- ç›‘æ§: æœåŠ¡å¥åº·æ£€æŸ¥ã€ä¾èµ–å…³ç³»ç›‘æ§

### 6.2 ä¸šåŠ¡é£é™©

**æœåŠ¡ä¸­æ–­é£é™©**
- é£é™©: å‡çº§è¿‡ç¨‹å¯èƒ½å½±å“ä¸šåŠ¡
- åº”å¯¹: ç°åº¦å‘å¸ƒã€å¿«é€Ÿå›æ»šæœºåˆ¶
- ç›‘æ§: å®æ—¶ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

**æ•°æ®ä¸¢å¤±é£é™©**
- é£é™©: ç³»ç»Ÿæ•…éšœå¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±  
- åº”å¯¹: å¤šé‡å¤‡ä»½ã€æ¶ˆæ¯æŒä¹…åŒ–
- ç›‘æ§: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ã€å¤‡ä»½éªŒè¯

## 7. æ€»ç»“

æœ¬ä¼˜åŒ–æ–¹æ¡ˆé€šè¿‡ç³»ç»Ÿæ€§çš„æ¶æ„å‡çº§å’Œæ€§èƒ½ä¼˜åŒ–ï¼Œå¯ä»¥å°†å½“å‰200 QPSçš„å¤„ç†èƒ½åŠ›æå‡è‡³5000+å¹¶å‘ï¼Œå¹¶åœ¨5ç§’å†…å®Œæˆå¤„ç†ã€‚æ ¸å¿ƒä¼˜åŒ–ç­–ç•¥åŒ…æ‹¬ï¼š

1. **æ¶æ„å‡çº§**: ä»å•å®ä¾‹å‡çº§ä¸ºå¾®æœåŠ¡é›†ç¾¤æ¶æ„
2. **æ•°æ®åº“ä¼˜åŒ–**: è¯»å†™åˆ†ç¦»ã€è¿æ¥æ± æ‰©å®¹ã€åˆ†è¡¨ç­–ç•¥
3. **ç¼“å­˜ç­–ç•¥**: å¤šçº§ç¼“å­˜å‡å°‘æ•°æ®åº“å‹åŠ›
4. **å¼‚æ­¥å¤„ç†**: æ¶ˆæ¯é˜Ÿåˆ—å®ç°çœŸæ­£çš„å¼‚æ­¥å¤„ç†
5. **ç›‘æ§è¿ç»´**: å®Œå–„çš„ç›‘æ§ä½“ç³»å’Œè‡ªåŠ¨åŒ–è¿ç»´

é€šè¿‡åˆ†é˜¶æ®µå®æ–½ï¼Œæ—¢ä¿è¯äº†ç³»ç»Ÿç¨³å®šæ€§ï¼Œåˆèƒ½é€æ­¥æå‡æ€§èƒ½ï¼Œæœ€ç»ˆè¾¾åˆ°ä¼ä¸šçº§é«˜å¹¶å‘å¤„ç†èƒ½åŠ›ã€‚