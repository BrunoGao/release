#!/usr/bin/env python3
"""
å¼‚æ­¥å¥åº·æ•°æ®å¤„ç†ç³»ç»Ÿå‹åŠ›æµ‹è¯•
1000å°æ‰‹è¡¨å¹¶å‘ä¸Šä¼ å¥åº·æ•°æ®å‹æµ‹
"""

import asyncio
import aiohttp
import time
import json
import random
import logging
import sys
import signal
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor
import threading
from dataclasses import dataclass, asdict
import uuid
import statistics

@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""
    base_url: str = "http://localhost:5225"  # ljwx-bigscreen æœ¬åœ°è°ƒè¯•ç«¯å£
    total_devices: int = 1000  # æ€»è®¾å¤‡æ•°
    concurrent_requests: int = 100  # å¹¶å‘è¯·æ±‚æ•°
    test_duration_minutes: int = 10  # æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    upload_interval_seconds: float = 1.0  # æ¯ä¸ªè®¾å¤‡ä¸Šä¼ é—´éš”ï¼ˆç§’ï¼‰
    timeout_seconds: int = 30  # è¯·æ±‚è¶…æ—¶
    enable_batch_upload: bool = True  # å¯ç”¨æ‰¹é‡ä¸Šä¼ æµ‹è¯•

@dataclass 
class TestStats:
    """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    timeout_requests: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    response_times: List[float] = None
    error_details: Dict[str, int] = None
    
    def __post_init__(self):
        if self.response_times is None:
            self.response_times = []
        if self.error_details is None:
            self.error_details = {}

class AsyncHealthStressTester:
    """å¼‚æ­¥å¥åº·æ•°æ®å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self, config: TestConfig = None):
        self.config = config or TestConfig()
        self.stats = TestStats()
        self.running = False
        self.stats_lock = threading.Lock()
        
        # è®¾å¤‡åˆ—è¡¨
        self.device_list = self._generate_device_list()
        
        # æ—¥å¿—è®¾ç½®
        self._setup_logging()
        
        # ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _generate_device_list(self) -> List[str]:
        """ç”Ÿæˆè®¾å¤‡SNåˆ—è¡¨ï¼Œä½¿ç”¨å®é™…åˆ›å»ºçš„1000ä¸ªæ‰‹è¡¨åºåˆ—å·"""
        devices = []
        for i in range(min(self.config.total_devices, 1000)):
            # ä½¿ç”¨å®é™…åˆ›å»ºçš„æ‰‹è¡¨åºåˆ—å·æ ¼å¼ï¼šCRFTQ23409000000 åˆ° CRFTQ23409000999
            device_sn = f"CRFTQ23409{i:06d}"
            devices.append(device_sn)
        
        # å¦‚æœéœ€è¦æ›´å¤šè®¾å¤‡ï¼Œç»§ç»­ç”¨éšæœºåºåˆ—å·
        if self.config.total_devices > 1000:
            for i in range(1000, self.config.total_devices):
                device_sn = f"CRFTQ{random.randint(20000, 99999)}{random.randint(100000, 999999)}"
                devices.append(device_sn)
                
        return devices
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log_file = log_dir / f"async_stress_test_{timestamp}.log"
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸš€ å¼‚æ­¥å¥åº·æ•°æ®å‹åŠ›æµ‹è¯•å¼€å§‹")
        self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†"""
        self.logger.info(f"æ¥æ”¶åˆ°ä¿¡å· {signum}, åœæ­¢æµ‹è¯•...")
        self.running = False
    
    def generate_health_data(self, device_sn: str, timestamp: datetime = None) -> Dict[str, Any]:
        """ç”Ÿæˆå¥åº·æ•°æ®ï¼ˆç¬¦åˆæä¾›çš„æ ·ä¾‹æ ¼å¼ï¼‰"""
        if timestamp is None:
            timestamp = datetime.now()
        
        timestamp_str = timestamp.strftime("%Y-%m-%d %H:%M:%S")
        
        # ç”ŸæˆçœŸå®çš„å¥åº·æ•°æ®å˜åŒ–
        heart_rate = random.randint(60, 120)
        blood_oxygen = random.randint(95, 100) if random.random() > 0.2 else 0
        body_temperature = f"{random.uniform(36.0, 37.5):.1f}"
        
        # è¿åŠ¨æ•°æ®ï¼ˆæ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼‰
        is_active = random.random() > 0.3
        step = random.randint(0, 15000) if is_active else 0
        distance = f"{random.uniform(0, 12):.1f}" if is_active else "0.0"
        calorie = f"{random.uniform(0, 600):.1f}" if is_active else "0.0"
        
        # GPSæ•°æ®ï¼ˆæ·±åœ³åœ°åŒºï¼‰
        latitude = f"{random.uniform(22.5, 22.6):.6f}"
        longitude = f"{random.uniform(113.9, 114.1):.6f}" 
        altitude = f"{random.uniform(0, 100):.1f}"
        
        # å‹åŠ›å’Œè¡€å‹
        stress = random.randint(0, 100)
        blood_pressure_systolic = random.randint(110, 140)
        blood_pressure_diastolic = random.randint(70, 90)
        
        # éšæœºç¡çœ æ•°æ®ï¼ˆéƒ¨åˆ†è®¾å¤‡æœ‰ï¼‰
        sleep_data = "null"
        if random.random() > 0.8:  # 20%æ¦‚ç‡æœ‰ç¡çœ æ•°æ®
            sleep_data = json.dumps({
                "code": 0,
                "data": [{
                    "endTimeStamp": int(timestamp.timestamp() * 1000),
                    "startTimeStamp": int((timestamp - timedelta(hours=8)).timestamp() * 1000),
                    "type": 2
                }],
                "name": "sleep",
                "type": "history"
            })
        
        return {
            "data": {
                "deviceSn": device_sn,
                "heart_rate": heart_rate,
                "blood_oxygen": blood_oxygen,
                "body_temperature": body_temperature,
                "step": step,
                "distance": distance,
                "calorie": calorie,
                "latitude": latitude,
                "longitude": longitude,
                "altitude": altitude,
                "stress": stress,
                "upload_method": random.choice(["wifi", "4g", "bluetooth"]),
                "blood_pressure_systolic": blood_pressure_systolic,
                "blood_pressure_diastolic": blood_pressure_diastolic,
                "sleepData": sleep_data,
                "exerciseDailyData": "null",
                "exerciseWeekData": "null", 
                "scientificSleepData": "null",
                "workoutData": "null",
                "timestamp": timestamp_str
            }
        }
    
    def generate_batch_health_data(self, device_count: int = 50) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰¹é‡å¥åº·æ•°æ®"""
        timestamp = datetime.now()
        batch_data = []
        
        # éšæœºé€‰æ‹©è®¾å¤‡
        selected_devices = random.sample(self.device_list, min(device_count, len(self.device_list)))
        
        for device_sn in selected_devices:
            health_data = self.generate_health_data(device_sn, timestamp)
            batch_data.append(health_data["data"])
        
        return {"data": batch_data}
    
    async def upload_single_health_data(self, session: aiohttp.ClientSession, device_sn: str) -> Dict[str, Any]:
        """ä¸Šä¼ å•ä¸ªè®¾å¤‡å¥åº·æ•°æ®"""
        start_time = time.time()
        
        try:
            health_data = self.generate_health_data(device_sn)
            url = f"{self.config.base_url}/upload_health_data"
            
            async with session.post(
                url, 
                json=health_data,
                timeout=aiohttp.ClientTimeout(total=self.config.timeout_seconds)
            ) as response:
                response_time = time.time() - start_time
                response_text = await response.text()
                
                # æ›´æ–°ç»Ÿè®¡
                with self.stats_lock:
                    self.stats.total_requests += 1
                    self.stats.response_times.append(response_time)
                    
                    if response.status == 200:
                        self.stats.successful_requests += 1
                    else:
                        self.stats.failed_requests += 1
                        error_key = f"HTTP_{response.status}"
                        self.stats.error_details[error_key] = self.stats.error_details.get(error_key, 0) + 1
                
                return {
                    'device_sn': device_sn,
                    'success': response.status == 200,
                    'status_code': response.status,
                    'response_time': response_time,
                    'response_text': response_text[:200],  # é™åˆ¶å“åº”æ–‡æœ¬é•¿åº¦
                    'timestamp': datetime.now().isoformat()
                }
                
        except asyncio.TimeoutError:
            response_time = time.time() - start_time
            with self.stats_lock:
                self.stats.total_requests += 1
                self.stats.timeout_requests += 1
                self.stats.response_times.append(response_time)
                self.stats.error_details['TIMEOUT'] = self.stats.error_details.get('TIMEOUT', 0) + 1
            
            return {
                'device_sn': device_sn,
                'success': False,
                'error': 'TIMEOUT',
                'response_time': response_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            response_time = time.time() - start_time
            with self.stats_lock:
                self.stats.total_requests += 1
                self.stats.failed_requests += 1
                error_key = type(e).__name__
                self.stats.error_details[error_key] = self.stats.error_details.get(error_key, 0) + 1
                self.stats.response_times.append(response_time)
            
            return {
                'device_sn': device_sn,
                'success': False,
                'error': str(e),
                'response_time': response_time,
                'timestamp': datetime.now().isoformat()
            }
    
    async def upload_batch_health_data(self, session: aiohttp.ClientSession, batch_size: int = 50) -> Dict[str, Any]:
        """ä¸Šä¼ æ‰¹é‡å¥åº·æ•°æ®"""
        start_time = time.time()
        
        try:
            batch_data = self.generate_batch_health_data(batch_size)
            url = f"{self.config.base_url}/upload_health_data"
            
            async with session.post(
                url,
                json=batch_data,
                timeout=aiohttp.ClientTimeout(total=self.config.timeout_seconds * 2)  # æ‰¹é‡è¯·æ±‚è¶…æ—¶æ—¶é—´åŠ å€
            ) as response:
                response_time = time.time() - start_time
                response_text = await response.text()
                
                # æ›´æ–°ç»Ÿè®¡
                with self.stats_lock:
                    self.stats.total_requests += batch_size  # æ‰¹é‡è¯·æ±‚æŒ‰æ•°æ®æ¡æ•°è®¡ç®—
                    self.stats.response_times.append(response_time)
                    
                    if response.status == 200:
                        self.stats.successful_requests += batch_size
                    else:
                        self.stats.failed_requests += batch_size
                        error_key = f"BATCH_HTTP_{response.status}"
                        self.stats.error_details[error_key] = self.stats.error_details.get(error_key, 0) + 1
                
                return {
                    'batch_size': batch_size,
                    'success': response.status == 200,
                    'status_code': response.status,
                    'response_time': response_time,
                    'response_text': response_text[:200],
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            response_time = time.time() - start_time
            with self.stats_lock:
                self.stats.total_requests += batch_size
                self.stats.failed_requests += batch_size
                error_key = f"BATCH_{type(e).__name__}"
                self.stats.error_details[error_key] = self.stats.error_details.get(error_key, 0) + 1
                self.stats.response_times.append(response_time)
            
            return {
                'batch_size': batch_size,
                'success': False,
                'error': str(e),
                'response_time': response_time,
                'timestamp': datetime.now().isoformat()
            }
    
    async def run_concurrent_test(self):
        """è¿è¡Œå¹¶å‘å‹åŠ›æµ‹è¯•"""
        self.logger.info("ğŸ”¥ å¼€å§‹1000å°æ‰‹è¡¨å¹¶å‘å‹åŠ›æµ‹è¯•")
        self.logger.info(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
        self.logger.info(f"   - æ€»è®¾å¤‡æ•°: {self.config.total_devices}")
        self.logger.info(f"   - å¹¶å‘æ•°: {self.config.concurrent_requests}")
        self.logger.info(f"   - æµ‹è¯•æ—¶é•¿: {self.config.test_duration_minutes}åˆ†é’Ÿ")
        self.logger.info(f"   - ä¸Šä¼ é—´éš”: {self.config.upload_interval_seconds}ç§’")
        self.logger.info(f"   - ç›®æ ‡URL: {self.config.base_url}")
        
        self.running = True
        self.stats.start_time = datetime.now()
        
        # åˆ›å»ºHTTPä¼šè¯
        connector = aiohttp.TCPConnector(
            limit=self.config.concurrent_requests * 2,
            limit_per_host=self.config.concurrent_requests,
            ttl_dns_cache=300,
            use_dns_cache=True,
        )
        
        timeout = aiohttp.ClientTimeout(total=self.config.timeout_seconds)
        
        async with aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'Content-Type': 'application/json',
                'User-Agent': 'AsyncHealthStressTester/1.0'
            }
        ) as session:
            # å¯åŠ¨ç›‘æ§ä»»åŠ¡
            monitor_task = asyncio.create_task(self._monitor_progress())
            
            try:
                # åˆ›å»ºæµ‹è¯•ä»»åŠ¡åˆ—è¡¨
                tasks = []
                end_time = datetime.now() + timedelta(minutes=self.config.test_duration_minutes)
                
                # æ··åˆå•ä¸ªå’Œæ‰¹é‡ä¸Šä¼ æµ‹è¯•
                while datetime.now() < end_time and self.running:
                    # å•ä¸ªè®¾å¤‡ä¸Šä¼ ï¼ˆ70%ï¼‰
                    if random.random() < 0.7 or not self.config.enable_batch_upload:
                        # éšæœºé€‰æ‹©è®¾å¤‡è¿›è¡Œå•ä¸ªä¸Šä¼ 
                        selected_devices = random.sample(
                            self.device_list, 
                            min(self.config.concurrent_requests, len(self.device_list))
                        )
                        
                        for device_sn in selected_devices:
                            if len(tasks) >= self.config.concurrent_requests:
                                # ç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ
                                done, pending = await asyncio.wait(
                                    tasks, 
                                    timeout=0.1, 
                                    return_when=asyncio.FIRST_COMPLETED
                                )
                                tasks = list(pending)
                            
                            task = asyncio.create_task(
                                self.upload_single_health_data(session, device_sn)
                            )
                            tasks.append(task)
                    
                    else:
                        # æ‰¹é‡ä¸Šä¼ ï¼ˆ30%ï¼‰
                        if len(tasks) >= self.config.concurrent_requests // 2:
                            done, pending = await asyncio.wait(
                                tasks,
                                timeout=0.1,
                                return_when=asyncio.FIRST_COMPLETED
                            )
                            tasks = list(pending)
                        
                        task = asyncio.create_task(
                            self.upload_batch_health_data(session, random.randint(10, 100))
                        )
                        tasks.append(task)
                    
                    # æ§åˆ¶ä¸Šä¼ é¢‘ç‡
                    await asyncio.sleep(self.config.upload_interval_seconds)
                
                # ç­‰å¾…æ‰€æœ‰å‰©ä½™ä»»åŠ¡å®Œæˆ
                if tasks:
                    self.logger.info(f"ç­‰å¾… {len(tasks)} ä¸ªå‰©ä½™ä»»åŠ¡å®Œæˆ...")
                    await asyncio.gather(*tasks, return_exceptions=True)
                
            finally:
                monitor_task.cancel()
                try:
                    await monitor_task
                except asyncio.CancelledError:
                    pass
        
        self.stats.end_time = datetime.now()
        self._print_final_report()
    
    async def _monitor_progress(self):
        """ç›‘æ§æµ‹è¯•è¿›åº¦"""
        last_requests = 0
        
        while self.running:
            try:
                await asyncio.sleep(10)  # æ¯10ç§’æ‰“å°ä¸€æ¬¡è¿›åº¦
                
                with self.stats_lock:
                    current_requests = self.stats.total_requests
                    successful = self.stats.successful_requests
                    failed = self.stats.failed_requests
                    
                    # è®¡ç®—QPS
                    requests_delta = current_requests - last_requests
                    qps = requests_delta / 10.0
                    
                    # è®¡ç®—æˆåŠŸç‡
                    success_rate = (successful / current_requests * 100) if current_requests > 0 else 0
                    
                    # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
                    avg_response_time = 0
                    if self.stats.response_times:
                        avg_response_time = statistics.mean(self.stats.response_times[-100:])  # æœ€è¿‘100ä¸ªè¯·æ±‚çš„å¹³å‡æ—¶é—´
                
                elapsed_time = datetime.now() - self.stats.start_time if self.stats.start_time else timedelta(0)
                
                self.logger.info(
                    f"ğŸ“Š æµ‹è¯•è¿›åº¦ - "
                    f"æ€»è¯·æ±‚: {current_requests}, "
                    f"æˆåŠŸ: {successful}, "
                    f"å¤±è´¥: {failed}, "
                    f"æˆåŠŸç‡: {success_rate:.1f}%, "
                    f"QPS: {qps:.1f}, "
                    f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s, "
                    f"è¿è¡Œæ—¶é—´: {str(elapsed_time).split('.')[0]}"
                )
                
                last_requests = current_requests
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"ç›‘æ§è¿›åº¦å¼‚å¸¸: {e}")
    
    def _print_final_report(self):
        """æ‰“å°æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š 1000å°æ‰‹è¡¨å¹¶å‘å‹åŠ›æµ‹è¯•æŠ¥å‘Š")
        self.logger.info("=" * 80)
        
        if self.stats.start_time and self.stats.end_time:
            duration = self.stats.end_time - self.stats.start_time
            self.logger.info(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {duration}")
            
            # è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡
            if self.stats.total_requests > 0 and duration.total_seconds() > 0:
                qps = self.stats.total_requests / duration.total_seconds()
                self.logger.info(f"ğŸš€ æ•´ä½“QPS: {qps:.2f} è¯·æ±‚/ç§’")
                self.logger.info(f"ğŸ’ª å¤„ç†èƒ½åŠ›: {qps * 60:.0f} è¯·æ±‚/åˆ†é’Ÿ")
        
        # è¯·æ±‚ç»Ÿè®¡
        self.logger.info(f"ğŸ“ˆ è¯·æ±‚ç»Ÿè®¡:")
        self.logger.info(f"   - æ€»è¯·æ±‚æ•°: {self.stats.total_requests}")
        self.logger.info(f"   - æˆåŠŸè¯·æ±‚: {self.stats.successful_requests}")
        self.logger.info(f"   - å¤±è´¥è¯·æ±‚: {self.stats.failed_requests}")
        self.logger.info(f"   - è¶…æ—¶è¯·æ±‚: {self.stats.timeout_requests}")
        
        # æˆåŠŸç‡
        if self.stats.total_requests > 0:
            success_rate = (self.stats.successful_requests / self.stats.total_requests) * 100
            self.logger.info(f"âœ… æˆåŠŸç‡: {success_rate:.2f}%")
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        if self.stats.response_times:
            response_times = self.stats.response_times
            self.logger.info(f"âš¡ å“åº”æ—¶é—´ç»Ÿè®¡:")
            self.logger.info(f"   - å¹³å‡å“åº”æ—¶é—´: {statistics.mean(response_times):.3f}ç§’")
            self.logger.info(f"   - æœ€å¿«å“åº”æ—¶é—´: {min(response_times):.3f}ç§’")
            self.logger.info(f"   - æœ€æ…¢å“åº”æ—¶é—´: {max(response_times):.3f}ç§’")
            self.logger.info(f"   - 95%å“åº”æ—¶é—´: {statistics.quantiles(response_times, n=20)[18]:.3f}ç§’")
        
        # é”™è¯¯è¯¦æƒ…
        if self.stats.error_details:
            self.logger.info(f"âŒ é”™è¯¯è¯¦æƒ…:")
            for error_type, count in self.stats.error_details.items():
                self.logger.info(f"   - {error_type}: {count}æ¬¡")
        
        # ç³»ç»Ÿæ€§èƒ½è¯„ä¼°
        self._evaluate_system_performance()
    
    def _evaluate_system_performance(self):
        """è¯„ä¼°ç³»ç»Ÿæ€§èƒ½"""
        self.logger.info("ğŸ¯ ç³»ç»Ÿæ€§èƒ½è¯„ä¼°:")
        
        if not self.stats.response_times or self.stats.total_requests == 0:
            self.logger.info("   - æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°")
            return
        
        # è®¡ç®—æŒ‡æ ‡
        success_rate = (self.stats.successful_requests / self.stats.total_requests) * 100
        avg_response_time = statistics.mean(self.stats.response_times)
        duration = self.stats.end_time - self.stats.start_time if self.stats.start_time and self.stats.end_time else timedelta(0)
        qps = self.stats.total_requests / duration.total_seconds() if duration.total_seconds() > 0 else 0
        
        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        performance_grade = "ä¼˜ç§€"
        issues = []
        
        if success_rate < 95:
            performance_grade = "éœ€è¦ä¼˜åŒ–"
            issues.append(f"æˆåŠŸç‡åä½ ({success_rate:.1f}%)")
        
        if avg_response_time > 2.0:
            performance_grade = "éœ€è¦ä¼˜åŒ–" if performance_grade != "éœ€è¦ä¼˜åŒ–" else performance_grade
            issues.append(f"å“åº”æ—¶é—´åæ…¢ ({avg_response_time:.3f}s)")
        
        if qps < 100:
            performance_grade = "éœ€è¦ä¼˜åŒ–" if performance_grade != "éœ€è¦ä¼˜åŒ–" else performance_grade
            issues.append(f"QPSåä½ ({qps:.1f})")
        
        self.logger.info(f"   - æ€§èƒ½ç­‰çº§: {performance_grade}")
        if issues:
            self.logger.info(f"   - å‘ç°é—®é¢˜:")
            for issue in issues:
                self.logger.info(f"     * {issue}")
        
        # å¼‚æ­¥ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½å¯¹æ¯”
        self.logger.info("ğŸ†š æ€§èƒ½å¯¹æ¯”åˆ†æ:")
        self.logger.info("   é¢„æœŸæ€§èƒ½æŒ‡æ ‡ï¼ˆåŸºäºå¼‚æ­¥ä¼˜åŒ–ï¼‰:")
        self.logger.info("   - ç›®æ ‡QPS: 500+ è¯·æ±‚/ç§’")
        self.logger.info("   - ç›®æ ‡å“åº”æ—¶é—´: <0.2ç§’")
        self.logger.info("   - ç›®æ ‡æˆåŠŸç‡: >99%")
        self.logger.info("   - å¹¶å‘å¤„ç†èƒ½åŠ›: 1000+ è®¾å¤‡")
        
        if qps >= 500:
            self.logger.info("   âœ… QPSè¾¾æ ‡ï¼å¼‚æ­¥ä¼˜åŒ–æ•ˆæœæ˜¾è‘—")
        else:
            self.logger.info(f"   âš ï¸ QPSæœªè¾¾æ ‡ï¼Œå½“å‰: {qps:.1f}, ç›®æ ‡: 500+")
        
        if avg_response_time <= 0.2:
            self.logger.info("   âœ… å“åº”æ—¶é—´ä¼˜ç§€ï¼")
        else:
            self.logger.info(f"   âš ï¸ å“åº”æ—¶é—´éœ€ä¼˜åŒ–ï¼Œå½“å‰: {avg_response_time:.3f}s, ç›®æ ‡: <0.2s")

    async def run_system_integration_test(self):
        """è¿è¡Œç³»ç»Ÿé›†æˆæµ‹è¯• - æµ‹è¯•æ–°å¼‚æ­¥æ¶æ„"""
        self.logger.info("ğŸ”§ å¼€å§‹å¼‚æ­¥ç³»ç»Ÿé›†æˆæµ‹è¯•")
        
        # æµ‹è¯•å¼‚æ­¥å¤„ç†å™¨çŠ¶æ€
        await self._test_async_processor_status()
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†èƒ½åŠ›
        await self._test_batch_processing()
        
        # æµ‹è¯•èµ„æºç®¡ç†
        await self._test_resource_management()
    
    async def _test_async_processor_status(self):
        """æµ‹è¯•å¼‚æ­¥å¤„ç†å™¨çŠ¶æ€"""
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.config.base_url}/get_async_system_stats"
                async with session.get(url) as response:
                    if response.status == 200:
                        stats = await response.json()
                        self.logger.info("âœ… å¼‚æ­¥å¤„ç†å™¨çŠ¶æ€æ­£å¸¸")
                        self.logger.info(f"   ç³»ç»Ÿç‰ˆæœ¬: {stats.get('system_overview', {}).get('version', 'unknown')}")
                        self.logger.info(f"   è¿è¡ŒçŠ¶æ€: {stats.get('system_overview', {}).get('status', 'unknown')}")
                    else:
                        self.logger.warning(f"âš ï¸ æ— æ³•è·å–å¼‚æ­¥å¤„ç†å™¨çŠ¶æ€: HTTP {response.status}")
        except Exception as e:
            self.logger.error(f"âŒ å¼‚æ­¥å¤„ç†å™¨çŠ¶æ€æµ‹è¯•å¤±è´¥: {e}")
    
    async def _test_batch_processing(self):
        """æµ‹è¯•æ‰¹é‡å¤„ç†èƒ½åŠ›"""
        self.logger.info("ğŸ”„ æµ‹è¯•æ‰¹é‡å¤„ç†èƒ½åŠ›...")
        
        batch_sizes = [10, 50, 100, 200]
        
        async with aiohttp.ClientSession() as session:
            for batch_size in batch_sizes:
                try:
                    result = await self.upload_batch_health_data(session, batch_size)
                    if result['success']:
                        self.logger.info(f"   âœ… æ‰¹é‡å¤§å° {batch_size}: æˆåŠŸï¼Œå“åº”æ—¶é—´: {result['response_time']:.3f}s")
                    else:
                        self.logger.warning(f"   âš ï¸ æ‰¹é‡å¤§å° {batch_size}: å¤±è´¥")
                except Exception as e:
                    self.logger.error(f"   âŒ æ‰¹é‡å¤§å° {batch_size}: å¼‚å¸¸ - {e}")
    
    async def _test_resource_management(self):
        """æµ‹è¯•èµ„æºç®¡ç†"""
        self.logger.info("ğŸ“Š æµ‹è¯•åŠ¨æ€èµ„æºç®¡ç†...")
        
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.config.base_url}/get_optimizer_stats"
                async with session.get(url) as response:
                    if response.status == 200:
                        stats = await response.json()
                        self.logger.info("âœ… èµ„æºç®¡ç†å™¨è¿è¡Œæ­£å¸¸")
                        self.logger.info(f"   æ‰¹æ¬¡å¤§å°: {stats.get('batch_size', 'unknown')}")
                        self.logger.info(f"   å·¥ä½œçº¿ç¨‹: {stats.get('max_workers', 'unknown')}")
                        self.logger.info(f"   é˜Ÿåˆ—å¤§å°: {stats.get('queue_size', 'unknown')}")
                    else:
                        self.logger.warning(f"âš ï¸ æ— æ³•è·å–èµ„æºç®¡ç†å™¨çŠ¶æ€: HTTP {response.status}")
        except Exception as e:
            self.logger.error(f"âŒ èµ„æºç®¡ç†æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼‚æ­¥å¥åº·æ•°æ®å¤„ç†ç³»ç»Ÿå‹åŠ›æµ‹è¯•")
    print("=" * 60)
    print("ğŸ¯ ç›®æ ‡: æµ‹è¯•1000å°æ‰‹è¡¨å¹¶å‘ä¸Šä¼ å¥åº·æ•°æ®")
    print("âš¡ éªŒè¯å¼‚æ­¥ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½æå‡æ•ˆæœ")
    print()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='å¼‚æ­¥å¥åº·æ•°æ®å‹åŠ›æµ‹è¯•')
    parser.add_argument('--devices', type=int, default=1000, help='è®¾å¤‡æ•°é‡ (é»˜è®¤: 1000)')
    parser.add_argument('--concurrent', type=int, default=100, help='å¹¶å‘æ•° (é»˜è®¤: 100)')
    parser.add_argument('--duration', type=int, default=10, help='æµ‹è¯•æ—¶é•¿(åˆ†é’Ÿ) (é»˜è®¤: 10)')
    parser.add_argument('--url', type=str, default='http://localhost:5225', help='æœåŠ¡URL (é»˜è®¤: http://localhost:5225)')
    parser.add_argument('--interval', type=float, default=1.0, help='ä¸Šä¼ é—´éš”(ç§’) (é»˜è®¤: 1.0)')
    parser.add_argument('--integration-test', action='store_true', help='è¿è¡Œç³»ç»Ÿé›†æˆæµ‹è¯•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig(
        base_url=args.url,
        total_devices=args.devices,
        concurrent_requests=args.concurrent,
        test_duration_minutes=args.duration,
        upload_interval_seconds=args.interval
    )
    
    print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"   - è®¾å¤‡æ•°é‡: {config.total_devices}")
    print(f"   - å¹¶å‘æ•°: {config.concurrent_requests}")
    print(f"   - æµ‹è¯•æ—¶é•¿: {config.test_duration_minutes}åˆ†é’Ÿ")
    print(f"   - æœåŠ¡åœ°å€: {config.base_url}")
    print(f"   - ä¸Šä¼ é—´éš”: {config.upload_interval_seconds}ç§’")
    print()
    
    if not args.integration_test:
        confirm = input("ç¡®è®¤å¼€å§‹å‹åŠ›æµ‹è¯•? (y/N): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = AsyncHealthStressTester(config)
    
    try:
        if args.integration_test:
            asyncio.run(tester.run_system_integration_test())
        else:
            asyncio.run(tester.run_concurrent_test())
    except KeyboardInterrupt:
        print("\nâ¸ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()