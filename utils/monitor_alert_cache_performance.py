#!/usr/bin/env python3
"""
å‘Šè­¦è§„åˆ™ç¼“å­˜æ€§èƒ½ç›‘æ§è„šæœ¬
å®æ—¶ç›‘æ§Redisç¼“å­˜å‘Šè­¦ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡
"""

import time
import json
import logging
import sys
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any
import threading

# æ·»åŠ å½“å‰è·¯å¾„
current_dir = os.path.dirname(__file__)
sys.path.insert(0, current_dir)

from redis_cache_generate_alerts import get_redis_cached_generator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AlertCacheMonitor:
    """å‘Šè­¦ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, interval: int = 10):
        self.interval = interval  # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
        self.running = False
        self.monitor_thread = None
        self.generator = None
        self.history = []  # å†å²æ•°æ®
        self.max_history = 100  # æœ€å¤§å†å²è®°å½•æ•°
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.running:
            logger.warning("ç›‘æ§å™¨å·²åœ¨è¿è¡Œä¸­")
            return
            
        print("ğŸ” å¯åŠ¨å‘Šè­¦ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨")
        try:
            self.generator = get_redis_cached_generator()
            self.running = True
            
            self.monitor_thread = threading.Thread(
                target=self._monitor_loop,
                daemon=True,
                name="AlertCacheMonitor"
            )
            self.monitor_thread.start()
            
            print(f"âœ… ç›‘æ§å™¨å·²å¯åŠ¨ï¼Œç›‘æ§é—´éš”: {self.interval}ç§’")
            
        except Exception as e:
            print(f"âŒ ç›‘æ§å™¨å¯åŠ¨å¤±è´¥: {e}")
            self.running = False
            
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        print("ğŸ›‘ ç›‘æ§å™¨å·²åœæ­¢")
        
    def _monitor_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        print("ğŸ“Š å¼€å§‹æ€§èƒ½ç›‘æ§...")
        print("-" * 80)
        
        while self.running:
            try:
                # æ”¶é›†æ€§èƒ½æ•°æ®
                metrics = self._collect_metrics()
                
                # ä¿å­˜å†å²æ•°æ®
                self._save_metrics(metrics)
                
                # æ˜¾ç¤ºå®æ—¶æ•°æ®
                self._display_metrics(metrics)
                
                # æ£€æŸ¥å‘Šè­¦
                self._check_alerts(metrics)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡ç›‘æ§
                time.sleep(self.interval)
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(self.interval)
                
    def _collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            # è·å–åŸºç¡€ç»Ÿè®¡
            stats = self.generator.get_stats()
            
            # è·å–å½“å‰æ—¶é—´
            timestamp = datetime.now()
            
            # æ„å»ºæŒ‡æ ‡æ•°æ®
            metrics = {
                'timestamp': timestamp,
                'total_processed': stats.get('total_processed', 0),
                'cache_hits': stats.get('cache_hits', 0),
                'db_fallbacks': stats.get('db_fallbacks', 0),
                'cache_hit_rate': stats.get('cache_hit_rate', '0.00%'),
                'alerts_generated': stats.get('alerts_generated', 0),
                'avg_processing_time': stats.get('avg_processing_time', '0.000s'),
            }
            
            # Redisè¿æ¥çŠ¶æ€
            cache_manager_status = stats.get('cache_manager_status', {})
            if isinstance(cache_manager_status, dict):
                redis_status = cache_manager_status.get('redis_connection_status', {})
                metrics['bigscreen_redis_ok'] = redis_status.get('bigscreen_redis', False)
                metrics['boot_redis_ok'] = redis_status.get('boot_redis', False)
                metrics['local_cache_size'] = cache_manager_status.get('local_cache_size', 0)
                metrics['subscriber_running'] = cache_manager_status.get('subscriber_running', False)
            else:
                metrics['bigscreen_redis_ok'] = False
                metrics['boot_redis_ok'] = False
                metrics['local_cache_size'] = 0
                metrics['subscriber_running'] = False
                
            return metrics
            
        except Exception as e:
            logger.error(f"æ”¶é›†æŒ‡æ ‡å¤±è´¥: {e}")
            return {'timestamp': datetime.now(), 'error': str(e)}
            
    def _save_metrics(self, metrics: Dict[str, Any]):
        """ä¿å­˜å†å²æŒ‡æ ‡"""
        self.history.append(metrics)
        
        # ä¿æŒå†å²è®°å½•æ•°é‡é™åˆ¶
        if len(self.history) > self.max_history:
            self.history.pop(0)
            
    def _display_metrics(self, metrics: Dict[str, Any]):
        """æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡"""
        timestamp = metrics.get('timestamp', datetime.now())
        
        print(f"\nâ° {timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: æ€»è®¡={metrics.get('total_processed', 0)}, å‘Šè­¦={metrics.get('alerts_generated', 0)}")
        print(f"ğŸ”¥ ç¼“å­˜æ€§èƒ½: å‘½ä¸­={metrics.get('cache_hits', 0)}, å…œåº•={metrics.get('db_fallbacks', 0)}, å‘½ä¸­ç‡={metrics.get('cache_hit_rate', 'N/A')}")
        print(f"âš¡ å¤„ç†æ—¶é—´: å¹³å‡={metrics.get('avg_processing_time', 'N/A')}")
        
        # Redisè¿æ¥çŠ¶æ€
        bigscreen_ok = metrics.get('bigscreen_redis_ok', False)
        boot_ok = metrics.get('boot_redis_ok', False)
        subscriber_ok = metrics.get('subscriber_running', False)
        
        bigscreen_status = "âœ…" if bigscreen_ok else "âŒ"
        boot_status = "âœ…" if boot_ok else "âŒ"
        subscriber_status = "âœ…" if subscriber_ok else "âŒ"
        
        print(f"ğŸ”— è¿æ¥çŠ¶æ€: bigscreen-redis={bigscreen_status}, boot-redis={boot_status}, è®¢é˜…è€…={subscriber_status}")
        print(f"ğŸ“‹ æœ¬åœ°ç¼“å­˜: {metrics.get('local_cache_size', 0)}ä¸ªå®¢æˆ·")
        print("-" * 80)
        
    def _check_alerts(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥æ€§èƒ½å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥Redisè¿æ¥
        if not metrics.get('bigscreen_redis_ok', True):
            alerts.append("âŒ ljwx-bigscreen Redisè¿æ¥å¼‚å¸¸")
        if not metrics.get('boot_redis_ok', True):
            alerts.append("âŒ ljwx-boot Redisè¿æ¥å¼‚å¸¸")
            
        # æ£€æŸ¥è®¢é˜…è€…çŠ¶æ€
        if not metrics.get('subscriber_running', True):
            alerts.append("âš ï¸ Redisè®¢é˜…è€…æœªè¿è¡Œ")
            
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        cache_hit_rate_str = metrics.get('cache_hit_rate', '0.00%')
        try:
            cache_hit_rate = float(cache_hit_rate_str.replace('%', ''))
            if cache_hit_rate < 80:
                alerts.append(f"âš ï¸ ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {cache_hit_rate_str}")
        except:
            pass
            
        # æ£€æŸ¥æ•°æ®åº“å…œåº•é¢‘ç‡
        db_fallbacks = metrics.get('db_fallbacks', 0)
        cache_hits = metrics.get('cache_hits', 0)
        total_queries = db_fallbacks + cache_hits
        
        if total_queries > 0:
            fallback_rate = db_fallbacks / total_queries * 100
            if fallback_rate > 20:
                alerts.append(f"âš ï¸ æ•°æ®åº“å…œåº•é¢‘ç‡è¿‡é«˜: {fallback_rate:.1f}%")
                
        # æ˜¾ç¤ºå‘Šè­¦
        if alerts:
            print("ğŸš¨ æ€§èƒ½å‘Šè­¦:")
            for alert in alerts:
                print(f"  {alert}")
                
    def get_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.history:
            return {"error": "æ— å†å²æ•°æ®"}
            
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total_records = len(self.history)
        recent_records = self.history[-10:] if len(self.history) >= 10 else self.history
        
        # æœ€æ–°çŠ¶æ€
        latest = self.history[-1]
        
        # å¤„ç†é‡è¶‹åŠ¿
        if len(self.history) >= 2:
            first = self.history[0]
            last = self.history[-1]
            processed_growth = last.get('total_processed', 0) - first.get('total_processed', 0)
        else:
            processed_growth = 0
            
        # Redisè¿æ¥ç¨³å®šæ€§
        redis_stability = sum(1 for m in recent_records if m.get('bigscreen_redis_ok') and m.get('boot_redis_ok')) / len(recent_records) * 100
        
        return {
            'report_time': datetime.now().isoformat(),
            'monitoring_duration': f"{total_records * self.interval}ç§’",
            'total_records': total_records,
            'latest_status': {
                'total_processed': latest.get('total_processed', 0),
                'cache_hit_rate': latest.get('cache_hit_rate', 'N/A'),
                'local_cache_size': latest.get('local_cache_size', 0),
                'redis_connections_ok': latest.get('bigscreen_redis_ok', False) and latest.get('boot_redis_ok', False)
            },
            'performance_trends': {
                'processed_growth': processed_growth,
                'redis_stability': f"{redis_stability:.1f}%",
            },
            'recommendations': self._generate_recommendations(recent_records)
        }
        
    def _generate_recommendations(self, recent_records: List[Dict]) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½å»ºè®®"""
        recommendations = []
        
        if not recent_records:
            return recommendations
            
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        avg_cache_hits = sum(r.get('cache_hits', 0) for r in recent_records) / len(recent_records)
        avg_db_fallbacks = sum(r.get('db_fallbacks', 0) for r in recent_records) / len(recent_records)
        
        if avg_db_fallbacks > avg_cache_hits:
            recommendations.append("å»ºè®®æ£€æŸ¥Redisç¼“å­˜é…ç½®ï¼Œæ•°æ®åº“å…œåº•é¢‘ç‡è¿‡é«˜")
            
        # æ£€æŸ¥Redisè¿æ¥ç¨³å®šæ€§
        disconnection_count = sum(1 for r in recent_records 
                                if not (r.get('bigscreen_redis_ok', True) and r.get('boot_redis_ok', True)))
        if disconnection_count > 0:
            recommendations.append("å‘ç°Redisè¿æ¥ä¸ç¨³å®šï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œå’ŒRedisæœåŠ¡çŠ¶æ€")
            
        # æ£€æŸ¥è®¢é˜…è€…çŠ¶æ€
        subscriber_down_count = sum(1 for r in recent_records if not r.get('subscriber_running', True))
        if subscriber_down_count > 0:
            recommendations.append("Redisè®¢é˜…è€…å­˜åœ¨ä¸­æ–­ï¼Œå»ºè®®æ£€æŸ¥è®¢é˜…è€…æœåŠ¡çŠ¶æ€")
            
        # æ£€æŸ¥æœ¬åœ°ç¼“å­˜å¤§å°
        latest_cache_size = recent_records[-1].get('local_cache_size', 0)
        if latest_cache_size == 0:
            recommendations.append("æœ¬åœ°ç¼“å­˜ä¸ºç©ºï¼Œå¯èƒ½éœ€è¦é¢„åŠ è½½å¸¸ç”¨å®¢æˆ·çš„å‘Šè­¦è§„åˆ™")
        elif latest_cache_size > 100:
            recommendations.append("æœ¬åœ°ç¼“å­˜è¿‡å¤§ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥æˆ–å¢åŠ å†…å­˜é™åˆ¶")
            
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæ— ç‰¹æ®Šå»ºè®®")
            
        return recommendations
        
    def save_report_to_file(self, filename: str = None):
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"alert_cache_performance_report_{timestamp}.json"
            
        report = self.get_performance_report()
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å‘Šè­¦è§„åˆ™ç¼“å­˜æ€§èƒ½ç›‘æ§")
    parser.add_argument('-i', '--interval', type=int, default=10, help='ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('-d', '--duration', type=int, default=0, help='ç›‘æ§æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºæŒç»­ç›‘æ§')
    parser.add_argument('-r', '--report', action='store_true', help='ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    monitor = AlertCacheMonitor(interval=args.interval)
    
    try:
        # å¯åŠ¨ç›‘æ§
        monitor.start_monitoring()
        
        if args.duration > 0:
            # å®šæ—¶ç›‘æ§
            print(f"â±ï¸ å°†ç›‘æ§{args.duration}ç§’åè‡ªåŠ¨åœæ­¢")
            time.sleep(args.duration)
            monitor.stop_monitoring()
            
            # ç”ŸæˆæŠ¥å‘Š
            if args.report:
                monitor.save_report_to_file()
        else:
            # æŒç»­ç›‘æ§
            print("âŒ¨ï¸ æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
            try:
                while monitor.running:
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\nâ¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·")
                monitor.stop_monitoring()
                
                if args.report:
                    monitor.save_report_to_file()
                    
    except Exception as e:
        print(f"âŒ ç›‘æ§è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {e}")
        monitor.stop_monitoring()
    
    print("ğŸ‘‹ ç›‘æ§ç»“æŸ")

if __name__ == "__main__":
    main()