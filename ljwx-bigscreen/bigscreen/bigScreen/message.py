import json
from flask import request, jsonify
from .models import DeviceMessage, DeviceMessageDetail, db, DeviceInfo, UserInfo, UserOrg, OrgInfo
from .redis_helper import RedisHelper
from datetime import datetime, timedelta
from .org import fetch_departments_by_orgId
from typing import List, Dict, Optional, Tuple
import logging
import time
import uuid
from concurrent.futures import ThreadPoolExecutor
from functools import wraps

# å¯¼å…¥æ—¥å¿—é…ç½®
try:
    from .logging_config import device_logger
except ImportError:
    device_logger = logging.getLogger(__name__)

logger = logging.getLogger(__name__)
redis = RedisHelper()

# å¯¼å…¥ä¿®å¤åçš„V2ç»„ä»¶
try:
    from services.message_service_v2_fixed import MessageServiceV2Fixed, MessageServiceConfig
    from models.message_v2_fixed_model import (
        TDeviceMessageV2Fixed, MessageTypeEnum, MessageStatusEnum, 
        DeliveryStatusEnum, UrgencyEnum
    )
    from core.distributed_transaction_manager import (
        DistributedTransactionManager, TransactionStep
    )
    from monitoring.message_monitoring import (
        MessageSystemMetrics, monitor_api_request, monitor_database_query
    )
    V2_COMPONENTS_AVAILABLE = True
except ImportError as e:
    logger.warning(f"V2ç»„ä»¶æœªå¯ç”¨ï¼Œå›é€€åˆ°V1å®ç°: {e}")
    V2_COMPONENTS_AVAILABLE = False

# çº¿ç¨‹æ± ç”¨äºå¹¶å‘æ“ä½œ
executor = ThreadPoolExecutor(max_workers=10)

# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(operation_name: str):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                duration = (time.time() - start_time) * 1000
                logger.info(f"ğŸ“Š {operation_name} è€—æ—¶: {duration:.2f}ms")
                return result
            except Exception as e:
                duration = (time.time() - start_time) * 1000
                logger.error(f"âŒ {operation_name} å¤±è´¥: {e}, è€—æ—¶: {duration:.2f}ms")
                raise
        return wrapper
    return decorator

@monitor_performance("get_all_message_data_optimized")
def get_all_message_data_optimized(orgId=None, userId=None, startDate=None, endDate=None, latest_only=False, page=1, pageSize=None, message_type=None, include_details=False):
    """
    ç»Ÿä¸€çš„æ¶ˆæ¯æ•°æ®æŸ¥è¯¢æ¥å£ï¼Œæ”¯æŒåˆ†é¡µå’Œä¼˜åŒ–æŸ¥è¯¢
    
    Args:
        orgId: ç»„ç»‡ID
        userId: ç”¨æˆ·ID  
        startDate: å¼€å§‹æ—¥æœŸ
        endDate: ç»“æŸæ—¥æœŸ
        latest_only: æ˜¯å¦åªæŸ¥è¯¢æœ€æ–°è®°å½•
        page: é¡µç 
        pageSize: æ¯é¡µå¤§å°
        message_type: æ¶ˆæ¯ç±»å‹
        include_details: æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯
    
    Returns:
        dict: åŒ…å«æ¶ˆæ¯æ•°æ®å’Œåˆ†é¡µä¿¡æ¯çš„å­—å…¸
    """
    try:
        import time
        from datetime import datetime, timedelta
        start_time = time.time()
        
        # å‚æ•°éªŒè¯å’Œç¼“å­˜é”®æ„å»º
        page = max(1, int(page or 1))
        if pageSize is not None:
            pageSize = min(int(pageSize), 1000)
        else:
            pageSize = None
        mode = 'latest' if latest_only else 'range'
        cache_key = f"message_opt_v1:{orgId}:{userId}:{startDate}:{endDate}:{mode}:{page}:{pageSize}:{message_type}:{include_details}"
        
        # ç¼“å­˜æ£€æŸ¥ï¼ˆV2å¢å¼ºï¼‰
        cached = redis.get_data(cache_key)
        if cached:
            result = json.loads(cached)
            result['performance'] = {
                'cached': True, 
                'response_time': round(time.time() - start_time, 3),
                'cache_key': cache_key,
                'version': 'v2-enhanced'
            }
            logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_key}")
            return result
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = db.session.query(
            DeviceMessage.id,
            DeviceMessage.message,
            DeviceMessage.message_type,
            DeviceMessage.sender_type,
            DeviceMessage.receiver_type,
            DeviceMessage.message_status,
            DeviceMessage.send_time,
            DeviceMessage.received_time,
            DeviceMessage.user_id,
            DeviceMessage.org_id,
            DeviceMessage.responded_number,
            DeviceMessage.total_number,
            UserInfo.user_name,
            OrgInfo.name.label('org_name')
        ).outerjoin(
            UserInfo, DeviceMessage.user_id == UserInfo.id
        ).outerjoin(
            OrgInfo, DeviceMessage.org_id == OrgInfo.id
        ).filter(
            DeviceMessage.is_deleted == False
        )
        
        if userId:
            # å•ç”¨æˆ·æŸ¥è¯¢ - åŒ…æ‹¬ä¸ªäººæ¶ˆæ¯å’Œå‘ç»™ç»„ç»‡çš„ç¾¤å‘æ¶ˆæ¯
            from .admin_helper import is_admin_user
            if is_admin_user(userId):
                return {"success": True, "data": {"messageData": [], "totalRecords": 0, "pagination": {"currentPage": page, "pageSize": pageSize, "totalCount": 0, "totalPages": 0}}}
            
            # ğŸš€ ä¼˜åŒ–ï¼šç›´æ¥ä»ç”¨æˆ·è¡¨è·å–ç»„ç»‡IDï¼Œæ— éœ€å…³è”è¡¨æŸ¥è¯¢ï¼
            user_info = UserInfo.query.filter_by(id=userId).first()
            if user_info and user_info.org_id:
                org_id = user_info.org_id
                # è·å–ç»„ç»‡åŠå…¶æ‰€æœ‰ä¸Šçº§ç»„ç»‡çš„ID
                org_info = OrgInfo.query.filter_by(id=org_id).first()
                if org_info and org_info.ancestors:
                    ancestor_org_ids = [int(id) for id in org_info.ancestors.split(',') if id != '0']
                    ancestor_org_ids.append(org_id)
                else:
                    ancestor_org_ids = [org_id] if org_id else []
                
                # æŸ¥è¯¢ç”¨æˆ·ä¸ªäººæ¶ˆæ¯å’Œå…¬å‘Šæ¶ˆæ¯
                query = query.filter(
                    db.or_(
                        DeviceMessage.user_id == userId,  # ä¸ªäººæ¶ˆæ¯
                        db.and_(DeviceMessage.org_id.in_(ancestor_org_ids), DeviceMessage.user_id.is_(None))  # å…¬å‘Šæ¶ˆæ¯
                    )
                )
            else:
                # å¦‚æœç”¨æˆ·æ²¡æœ‰ç»„ç»‡å…³è”ï¼ŒåªæŸ¥ä¸ªäººæ¶ˆæ¯
                query = query.filter(DeviceMessage.user_id == userId)
                
        elif orgId:
            # ç»„ç»‡æŸ¥è¯¢ - è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·çš„æ¶ˆæ¯
            from .org import fetch_users_by_orgId
            users = fetch_users_by_orgId(orgId)
            if not users:
                return {"success": True, "data": {"messageData": [], "totalRecords": 0, "pagination": {"currentPage": page, "pageSize": pageSize, "totalCount": 0, "totalPages": 0}}}
            
            user_ids = [int(user['id']) for user in users]
            
            # è·å–æ‰€æœ‰ç›¸å…³ç»„ç»‡IDï¼ˆåŒ…æ‹¬å­éƒ¨é—¨ï¼‰
            departments_response = fetch_departments_by_orgId(orgId)
            subordinate_org_ids = []
            if departments_response['success'] and departments_response['data']:
                def extract_department_ids(departments):
                    dept_ids = []
                    for dept in departments:
                        dept_ids.append(int(dept['id']))
                        if 'children' in dept and dept['children']:
                            dept_ids.extend(extract_department_ids(dept['children']))
                    return dept_ids
                subordinate_org_ids = extract_department_ids(departments_response['data'])
            
            all_org_ids = list(set([orgId] + subordinate_org_ids))
            
            # æŸ¥è¯¢ç”¨æˆ·æ¶ˆæ¯å’Œç¾¤å‘æ¶ˆæ¯
            query = query.filter(
                db.or_(
                    DeviceMessage.user_id.in_(user_ids),  # ç”¨æˆ·æ¶ˆæ¯
                    db.and_(DeviceMessage.org_id.in_(all_org_ids), DeviceMessage.user_id.is_(None))  # ç¾¤å‘æ¶ˆæ¯
                )
            )
            
        else:
            return {"success": False, "message": "ç¼ºå°‘orgIdæˆ–userIdå‚æ•°", "data": {"messageData": [], "totalRecords": 0}}
        
        # æ—¶é—´èŒƒå›´è¿‡æ»¤
        if startDate:
            query = query.filter(DeviceMessage.send_time >= startDate)
        if endDate:
            query = query.filter(DeviceMessage.send_time <= endDate)
        
        # æ¶ˆæ¯ç±»å‹è¿‡æ»¤
        if message_type:
            query = query.filter(DeviceMessage.message_type == message_type)
        
        # ç»Ÿè®¡æ€»æ•°
        total_count = query.count()
        
        # æ’åº
        query = query.order_by(DeviceMessage.send_time.desc())
        
        # åˆ†é¡µå¤„ç†
        if pageSize is not None:
            offset = (page - 1) * pageSize
            query = query.offset(offset).limit(pageSize)
        
        if latest_only and not pageSize:
            query = query.limit(1)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        messages = query.all()
        
        # æ ¼å¼åŒ–æ•°æ®
        message_data_list = []
        for message in messages:
            message_dict = {
                'id': message.id,
                'message': message.message,
                'message_type': message.message_type,
                'sender_type': message.sender_type,
                'receiver_type': message.receiver_type,
                'message_status': message.message_status,
                'send_time': message.send_time.strftime('%Y-%m-%d %H:%M:%S') if message.send_time else None,
                'received_time': message.received_time.strftime('%Y-%m-%d %H:%M:%S') if message.received_time else None,
                'user_id': message.user_id,
                'org_id': message.org_id,
                'responded_number': message.responded_number or 0,
                'total_number': message.total_number or 0,
                'user_name': message.user_name,
                'org_name': message.org_name,
                'dept_name': message.org_name,  # å…¼å®¹å­—æ®µ
                'dept_id': message.org_id
            }
            
            # å¦‚æœéœ€è¦åŒ…å«è¯¦ç»†ä¿¡æ¯
            if include_details:
                message_dict['details'] = []  # å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ æ¶ˆæ¯ç›¸å…³è¯¦ç»†ä¿¡æ¯
            
            message_data_list.append(message_dict)
        
        # æ„å»ºåˆ†é¡µä¿¡æ¯
        pagination = {
            'currentPage': page,
            'pageSize': pageSize,
            'totalCount': total_count,
            'totalPages': (total_count + pageSize - 1) // pageSize if pageSize else 1
        }
        
        # æ„å»ºç»“æœ
        result = {
            'success': True,
            'data': {
                'messageData': message_data_list,
                'totalRecords': len(message_data_list),
                'pagination': pagination
            },
            'performance': {
                'cached': False,
                'response_time': round(time.time() - start_time, 3),
                'query_time': round(time.time() - start_time, 3)
            }
        }
        
        # ç¼“å­˜ç»“æœï¼ˆV2ä¼˜åŒ–TTLç­–ç•¥ï¼‰
        cache_ttl = 300  # é»˜è®¤5åˆ†é’Ÿ
        if latest_only:
            cache_ttl = 60   # æœ€æ–°æ•°æ®1åˆ†é’Ÿç¼“å­˜
        elif pageSize and pageSize <= 20:
            cache_ttl = 180  # å°åˆ†é¡µ3åˆ†é’Ÿç¼“å­˜
        
        redis.set_data(cache_key, json.dumps(result, default=str), cache_ttl)
        logger.debug(f"âœ… ç¼“å­˜è®¾ç½®: {cache_key}, TTL: {cache_ttl}s")
        
        return result
        
    except Exception as e:
        logger.error(f"æ¶ˆæ¯æŸ¥è¯¢å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'data': {'messageData': [], 'totalRecords': 0}
        }

class MessageService:
    """æ¶ˆæ¯ç®¡ç†ç»Ÿä¸€æœåŠ¡å°è£…ç±» - åŸºäºuserIdçš„æŸ¥è¯¢å’Œæ±‡æ€»"""
    
    def __init__(self):
        self.redis = redis
    
    def get_messages_by_common_params(self, customer_id: int = None, org_id: int = None,
                                    user_id: int = None, start_date: str = None, 
                                    end_date: str = None, message_type: str = None,
                                    page: int = 1, page_size: int = None,
                                    latest_only: bool = False, include_details: bool = False) -> Dict:
        """
        åŸºäºç»Ÿä¸€å‚æ•°è·å–æ¶ˆæ¯ä¿¡æ¯ - æ•´åˆç°æœ‰get_all_message_data_optimizedæ¥å£
        
        Args:
            customer_id: å®¢æˆ·ID (æ˜ å°„åˆ°orgId)
            org_id: ç»„ç»‡ID
            user_id: ç”¨æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            message_type: æ¶ˆæ¯ç±»å‹
            page: é¡µç 
            page_size: æ¯é¡µå¤§å°
            latest_only: æ˜¯å¦åªæŸ¥è¯¢æœ€æ–°è®°å½•
            include_details: æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯
            
        Returns:
            æ¶ˆæ¯ä¿¡æ¯å­—å…¸
        """
        try:
            # å‚æ•°æ˜ å°„å’Œä¼˜å…ˆçº§å¤„ç†
            if user_id:
                result = get_all_message_data_optimized(
                    orgId=None,
                    userId=user_id, 
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=latest_only,
                    page=page,
                    pageSize=page_size,
                    message_type=message_type,
                    include_details=include_details
                )
                logger.info(f"åŸºäºuserIdæŸ¥è¯¢æ¶ˆæ¯æ•°æ®: user_id={user_id}")
                
            elif org_id:
                # ç»„ç»‡æŸ¥è¯¢ - è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·çš„æ¶ˆæ¯
                result = get_all_message_data_optimized(
                    orgId=org_id,
                    userId=None,
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=latest_only,
                    page=page,
                    pageSize=page_size,
                    message_type=message_type,
                    include_details=include_details
                )
                logger.info(f"åŸºäºorgIdæŸ¥è¯¢æ¶ˆæ¯æ•°æ®: org_id={org_id}")
                
            elif customer_id:
                # å®¢æˆ·æŸ¥è¯¢ - å°†customer_idä½œä¸ºorgIdå¤„ç†
                result = get_all_message_data_optimized(
                    orgId=customer_id,
                    userId=None,
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=latest_only,
                    page=page,
                    pageSize=page_size,
                    message_type=message_type,
                    include_details=include_details
                )
                logger.info(f"åŸºäºcustomerIdæŸ¥è¯¢æ¶ˆæ¯æ•°æ®: customer_id={customer_id}")
                
            else:
                return {
                    'success': False,
                    'error': 'Missing required parameters: customer_id, org_id, or user_id',
                    'data': {'messages': [], 'total_count': 0}
                }
            
            # ç»Ÿä¸€è¿”å›æ ¼å¼ï¼Œå…¼å®¹æ–°çš„æœåŠ¡æ¥å£
            if result.get('success', True):
                message_data = result.get('data', {}).get('messageData', [])
                
                unified_result = {
                    'success': True,
                    'data': {
                        'messages': message_data,
                        'total_count': result.get('data', {}).get('totalRecords', len(message_data)),
                        'pagination': result.get('data', {}).get('pagination', {}),
                        'query_params': {
                            'customer_id': customer_id,
                            'org_id': org_id,
                            'user_id': user_id,
                            'start_date': start_date,
                            'end_date': end_date,
                            'message_type': message_type,
                            'page': page,
                            'page_size': page_size,
                            'latest_only': latest_only,
                            'include_details': include_details
                        }
                    },
                    'performance': result.get('performance', {}),
                    'from_cache': result.get('performance', {}).get('cached', False)
                }
                
                return unified_result
            else:
                return result
                
        except Exception as e:
            logger.error(f"æ¶ˆæ¯æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'data': {'messages': [], 'total_count': 0}
            }
    
    def _get_messages_by_user_id(self, user_id: int, start_date: str = None,
                                end_date: str = None, message_type: str = None) -> List[Dict]:
        """åŸºäºç”¨æˆ·IDæŸ¥è¯¢æ¶ˆæ¯"""
        try:
            # æŸ¥è¯¢ç”¨æˆ·ç›¸å…³çš„æ¶ˆæ¯
            query = db.session.query(
                DeviceMessage.id,
                DeviceMessage.message,
                DeviceMessage.message_type,
                DeviceMessage.sender_type,
                DeviceMessage.receiver_type,
                DeviceMessage.message_status,
                DeviceMessage.send_time,
                DeviceMessage.received_time,
                DeviceMessage.user_id,
                DeviceMessage.org_id,
                DeviceMessage.responded_number,
                DeviceMessage.total_number,
                UserInfo.user_name,
                OrgInfo.name.label('org_name')
            ).outerjoin(
                UserInfo, DeviceMessage.user_id == UserInfo.id
            ).outerjoin(
                OrgInfo, DeviceMessage.org_id == OrgInfo.id
            ).filter(
                DeviceMessage.user_id == user_id
            )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(DeviceMessage.send_time >= start_date)
            if end_date:
                query = query.filter(DeviceMessage.send_time <= end_date)
            if message_type:
                query = query.filter(DeviceMessage.message_type == message_type)
            
            results = query.order_by(DeviceMessage.send_time.desc()).all()
            
            messages = []
            for result in results:
                messages.append(self._format_message_data(result))
            
            return messages
            
        except Exception as e:
            logger.error(f"åŸºäºç”¨æˆ·IDæŸ¥è¯¢æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    def _get_messages_by_org_id(self, org_id: int, customer_id: int = None,
                               start_date: str = None, end_date: str = None,
                               message_type: str = None) -> List[Dict]:
        """åŸºäºç»„ç»‡IDæŸ¥è¯¢æ¶ˆæ¯"""
        try:
            # è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·
            from .org import fetch_users_by_orgId
            users = fetch_users_by_orgId(org_id, customer_id)
            
            if not users:
                # æ²¡æœ‰ç”¨æˆ·æ—¶ï¼ŒæŸ¥è¯¢å‘é€ç»™ç»„ç»‡çš„ç¾¤å‘æ¶ˆæ¯
                query = db.session.query(
                    DeviceMessage.id,
                    DeviceMessage.message,
                    DeviceMessage.message_type,
                    DeviceMessage.sender_type,
                    DeviceMessage.receiver_type,
                    DeviceMessage.message_status,
                    DeviceMessage.send_time,
                    DeviceMessage.received_time,
                    DeviceMessage.user_id,
                    DeviceMessage.org_id,
                    DeviceMessage.responded_number,
                    DeviceMessage.total_number,
                    UserInfo.user_name,
                    OrgInfo.name.label('org_name')
                ).outerjoin(
                    UserInfo, DeviceMessage.user_id == UserInfo.id
                ).outerjoin(
                    OrgInfo, DeviceMessage.org_id == OrgInfo.id
                ).filter(
                    DeviceMessage.org_id == org_id,
                    DeviceMessage.user_id.is_(None)  # ç¾¤å‘æ¶ˆæ¯
                )
            else:
                user_ids = [int(user['id']) for user in users]
                
                # æŸ¥è¯¢ç”¨æˆ·æ¶ˆæ¯å’Œç¾¤å‘æ¶ˆæ¯
                query = db.session.query(
                    DeviceMessage.id,
                    DeviceMessage.message,
                    DeviceMessage.message_type,
                    DeviceMessage.sender_type,
                    DeviceMessage.receiver_type,
                    DeviceMessage.message_status,
                    DeviceMessage.send_time,
                    DeviceMessage.received_time,
                    DeviceMessage.user_id,
                    DeviceMessage.org_id,
                    DeviceMessage.responded_number,
                    DeviceMessage.total_number,
                    UserInfo.user_name,
                    OrgInfo.name.label('org_name')
                ).outerjoin(
                    UserInfo, DeviceMessage.user_id == UserInfo.id
                ).outerjoin(
                    OrgInfo, DeviceMessage.org_id == OrgInfo.id
                ).filter(
                    db.or_(
                        DeviceMessage.user_id.in_(user_ids),
                        db.and_(DeviceMessage.org_id == org_id, DeviceMessage.user_id.is_(None))
                    )
                )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(DeviceMessage.send_time >= start_date)
            if end_date:
                query = query.filter(DeviceMessage.send_time <= end_date)
            if message_type:
                query = query.filter(DeviceMessage.message_type == message_type)
            
            results = query.order_by(DeviceMessage.send_time.desc()).all()
            
            messages = []
            for result in results:
                messages.append(self._format_message_data(result))
            
            return messages
            
        except Exception as e:
            logger.error(f"åŸºäºç»„ç»‡IDæŸ¥è¯¢æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    def _get_messages_by_customer_id(self, customer_id: int, start_date: str = None,
                                    end_date: str = None, message_type: str = None) -> List[Dict]:
        """åŸºäºå®¢æˆ·IDæŸ¥è¯¢æ¶ˆæ¯"""
        try:
            # é€šè¿‡ç”¨æˆ·è¡¨çš„customer_idæŸ¥è¯¢
            query = db.session.query(
                DeviceMessage.id,
                DeviceMessage.message,
                DeviceMessage.message_type,
                DeviceMessage.sender_type,
                DeviceMessage.receiver_type,
                DeviceMessage.message_status,
                DeviceMessage.send_time,
                DeviceMessage.received_time,
                DeviceMessage.user_id,
                DeviceMessage.org_id,
                DeviceMessage.responded_number,
                DeviceMessage.total_number,
                UserInfo.user_name,
                OrgInfo.name.label('org_name')
            ).outerjoin(
                UserInfo, DeviceMessage.user_id == UserInfo.id
            ).outerjoin(
                OrgInfo, DeviceMessage.org_id == OrgInfo.id
            ).filter(
                db.or_(
                    UserInfo.customer_id == customer_id,
                    db.and_(DeviceMessage.user_id.is_(None), OrgInfo.customer_id == customer_id)
                )
            )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(DeviceMessage.send_time >= start_date)
            if end_date:
                query = query.filter(DeviceMessage.send_time <= end_date)
            if message_type:
                query = query.filter(DeviceMessage.message_type == message_type)
            
            results = query.order_by(DeviceMessage.send_time.desc()).all()
            
            messages = []
            for result in results:
                messages.append(self._format_message_data(result))
            
            return messages
            
        except Exception as e:
            logger.error(f"åŸºäºå®¢æˆ·IDæŸ¥è¯¢æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    def _format_message_data(self, result) -> Dict:
        """æ ¼å¼åŒ–æ¶ˆæ¯æ•°æ®"""
        return {
            'id': result.id,
            'message': result.message,
            'message_type': result.message_type,
            'sender_type': result.sender_type,
            'receiver_type': result.receiver_type,
            'message_status': result.message_status,
            'send_time': result.send_time.strftime('%Y-%m-%d %H:%M:%S') if result.send_time else None,
            'received_time': result.received_time.strftime('%Y-%m-%d %H:%M:%S') if result.received_time else None,
            'user_id': result.user_id,
            'org_id': result.org_id,
            'responded_number': result.responded_number or 0,
            'total_number': result.total_number or 0,
            'user_name': result.user_name,
            'org_name': result.org_name
        }
    
    def get_message_statistics_by_common_params(self, customer_id: int = None,
                                               org_id: int = None, user_id: int = None,
                                               start_date: str = None, end_date: str = None) -> Dict:
        """åŸºäºç»Ÿä¸€å‚æ•°è·å–æ¶ˆæ¯ç»Ÿè®¡"""
        try:
            cache_key = f"message_stats_v2:{customer_id}:{org_id}:{user_id}:{start_date}:{end_date}"
            
            # ç¼“å­˜æ£€æŸ¥
            cached = self.redis.get_data(cache_key)
            if cached:
                return json.loads(cached)
            
            # è·å–æ¶ˆæ¯æ•°æ®
            messages_result = self.get_messages_by_common_params(
                customer_id, org_id, user_id, start_date, end_date
            )
            
            if not messages_result.get('success'):
                return messages_result
            
            messages = messages_result['data']['messages']
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            total_messages = len(messages)
            type_stats = {}
            status_stats = {'pending': 0, 'sent': 0, 'received': 0, 'responded': 0}
            response_stats = {'total_sent': 0, 'total_responded': 0}
            
            for message in messages:
                # æ¶ˆæ¯ç±»å‹ç»Ÿè®¡
                msg_type = message.get('message_type', 'unknown')
                if msg_type not in type_stats:
                    type_stats[msg_type] = 0
                type_stats[msg_type] += 1
                
                # æ¶ˆæ¯çŠ¶æ€ç»Ÿè®¡
                status = message.get('message_status', 'pending')
                if status in status_stats:
                    status_stats[status] += 1
                
                # å“åº”ç»Ÿè®¡
                total_num = message.get('total_number', 0)
                responded_num = message.get('responded_number', 0)
                response_stats['total_sent'] += total_num
                response_stats['total_responded'] += responded_num
            
            # æŒ‰ç»„ç»‡ç»Ÿè®¡
            org_stats = {}
            for message in messages:
                org_name = message.get('org_name', 'æœªçŸ¥ç»„ç»‡')
                if org_name not in org_stats:
                    org_stats[org_name] = {
                        'total': 0,
                        'pending': 0,
                        'responded': 0,
                        'response_rate': 0
                    }
                
                org_stats[org_name]['total'] += 1
                status = message.get('message_status', 'pending')
                if status == 'pending':
                    org_stats[org_name]['pending'] += 1
                elif status in ['responded', 'received']:
                    org_stats[org_name]['responded'] += 1
            
            # è®¡ç®—å“åº”ç‡
            for org_name in org_stats:
                total = org_stats[org_name]['total']
                responded = org_stats[org_name]['responded']
                org_stats[org_name]['response_rate'] = round(responded / total * 100, 2) if total > 0 else 0
            
            result = {
                'success': True,
                'data': {
                    'overview': {
                        'total_messages': total_messages,
                        'type_stats': type_stats,
                        'status_stats': status_stats,
                        'response_stats': response_stats,
                        'overall_response_rate': round(response_stats['total_responded'] / response_stats['total_sent'] * 100, 2) if response_stats['total_sent'] > 0 else 0
                    },
                    'org_statistics': org_stats,
                    'query_params': {
                        'customer_id': customer_id,
                        'org_id': org_id,
                        'user_id': user_id,
                        'start_date': start_date,
                        'end_date': end_date
                    }
                }
            }
            
            # ç¼“å­˜ç»“æœ
            self.redis.set_data(cache_key, json.dumps(result, default=str), 180)
            
            return result
            
        except Exception as e:
            logger.error(f"æ¶ˆæ¯ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'data': {'overview': {}, 'org_statistics': {}}
            }

# V2å¢å¼ºï¼šå…¨å±€å®ä¾‹å’Œæ€§èƒ½ç›‘æ§
_message_service_instance = None
_message_service_v2_instance = None
_monitoring_instance = None

@monitor_performance("get_unified_message_service")
def get_unified_message_service() -> MessageService:
    """è·å–ç»Ÿä¸€æ¶ˆæ¯æœåŠ¡å®ä¾‹"""
    global _message_service_instance
    if _message_service_instance is None:
        _message_service_instance = MessageService()
        logger.info("âœ… ç»Ÿä¸€æ¶ˆæ¯æœåŠ¡å®ä¾‹åˆ›å»ºå®Œæˆ")
    return _message_service_instance

def get_v2_message_service():
    """V2å¢å¼ºï¼šè·å–V2æ¶ˆæ¯æœåŠ¡å®ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    global _message_service_v2_instance
    
    if not V2_COMPONENTS_AVAILABLE:
        logger.warning("V2ç»„ä»¶ä¸å¯ç”¨ï¼Œè¿”å›None")
        return None
    
    if _message_service_v2_instance is None:
        try:
            from services.message_service_v2_fixed import MessageServiceV2Fixed
            _message_service_v2_instance = MessageServiceV2Fixed()
            logger.info("âœ… V2æ¶ˆæ¯æœåŠ¡å®ä¾‹åˆ›å»ºå®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ V2æ¶ˆæ¯æœåŠ¡å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    return _message_service_v2_instance

def get_monitoring_instance():
    """V2å¢å¼ºï¼šè·å–ç›‘æ§å®ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    global _monitoring_instance
    
    if not V2_COMPONENTS_AVAILABLE:
        return None
    
    if _monitoring_instance is None:
        try:
            from monitoring.message_monitoring import MessageSystemMonitor
            _monitoring_instance = MessageSystemMonitor()
            _monitoring_instance.start()
            logger.info("âœ… æ¶ˆæ¯ç³»ç»Ÿç›‘æ§å®ä¾‹åˆ›å»ºå®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç›‘æ§å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    return _monitoring_instance

# V2å¢å¼ºï¼šæ€§èƒ½ç¼“å­˜ç®¡ç†å™¨
class MessageCacheManager:
    """V2å¢å¼ºæ¶ˆæ¯ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.redis = redis
        self.cache_prefix = "message_v2_cache"
    
    def get_cache_key(self, operation: str, **params) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        param_str = ":".join(f"{k}={v}" for k, v in sorted(params.items()) if v is not None)
        return f"{self.cache_prefix}:{operation}:{param_str}"
    
    def get_with_fallback(self, cache_key: str, fallback_func: callable, ttl: int = 300, **kwargs):
        """ç¼“å­˜è·å–ä¸å›é€€æœºåˆ¶"""
        try:
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = self.redis.get_data(cache_key)
            if cached_data:
                logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
                return json.loads(cached_data)
        except Exception as e:
            logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå›é€€å‡½æ•°
        try:
            result = fallback_func(**kwargs)
            
            # ç¼“å­˜ç»“æœ
            try:
                self.redis.set_data(cache_key, json.dumps(result, default=str), ttl)
                logger.debug(f"ç¼“å­˜è®¾ç½®æˆåŠŸ: {cache_key}, TTL: {ttl}s")
            except Exception as e:
                logger.warning(f"ç¼“å­˜è®¾ç½®å¤±è´¥: {e}")
            
            return result
            
        except Exception as e:
            logger.error(f"å›é€€å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯å¼‚å¸¸
            return {
                'success': False,
                'error': str(e),
                'data': {'messages': [], 'total_count': 0}
            }
    
    def invalidate_pattern(self, pattern: str):
        """æ ¹æ®æ¨¡å¼æ¸…ç†ç¼“å­˜"""
        try:
            keys = self.redis.keys(f"{self.cache_prefix}:{pattern}")
            if keys:
                self.redis.delete(*keys)
                logger.debug(f"ç¼“å­˜æ¸…ç†å®Œæˆ: {len(keys)} ä¸ªé”®")
        except Exception as e:
            logger.warning(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {pattern}, é”™è¯¯: {e}")

# V2å¢å¼ºï¼šå…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_cache_manager_instance = None

def get_cache_manager() -> MessageCacheManager:
    """è·å–ç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _cache_manager_instance
    if _cache_manager_instance is None:
        _cache_manager_instance = MessageCacheManager()
        logger.info("âœ… æ¶ˆæ¯ç¼“å­˜ç®¡ç†å™¨å®ä¾‹åˆ›å»ºå®Œæˆ")
    return _cache_manager_instance

# å‘åå…¼å®¹çš„å‡½æ•°ï¼Œä¾›ç°æœ‰ä»£ç ä½¿ç”¨
def get_messages_unified(customer_id: int = None, org_id: int = None,
                        user_id: int = None, start_date: str = None,
                        end_date: str = None, message_type: str = None,
                        page: int = 1, page_size: int = None,
                        latest_only: bool = False, include_details: bool = False) -> Dict:
    """ç»Ÿä¸€çš„æ¶ˆæ¯æŸ¥è¯¢æ¥å£ - æ•´åˆç°æœ‰get_all_message_data_optimizedæ¥å£"""
    service = get_unified_message_service()
    return service.get_messages_by_common_params(
        customer_id, org_id, user_id, start_date, end_date, message_type,
        page, page_size, latest_only, include_details
    )

def get_message_statistics_unified(customer_id: int = None, org_id: int = None,
                                  user_id: int = None, start_date: str = None,
                                  end_date: str = None) -> Dict:
    """ç»Ÿä¸€çš„æ¶ˆæ¯ç»Ÿè®¡æ¥å£"""
    service = get_unified_message_service()
    return service.get_message_statistics_by_common_params(customer_id, org_id, user_id, start_date, end_date)
@monitor_performance("send_message_enhanced")
def send_message(data):
    """
    V2å¢å¼ºç‰ˆæ¶ˆæ¯å‘é€å¤„ç†
    æ”¯æŒåˆ†å¸ƒå¼äº‹åŠ¡å’Œæ€§èƒ½ç›‘æ§
    """
    logger.info("DeviceMessage:send_message V2", data)
    
    # V2å¢å¼ºï¼šåˆ›å»ºäº‹åŠ¡ç®¡ç†å™¨
    transaction_manager = None
    if V2_COMPONENTS_AVAILABLE:
        try:
            transaction_manager = DistributedTransactionManager()
            transaction_id = transaction_manager.start_transaction({
                'operation': 'send_message',
                'message_id': data.get('message_id'),
                'device_sn': data.get('device_sn')
            })
        except Exception as e:
            logger.warning(f"åˆ†å¸ƒå¼äº‹åŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼: {e}")
    
    # æ•°æ®éªŒè¯å¢å¼º
    required_fields = ['department_id','message_id', 'message', 'device_sn', 'received_time', 'user_id']
    missing_fields = [field for field in required_fields if field not in data]
    if missing_fields:
        error_msg = f"Missing required fields: {missing_fields}"
        logger.error(error_msg)
        return jsonify({"status": "error", "message": error_msg}), 400

    message_id = data.get('message_id')
    device_sn = data.get('device_sn')
    
    # V2å¢å¼ºï¼šç¼“å­˜æ£€æŸ¥
    cache_key = f"message_send_lock:{message_id}:{device_sn}"
    if redis.exists(cache_key):
        logger.warning(f"é‡å¤æ¶ˆæ¯å‘é€è¯·æ±‚è¢«æ‹’ç»: {message_id}:{device_sn}")
        return jsonify({"status": "error", "message": "Duplicate message processing"}), 409
    
    try:
        # è®¾ç½®å¤„ç†é”ï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
        redis.setex(cache_key, 300, "processing")
        
        if message_id:
            message = DeviceMessage.query.get(message_id)
            logger.debug(f"æŸ¥è¯¢åˆ°æ¶ˆæ¯: {message}")
            
            if message:
                # V2å¢å¼ºï¼šå¹¶å‘å®‰å…¨çš„æ¶ˆæ¯å¤„ç†
                with db.session.begin():
                    if message.user_id is None:
                        # ç¾¤å‘æ¶ˆæ¯å¤„ç†
                        logger.info("å¤„ç†ç¾¤å‘æ¶ˆæ¯")
                        existing_detail = DeviceMessageDetail.query.filter_by(
                            message_id=message_id,
                            device_sn=device_sn
                        ).first()
                        
                        if not existing_detail:
                            # V2å¢å¼ºï¼šä½¿ç”¨æ‰¹é‡æ’å…¥ä¼˜åŒ–
                            message_detail = DeviceMessageDetail(
                                message_id=message_id,
                                device_sn=device_sn,
                                message=data['message'],
                                message_type=data.get('message_type', 'notification'),
                                sender_type=data.get('sender_type', 'device'),
                                receiver_type=data.get('receiver_type', 'platform'),
                                message_status=data.get('message_status', '2')
                            )
                            db.session.add(message_detail)
                            
                            # åŸå­æ€§å¢åŠ å“åº”è®¡æ•°
                            message.responded_number = (message.responded_number or 0) + 1
                            
                            # V2å¢å¼ºï¼šè®°å½•æ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸ
                            if V2_COMPONENTS_AVAILABLE:
                                try:
                                    lifecycle_event = {
                                        'message_id': message_id,
                                        'device_sn': device_sn,
                                        'event_type': 'acknowledged',
                                        'event_time': datetime.now(),
                                        'metadata': {'response_time': data.get('received_time')}
                                    }
                                    # è®°å½•åˆ°Redisæµç”¨äºåç»­å¤„ç†
                                    redis.xadd('message_lifecycle_stream', lifecycle_event)
                                except Exception as e:
                                    logger.warning(f"ç”Ÿå‘½å‘¨æœŸè®°å½•å¤±è´¥: {e}")
                    else:
                        # ä¸ªäººæ¶ˆæ¯å¤„ç†
                        logger.info("å¤„ç†ä¸ªäººæ¶ˆæ¯")
                        user = UserInfo.query.filter_by(id=message.user_id, is_deleted=0).first()
                        
                        if user and user.device_sn == device_sn:
                            # æ›´æ–°æ¶ˆæ¯çŠ¶æ€
                            message.message_status = '2'  # å·²å“åº”
                            
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å“åº”è®°å½•
                            existing_detail = DeviceMessageDetail.query.filter_by(
                                message_id=message_id,
                                device_sn=device_sn
                            ).first()
                            
                            if not existing_detail:
                                message_detail = DeviceMessageDetail(
                                    message_id=message_id,
                                    device_sn=device_sn,
                                    message=data['message'],
                                    message_type=data.get('message_type', 'notification'),
                                    sender_type=data.get('sender_type', 'device'),
                                    receiver_type=data.get('receiver_type', 'platform'),
                                    message_status='2'  # å·²å“åº”
                                )
                                db.session.add(message_detail)
                    
                    # æ›´æ–°æ¥æ”¶æ—¶é—´
                    message.received_time = data['received_time']
                    
                # V2å¢å¼ºï¼šæ¸…ç†ç›¸å…³ç¼“å­˜
                cache_keys_to_delete = [
                    f"message_opt_v1:*:{message.user_id}:*",
                    f"message_opt_v1:{message.org_id}:*:*",
                    f"department_user_messages:{message.org_id}:{message.user_id}"
                ]
                
                for pattern in cache_keys_to_delete:
                    try:
                        keys = redis.keys(pattern)
                        if keys:
                            redis.delete(*keys)
                    except Exception as e:
                        logger.warning(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {pattern}, é”™è¯¯: {e}")
                
                # V2å¢å¼ºï¼šå®Œæˆåˆ†å¸ƒå¼äº‹åŠ¡
                if transaction_manager:
                    try:
                        transaction_manager.commit_transaction(transaction_id)
                    except Exception as e:
                        logger.warning(f"åˆ†å¸ƒå¼äº‹åŠ¡æäº¤å¤±è´¥: {e}")
                
                logger.info(f"æ¶ˆæ¯å¤„ç†å®Œæˆ: {message.id}")
                return jsonify({"status": "success", "message": "æ•°æ®å·²æ¥æ”¶å¹¶å¤„ç†", "id": message.id}), 200
            else:
                return jsonify({"status": "error", "message": "Message not found"}), 404
        else:
            logger.error("æ•°æ®æœ‰è¯¯ï¼Œæ‰‹è¡¨å›å¤äº†ä¸å­˜åœ¨çš„æ¶ˆæ¯")
            return jsonify({"status": "error", "message": "æ•°æ®æœ‰è¯¯ï¼Œæ‰‹è¡¨å›å¤äº†ä¸å­˜åœ¨çš„æ¶ˆæ¯"}), 400
            
    except Exception as e:
        logger.error(f"æ¶ˆæ¯å‘é€å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
        
        # V2å¢å¼ºï¼šäº‹åŠ¡å›æ»š
        if transaction_manager:
            try:
                transaction_manager.rollback_transaction(transaction_id, str(e))
            except Exception as rollback_e:
                logger.error(f"äº‹åŠ¡å›æ»šå¤±è´¥: {rollback_e}")
        
        return jsonify({"status": "error", "message": f"å¤„ç†å¼‚å¸¸: {str(e)}"}), 500
    finally:
        # æ¸…ç†å¤„ç†é”
        try:
            redis.delete(cache_key)
        except Exception as e:
            logger.warning(f"æ¸…ç†å¤„ç†é”å¤±è´¥: {e}")
    
@monitor_performance("received_messages_enhanced")
def received_messages(device_sn):
    """
    V2å¢å¼ºç‰ˆæ¶ˆæ¯æ¥æ”¶å¤„ç†
    ä¼˜åŒ–ç¼“å­˜ç­–ç•¥å’Œæ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
    """
    if not device_sn:
        return {"success": False, "error": "device_sn is required"}
    
    # V2å¢å¼ºï¼šæ™ºèƒ½ç¼“å­˜ç­–ç•¥
    cache_key = f"received_messages_v2:{device_sn}"
    
    try:
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_result = redis.get_data(cache_key)
        if cached_result:
            logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
            return json.loads(cached_result)
    except Exception as e:
        logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
    
    try:
        # 1. V2å¢å¼ºï¼šä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢
        user = UserInfo.query.filter_by(
            device_sn=device_sn, 
            is_deleted=0
        ).with_entities(UserInfo.id, UserInfo.org_id, UserInfo.user_name).first()
        
        if not user:
            error_result = {"success": False, "error": "æœªæ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·"}
            # ç¼“å­˜é”™è¯¯ç»“æœ30ç§’
            redis.setex(cache_key, 30, json.dumps(error_result))
            return error_result

        user_id = user.id
        logger.debug(f"ç”¨æˆ·ä¿¡æ¯: user_id={user_id}, org_id={user.org_id}")

        # 2. V2å¢å¼ºï¼šä½¿ç”¨ä¼˜åŒ–çš„æ¶ˆæ¯æŸ¥è¯¢æ¥å£
        resp = get_all_message_data_optimized(
            userId=user_id,
            latest_only=False,
            page=1,
            pageSize=50,  # é™åˆ¶è¿”å›æ•°é‡æé«˜æ€§èƒ½
            include_details=False
        )
        
        if not resp.get("success", True):
            return {"success": False, "error": "è·å–æ¶ˆæ¯å¤±è´¥"}

        # 3. V2å¢å¼ºï¼šæ™ºèƒ½æ•°æ®è§£æ
        raw_data = resp.get("data", {})
        messages = raw_data.get("messageData", [])
        
        # 4. V2å¢å¼ºï¼šé«˜æ•ˆè¿‡æ»¤ç®—æ³•
        # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ç›¸å…³çš„DeviceMessageDetail
        message_ids = [str(m.get("id", m.get("message_id", ""))) for m in messages if m.get("id") or m.get("message_id")]
        
        acknowledged_message_ids = set()
        if message_ids:
            try:
                acknowledged_details = DeviceMessageDetail.query.filter(
                    DeviceMessageDetail.message_id.in_(message_ids),
                    DeviceMessageDetail.device_sn == device_sn
                ).with_entities(DeviceMessageDetail.message_id).all()
                
                acknowledged_message_ids = {str(detail.message_id) for detail in acknowledged_details}
                logger.debug(f"å·²ç¡®è®¤æ¶ˆæ¯IDs: {acknowledged_message_ids}")
            except Exception as e:
                logger.warning(f"æŸ¥è¯¢å·²ç¡®è®¤æ¶ˆæ¯å¤±è´¥: {e}")
        
        # 5. V2å¢å¼ºï¼šæ™ºèƒ½è¿‡æ»¤ç­–ç•¥
        filtered_messages = []
        for msg in messages:
            msg_id = str(msg.get("id", msg.get("message_id", "")))
            msg_status = msg.get("message_status", "")
            
            # è¿‡æ»¤æ¡ä»¶ï¼š
            # 1. æ¶ˆæ¯çŠ¶æ€ä¸æ˜¯å·²å“åº”
            # 2. æ²¡æœ‰åœ¨DeviceMessageDetailä¸­æ‰¾åˆ°ç¡®è®¤è®°å½•
            if (msg_status not in ("2", "responded", "acknowledged") and 
                msg_id not in acknowledged_message_ids):
                
                # V2å¢å¼ºï¼šæ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
                cleaned_msg = {
                    'message_id': msg_id,
                    'department_id': msg.get('dept_id', msg.get('org_id', '')),
                    'department_name': msg.get('dept_name', msg.get('org_name', '')),
                    'user_id': msg.get('user_id'),
                    'user_name': msg.get('user_name'),
                    'message': msg.get('message', ''),
                    'message_type': msg.get('message_type', 'notification'),
                    'message_status': msg_status,
                    'send_time': msg.get('send_time'),
                    'sender_type': msg.get('sender_type', 'system'),
                    'receiver_type': msg.get('receiver_type', 'device'),
                    'is_public': msg.get('is_public', False)
                }
                filtered_messages.append(cleaned_msg)
        
        # 6. V2å¢å¼ºï¼šæ„å»ºç»“æœ
        result = {
            "success": True,
            "data": {
                "messages": filtered_messages,
                "total_count": len(filtered_messages),
                "user_info": {
                    "user_id": user_id,
                    "user_name": user.user_name,
                    "org_id": user.org_id
                },
                "device_sn": device_sn,
                "timestamp": datetime.now().isoformat(),
                "version": "v2-enhanced"
            }
        }
        
        # V2å¢å¼ºï¼šæ™ºèƒ½ç¼“å­˜TTLç­–ç•¥
        cache_ttl = 60  # é»˜è®¤ç¼“å­˜1åˆ†é’Ÿ
        if len(filtered_messages) == 0:
            cache_ttl = 30  # ç©ºç»“æœçŸ­ç¼“å­˜
        elif len(filtered_messages) > 10:
            cache_ttl = 90  # å¤§é‡æ¶ˆæ¯é•¿ç¼“å­˜
        
        try:
            redis.setex(cache_key, cache_ttl, json.dumps(result, default=str))
            logger.debug(f"ç¼“å­˜è®¾ç½®æˆåŠŸ: {cache_key}, TTL: {cache_ttl}s")
        except Exception as e:
            logger.warning(f"ç¼“å­˜è®¾ç½®å¤±è´¥: {e}")
        
        logger.info(f"æ¶ˆæ¯æ¥æ”¶å¤„ç†å®Œæˆ: device_sn={device_sn}, è¿‡æ»¤åæ¶ˆæ¯æ•°={len(filtered_messages)}")
        return result
        
    except Exception as e:
        logger.error(f"æ¶ˆæ¯æ¥æ”¶å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
        error_result = {
            "success": False, 
            "error": f"å¤„ç†å¼‚å¸¸: {str(e)}",
            "data": {"messages": []}
        }
        
        # é”™è¯¯ç»“æœä¹ŸçŸ­æ—¶ç¼“å­˜ï¼Œé¿å…é‡å¤å¤„ç†
        try:
            redis.setex(cache_key, 15, json.dumps(error_result))
        except:
            pass
            
        return error_result
    

def send_message_bak(data):
    print("DeviceMessage:send_message", data)

    # Check if all required fields are present
    required_fields = ['device_sn','id', 'message', 'message_type', 'sender_type', 'receiver_type']
    if not all(field in data for field in required_fields):
        return jsonify({"status": "error", "message": "Missing required fields"}), 400

    # Check if message_id is present to update the existing message
    message_id = data.get('id')
    
    print("message_id:", message_id)
    if message_id:
        message = DeviceMessage.query.get(message_id)
        print("message:", message)
        if message:
            if message.device_sn == 'all':
                print("message.device_sn:", message.device_sn)
                # Check if the message detail already exists
                existing_detail = DeviceMessageDetail.query.filter_by(
                    message_id=message_id,
                    device_sn=data['device_sn']
                ).first()

                if not existing_detail:
                    # Insert into DeviceMessageDetail if it doesn't exist
                    message_detail = DeviceMessageDetail(
                        message_id=message_id,
                        device_sn=data['device_sn'],
                        message=data['message'],
                        message_type=data['message_type'],
                        sender_type=data['sender_type'],
                        receiver_type=data['receiver_type'],
                        message_status=data['message_status']
                    )
                    db.session.add(message_detail)
                    print("message.responded_number:", message.responded_number)
                    message.responded_number = message.responded_number + 1
            else:
                message.device_sn = data['device_sn']
                message.message = data['message']
                message.message_type = data['message_type']
                message.sender_type = data['sender_type']
                message.receiver_type = data['receiver_type']
                message.message_status = data['message_status']

                # Convert sent_time and received_time to MySQL compatible format
                sent_time_str = data.get('sent_time')
                received_time_str = data.get('received_time')
                if sent_time_str:
                    message.sent_time = datetime.strptime(sent_time_str, '%a, %d %b %Y %H:%M:%S GMT')
                if received_time_str:
                    message.received_time = datetime.fromisoformat(received_time_str.replace('Z', '+00:00'))

            db.session.commit()
            return jsonify({"status": "success", "message": "æ•°æ®å·²æ¥æ”¶å¹¶å¤„ç†", "id": message.id}), 200
        else:
            return jsonify({"status": "error", "message": "Message not found"}), 404
    else:
        # Create a new message if message_id is not provided
        message = DeviceMessage(
            device_sn=data['device_sn'],
            message=data['message'],
            message_type=data['message_type'],
            sender_type=data['sender_type'],
            receiver_type=data['receiver_type'],
            message_status=data['message_status']
        )
        db.session.add(message)
        db.session.commit()
        return jsonify({"status": "success", "message": "æ•°æ®å·²æ¥æ”¶å¹¶å¤„ç†", "message_id": message.id}), 201    
def received_messages_bak(device_sn):
    # Modify the query to filter by device_sn or 'all' and check for non-existence in DeviceMessageDetail
    messages = DeviceMessage.query.filter(
        ((DeviceMessage.device_sn == device_sn) | 
         ((DeviceMessage.device_sn == 'all')  & 
          ~DeviceMessageDetail.query.filter_by(
              device_sn=device_sn, 
              message_id=DeviceMessage.id
          ).exists())),
        DeviceMessage.message_status == 'pending' or DeviceMessage.message_status == '1'
    ).all()
    
    messages_data = [{
        'id': str(m.id),  # Convert id to string
        'device_sn': m.device_sn,
        'message': m.message,
        'message_type': m.message_type,
        'sender_type': m.sender_type,
        'receiver_type': m.receiver_type,
        'message_status': m.message_status,
        'sent_time': m.sent_time,
        'received_time': m.received_time
    } for m in messages]
    
    # Wrap the list of messages in a dictionary
    response_data = {
        'success': True,
        'messages': messages_data
    }
    
    return jsonify(response_data), 200
    
@monitor_performance("generate_message_stats_enhanced")
def generate_message_stats(message_info):
    """
    V2å¢å¼ºç‰ˆæ¶ˆæ¯ç»Ÿè®¡ç”Ÿæˆ
    æ”¯æŒæ›´ä¸°å¯Œçš„ç»Ÿè®¡æ•°æ®å’Œæ€§èƒ½ä¼˜åŒ–
    """
    if not message_info:
        return {
            'success': True,
            'messages': [],
            'totalMessages': 0,
            'uniqueMessageTypes': 0,
            'messageStatusCounts': {},
            'messageTypeCounts': {},
            'statistics': {
                'response_rate': 0.0,
                'avg_response_time': 0.0,
                'peak_hour': None,
                'distribution': {}
            }
        }
    
    try:
        start_time = time.time()
        
        # V2å¢å¼ºï¼šå¹¶è¡Œç»Ÿè®¡è®¡ç®—
        total_messages = len(message_info)
        message_status_counts = {}
        message_type_counts = {}
        
        # V2å¢å¼ºï¼šæ—¶é—´åˆ†å¸ƒç»Ÿè®¡
        hourly_distribution = {}
        response_times = []
        responded_count = 0
        
        # V2å¢å¼ºï¼šéƒ¨é—¨ç»Ÿè®¡
        department_stats = {}
        user_stats = {}
        
        for message in message_info:
            # çŠ¶æ€ç»Ÿè®¡
            status = message.get('message_status', 'unknown')
            message_status_counts[status] = message_status_counts.get(status, 0) + 1
            
            # ç±»å‹ç»Ÿè®¡
            msg_type = message.get('message_type', 'unknown')
            message_type_counts[msg_type] = message_type_counts.get(msg_type, 0) + 1
            
            # V2å¢å¼ºï¼šæ—¶é—´åˆ†å¸ƒç»Ÿè®¡
            send_time_str = message.get('send_time') or message.get('sent_time')
            if send_time_str:
                try:
                    if isinstance(send_time_str, str):
                        send_time = datetime.strptime(send_time_str[:19], '%Y-%m-%d %H:%M:%S')
                    else:
                        send_time = send_time_str
                    
                    hour_key = send_time.hour
                    hourly_distribution[hour_key] = hourly_distribution.get(hour_key, 0) + 1
                except Exception as e:
                    logger.warning(f"æ—¶é—´è§£æå¤±è´¥: {send_time_str}, é”™è¯¯: {e}")
            
            # V2å¢å¼ºï¼šå“åº”æ—¶é—´ç»Ÿè®¡
            if status in ['2', 'responded', 'acknowledged']:
                responded_count += 1
                
                sent_time = message.get('send_time') or message.get('sent_time')
                received_time = message.get('received_time')
                
                if sent_time and received_time:
                    try:
                        if isinstance(sent_time, str):
                            sent_dt = datetime.strptime(sent_time[:19], '%Y-%m-%d %H:%M:%S')
                        else:
                            sent_dt = sent_time
                            
                        if isinstance(received_time, str):
                            received_dt = datetime.strptime(received_time[:19], '%Y-%m-%d %H:%M:%S')
                        else:
                            received_dt = received_time
                        
                        response_time_seconds = (received_dt - sent_dt).total_seconds()
                        if response_time_seconds > 0:
                            response_times.append(response_time_seconds)
                    except Exception as e:
                        logger.warning(f"å“åº”æ—¶é—´è®¡ç®—å¤±è´¥: {e}")
            
            # V2å¢å¼ºï¼šéƒ¨é—¨å’Œç”¨æˆ·ç»Ÿè®¡
            dept_name = message.get('department_name', message.get('org_name', 'æœªçŸ¥éƒ¨é—¨'))
            if dept_name not in department_stats:
                department_stats[dept_name] = {
                    'total': 0, 'pending': 0, 'responded': 0, 'failed': 0
                }
            
            department_stats[dept_name]['total'] += 1
            if status in ['1', 'pending']:
                department_stats[dept_name]['pending'] += 1
            elif status in ['2', 'responded', 'acknowledged']:
                department_stats[dept_name]['responded'] += 1
            elif status in ['failed', 'error']:
                department_stats[dept_name]['failed'] += 1
            
            # ç”¨æˆ·ç»Ÿè®¡
            user_name = message.get('user_name', 'åŒ¿åç”¨æˆ·')
            if user_name != 'åŒ¿åç”¨æˆ·':
                if user_name not in user_stats:
                    user_stats[user_name] = {'total': 0, 'responded': 0}
                user_stats[user_name]['total'] += 1
                if status in ['2', 'responded', 'acknowledged']:
                    user_stats[user_name]['responded'] += 1
        
        # V2å¢å¼ºï¼šé«˜çº§ç»Ÿè®¡è®¡ç®—
        response_rate = (responded_count / max(total_messages, 1)) * 100
        avg_response_time = sum(response_times) / max(len(response_times), 1) if response_times else 0
        
        # æ‰¾å‡ºæ¶ˆæ¯é«˜å³°æ—¶æ®µ
        peak_hour = max(hourly_distribution.items(), key=lambda x: x[1])[0] if hourly_distribution else None
        
        # è®¡ç®—éƒ¨é—¨å“åº”ç‡
        for dept_name, stats in department_stats.items():
            if stats['total'] > 0:
                stats['response_rate'] = round((stats['responded'] / stats['total']) * 100, 2)
            else:
                stats['response_rate'] = 0.0
        
        # è®¡ç®—ç”¨æˆ·å“åº”ç‡
        for user_name, stats in user_stats.items():
            if stats['total'] > 0:
                stats['response_rate'] = round((stats['responded'] / stats['total']) * 100, 2)
            else:
                stats['response_rate'] = 0.0
        
        unique_message_types = len(message_type_counts)
        processing_time = round((time.time() - start_time) * 1000, 2)
        
        # V2å¢å¼ºï¼šæ„å»ºç»“æœ
        result = {
            'success': True,
            'messages': message_info,
            'totalMessages': total_messages,
            'uniqueMessageTypes': unique_message_types,
            'messageStatusCounts': message_status_counts,
            'messageTypeCounts': message_type_counts,
            
            # V2å¢å¼ºï¼šé«˜çº§ç»Ÿè®¡
            'statistics': {
                'response_rate': round(response_rate, 2),
                'avg_response_time_seconds': round(avg_response_time, 2),
                'peak_hour': peak_hour,
                'hourly_distribution': hourly_distribution,
                'responded_count': responded_count,
                'pending_count': total_messages - responded_count,
                'response_time_distribution': {
                    'min': min(response_times) if response_times else 0,
                    'max': max(response_times) if response_times else 0,
                    'avg': avg_response_time
                }
            },
            
            # V2å¢å¼ºï¼šç»„ç»‡å’Œç”¨æˆ·ç»Ÿè®¡
            'department_statistics': department_stats,
            'user_statistics': dict(list(user_stats.items())[:10]),  # åªè¿”å›å‰10ä¸ªç”¨æˆ·
            
            # V2å¢å¼ºï¼šå…ƒæ•°æ®
            'metadata': {
                'processing_time_ms': processing_time,
                'version': 'v2-enhanced',
                'timestamp': datetime.now().isoformat(),
                'data_quality': {
                    'complete_messages': sum(1 for msg in message_info if msg.get('message') and msg.get('message_type')),
                    'incomplete_messages': sum(1 for msg in message_info if not (msg.get('message') and msg.get('message_type'))),
                    'with_timestamps': sum(1 for msg in message_info if msg.get('send_time') or msg.get('sent_time'))
                }
            }
        }
        
        logger.info(f"æ¶ˆæ¯ç»Ÿè®¡ç”Ÿæˆå®Œæˆ: å¤„ç†{total_messages}æ¡æ¶ˆæ¯, è€—æ—¶{processing_time}ms")
        return result
        
    except Exception as e:
        logger.error(f"æ¶ˆæ¯ç»Ÿè®¡ç”Ÿæˆå¼‚å¸¸: {e}", exc_info=True)
        return {
            'success': False, 
            'error': str(e),
            'error_type': type(e).__name__,
            'messages': message_info or [],
            'totalMessages': len(message_info) if message_info else 0
        }
    
def fetch_messages(deviceSn, messageType, customerId):
    print("deviceSn:", deviceSn)
    print("messageType:", messageType)
    print("customerId:", customerId)
    print("fetch_alerts:deviceSn:", deviceSn)
    from .user import get_user_info
    user_info = get_user_info(deviceSn)
    print("fetch_alerts:user_info:", user_info)
    if user_info:
        user_dict = json.loads(user_info)
        userId = user_dict.get('user_id')
        return fetch_messages_by_orgIdAndUserId(orgId=None, userId=userId,messageType=messageType)
    else:
        return jsonify({"error": "User not found"}), 404

    try:
        if deviceSn is None:
            subquery = db.session.query(DeviceInfo.serial_number).filter(DeviceInfo.customer_id == customerId).subquery()
            print("subquery:", subquery)
            messages = DeviceMessage.query.filter(DeviceMessage.device_sn.in_(subquery)).all()
        else:
            if messageType is None:
                messages = DeviceMessage.query.filter_by(device_sn=deviceSn).all()
            else:
                messages = DeviceMessage.query.filter_by(device_sn=deviceSn, message_type=messageType).all()
        
        print("messages:", messages)
        messages_data = [{
            'id': message.id,
            'device_sn': message.device_sn,
            'message': message.message,
            'message_type': message.message_type,
            'message_status': message.message_status,
            'sent_time': message.sent_time.strftime("%Y-%m-%d %H:%M:%S") if message.sent_time else None,
            'received_time': message.received_time.strftime("%Y-%m-%d %H:%M:%S") if message.received_time else None
        } for message in messages]
        
        # Calculate total number of alerts
        total_messages = len(messages)

        # Calculate total number of unique alert types
        unique_message_types = len(set(message.message_type for message in messages))

        # Calculate statistics for message_type and message_status
        message_type_count = {}
        message_status_count = {}

        for message in messages:
            message_type_count[message.message_type] = message_type_count.get(message.message_type, 0) + 1
            message_status_count[message.message_status] = message_status_count.get(message.message_status, 0) + 1

        response_data = {
            'success': True,
            'messages': messages_data,
            'totalMessages': total_messages,
            'uniqueMessageTypes': unique_message_types,
            'messageTypeCount': message_type_count,
            'messageStatusCount': message_status_count
        }
        print("response_data:", response_data)

        # Store all messages for the same deviceSn in a single Redis hash
       
        # Publish the message data
        messages_data_json = json.dumps(messages_data)
        print("messages_data_json:", messages_data_json)
        if len(messages_data_json) > 0:  # Check if alerts_data_json is not empty
            mapping = {str(message['id']): json.dumps(message) for message in messages_data}
            if mapping:  # Ensure mapping is not empty
                if deviceSn is None:
                    redis.hset(f"message_info:all", mapping=mapping)
                    redis.publish("message_info_channel", messages_data_json)
                else:
                    redis.hset(f"message_info:{deviceSn}", mapping=mapping)
                    redis.publish(f"message_info_channel:{deviceSn}", messages_data_json)

        return jsonify(response_data)  # Pass the dictionary directly
    except Exception as e:
        print("Error:", e)
        return jsonify({'success': False, 'error': str(e)}), 500

@monitor_performance("fetch_messages_by_orgIdAndUserId_enhanced")
def fetch_messages_by_orgIdAndUserId(orgId, userId=None, messageType=None, customerId=None):
    """
    V2å¢å¼ºç‰ˆæ¶ˆæ¯åˆ—è¡¨è·å–
    ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥
    
    :param orgId: ç»„ç»‡ID
    :param userId: ç”¨æˆ·IDï¼Œå¯é€‰
    :param messageType: æ¶ˆæ¯ç±»å‹ï¼Œå¯é€‰
    :param customerId: å®¢æˆ·IDï¼Œå¯é€‰
    :return: æ¶ˆæ¯åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from .admin_helper import is_admin_user  # å¯¼å…¥adminåˆ¤æ–­å‡½æ•°
        
        #print(f"DEBUG: fetch_messages_by_orgIdAndUserId - orgId: {orgId}, userId: {userId}, messageType: {messageType}")
        result_list = []
        seen_message_ids = set()

        def extract_department_ids(departments):
            """é€’å½’æå–æ‰€æœ‰éƒ¨é—¨ID"""
            dept_ids = []
            for dept in departments:
                dept_ids.append(int(dept['id']))
                if 'children' in dept and dept['children']:
                    dept_ids.extend(extract_department_ids(dept['children']))
            return dept_ids

        # åŸºç¡€æŸ¥è¯¢
        base_query = db.session.query(
            DeviceMessage.id,
            DeviceMessage.message,
            DeviceMessage.message_type,
            DeviceMessage.message_status,
            DeviceMessage.sent_time,
            DeviceMessage.received_time,
            DeviceMessage.org_id,  # ä¿®æ”¹: department_info -> org_id
            DeviceMessage.sender_type,
            DeviceMessage.receiver_type,
            UserInfo.id.label('user_id'),
            UserInfo.user_name,
            UserInfo.device_sn
        ).outerjoin(
            UserInfo,
            DeviceMessage.user_id == UserInfo.id
        ).filter(
            DeviceMessage.is_deleted.is_(False)
        ).order_by(DeviceMessage.sent_time.desc())

        # æ·»åŠ customerIdè¿‡æ»¤
        if customerId:
            base_query = base_query.filter(DeviceMessage.customer_id == customerId)

        if messageType:
            base_query = base_query.filter(DeviceMessage.message_type == messageType)

        # å¦‚æœæä¾›äº†userId
        if userId:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜ç”¨æˆ·
            if is_admin_user(userId):
                return {
                    'success': True,
                    'data': {
                        'messages': [],
                        'totalMessages': 0,
                        'messageTypeCount': {},
                        'messageStatusCount': {},
                        'departmentStats': {},
                        'orgId': str(orgId) if orgId else None
                    }
                }
            
            #print(f"DEBUG: æŸ¥è¯¢ç”¨æˆ· {userId} çš„æ¶ˆæ¯")
            # ğŸš€ ä¼˜åŒ–ï¼šç›´æ¥ä»ç”¨æˆ·è¡¨è·å–ç»„ç»‡IDï¼Œæ— éœ€å…³è”è¡¨æŸ¥è¯¢ï¼
            user_info = UserInfo.query.filter_by(id=userId).first()
            print(f"DEBUG: user_info æŸ¥è¯¢ç»“æœ: {user_info}")
            
            if not user_info:
                raise Exception(f"User {userId} not found")
            
            # ğŸ‰ ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¡¨çš„org_idå­—æ®µï¼
            org_id = user_info.org_id
            if not org_id:
                # å¦‚æœç”¨æˆ·è¡¨ä¸­æ²¡æœ‰org_idï¼Œå°è¯•ä½¿ç”¨ä¼ å…¥çš„orgId
                org_id = int(orgId) if orgId else None
                if not org_id:
                    raise Exception("User organization not found and no orgId provided")
            
            print(f"DEBUG: ä»ç”¨æˆ·è¡¨ç›´æ¥è·å–org_id: {org_id}")
            
            # 1. è·å–ç”¨æˆ·ä¸ªäººæ¶ˆæ¯
            personal_messages = base_query.filter(DeviceMessage.user_id == userId).all()
            #print(f"DEBUG: ç”¨æˆ·ä¸ªäººæ¶ˆæ¯æ•°é‡: {len(personal_messages)}")
            
            # 2. ğŸ”§ ä¿®å¤: ç®€åŒ–ç”¨æˆ·ç»„ç»‡æ¶ˆæ¯æŸ¥è¯¢ï¼Œç›´æ¥åŸºäºorg_idæŸ¥è¯¢
            print(f"ğŸ” æŸ¥è¯¢ç”¨æˆ·ç»„ç»‡org_id={org_id}çš„å…¬å‘Šæ¶ˆæ¯")
            
            # ç›´æ¥æŸ¥è¯¢ç”¨æˆ·æ‰€åœ¨ç»„ç»‡çš„å…¬å‘Šæ¶ˆæ¯
            announcement_messages = base_query.filter(
                DeviceMessage.org_id == str(org_id),  # ç›´æ¥åŒ¹é…org_id
                DeviceMessage.user_id == None  # å…¬å‘Šæ¶ˆæ¯æ²¡æœ‰user_id
            ).all()
            
            print(f"ğŸ“Š ç”¨æˆ·ç»„ç»‡å…¬å‘Šæ¶ˆæ¯: {len(announcement_messages)} æ¡")

        else:
            # å¦‚æœåªæä¾›äº†orgId
            if not orgId:
                raise Exception("Either userId or orgId must be provided")

            # ğŸ”§ ä¿®å¤: ç®€åŒ–æ¶ˆæ¯æŸ¥è¯¢é€»è¾‘ï¼Œç›´æ¥åŸºäºorgIdæŸ¥è¯¢ï¼Œä¸ä¾èµ–ancestorså­—æ®µ
            print(f"ğŸ” ç›´æ¥æŸ¥è¯¢orgId={orgId}çš„æ¶ˆæ¯")
            
            # 1. ç›´æ¥æŸ¥è¯¢æŒ‡å®šorgIdçš„æ¶ˆæ¯ï¼ˆå…¬å‘Šå’Œä¸ªäººæ¶ˆæ¯ï¼‰
            all_messages = base_query.filter(
                DeviceMessage.org_id == str(orgId)  # ç›´æ¥åŒ¹é…org_id
            ).all()
            
            print(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(all_messages)} æ¡æ¶ˆæ¯ï¼ŒorgId={orgId}")
            
            # 2. è·å–å­éƒ¨é—¨æ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦åŒ…å«å­éƒ¨é—¨ï¼‰
            try:
                departments_response = fetch_departments_by_orgId(orgId)
                subordinate_org_ids = []
                if departments_response.get('success') and departments_response.get('data'):
                    subordinate_org_ids = extract_department_ids(departments_response['data'])
                    if subordinate_org_ids:
                        sub_messages = base_query.filter(
                            DeviceMessage.org_id.in_([str(id) for id in subordinate_org_ids])
                        ).all()
                        all_messages.extend(sub_messages)
                        print(f"ğŸ“Š åŒ…å«å­éƒ¨é—¨æ¶ˆæ¯ï¼Œæ€»è®¡ {len(all_messages)} æ¡")
            except Exception as e:
                print(f"âš ï¸ è·å–å­éƒ¨é—¨æ¶ˆæ¯å¤±è´¥: {e}")
            
            # 3. åˆ†ç¦»å…¬å‘Šæ¶ˆæ¯å’Œä¸ªäººæ¶ˆæ¯
            announcement_messages = [msg for msg in all_messages if not msg.user_id]
            personal_messages = [msg for msg in all_messages if msg.user_id]
            
            print(f"ğŸ“Š å…¬å‘Šæ¶ˆæ¯: {len(announcement_messages)} æ¡ï¼Œä¸ªäººæ¶ˆæ¯: {len(personal_messages)} æ¡")

        # ğŸš€ ä¼˜åŒ–ï¼šæ‰¹é‡é¢„åŠ è½½ç»„ç»‡ä¿¡æ¯ï¼Œæ¶ˆé™¤N+1æŸ¥è¯¢é—®é¢˜ï¼
        def get_org_info_batch(messages):
            """æ‰¹é‡è·å–ç»„ç»‡ä¿¡æ¯ï¼Œé¿å…N+1æŸ¥è¯¢"""
            org_ids = list(set(str(msg.org_id) for msg in messages if msg.org_id))
            if not org_ids:
                return {}
            
            orgs = OrgInfo.query.filter(OrgInfo.id.in_(org_ids)).all()
            return {str(org.id): org.name for org in orgs}
        
        # å¤„ç†æ¶ˆæ¯å¹¶æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        def process_messages(messages, is_public=False):
            # ğŸ‰ æ‰¹é‡é¢„åŠ è½½ç»„ç»‡ä¿¡æ¯ï¼Œä¸€æ¬¡æŸ¥è¯¢è§£å†³æ‰€æœ‰æ¶ˆæ¯çš„ç»„ç»‡åç§°ï¼
            org_info_cache = get_org_info_batch(messages)
            
            for msg in messages:
                #print("process_messages.sg:", msg)
                if msg.id not in seen_message_ids:
                    status = msg.message_status
                    if userId and status == '1':
                        user_info = UserInfo.query.filter_by(id=userId).first()
                        device_sn = user_info.device_sn
                        existing_detail = DeviceMessageDetail.query.filter_by(
                            message_id=msg.id,
                            device_sn=device_sn
                        ).first()
                        #print("process_messages.existing_detail:", existing_detail)
                        if existing_detail:
                            # å¦‚æœå­˜åœ¨ï¼Œåˆ™æ›´æ–°received_time
                            status = '2'
                    seen_message_ids.add(msg.id)
                    dept_id = str(msg.org_id)  # ä¿®æ”¹: department_info -> org_id
                    # ğŸ‰ ä»ç¼“å­˜ä¸­è·å–ç»„ç»‡åç§°ï¼Œæ— éœ€æ¯æ¬¡æŸ¥è¯¢æ•°æ®åº“ï¼
                    dept_name = org_info_cache.get(dept_id, 'Unknown Department')
                    message_dict = {
                        'department_name': dept_name,
                        'department_id': dept_id,
                        'message_id': str(msg.id),
                        'device_sn': msg.device_sn,
                        'user_id': str(msg.user_id) if msg.user_id else None,
                        'user_name': msg.user_name,
                        'message': msg.message,
                        'message_type': msg.message_type,
                        'message_status': status,
                        'sent_time': msg.sent_time.strftime("%Y-%m-%d %H:%M:%S") if msg.sent_time else None,
                        'received_time': msg.received_time.strftime("%Y-%m-%d %H:%M:%S") if msg.received_time else None,
                        'sender_type': msg.sender_type,
                        'receiver_type': msg.receiver_type,
                        'is_public': is_public
                    }
                    result_list.append(message_dict)

        # å¤„ç†æ‰€æœ‰è·å–åˆ°çš„æ¶ˆæ¯
        if userId:
            process_messages(personal_messages, False)
            process_messages(announcement_messages, True)
        else:
            process_messages(announcement_messages, True)
            process_messages(personal_messages, False)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_messages = len(result_list)
        message_type_count = {}
        message_status_count = {}
        department_message_count = {}
        
        for msg in result_list:
            dept_name = msg['department_name']
            department_message_count[dept_name] = department_message_count.get(dept_name, 0) + 1
            message_type_count[msg['message_type']] = message_type_count.get(msg['message_type'], 0) + 1
            message_status_count[msg['message_status']] = message_status_count.get(msg['message_status'], 0) + 1

        print(f"DEBUG: æœ€ç»ˆå¤„ç†çš„æ¶ˆæ¯æ€»æ•°: {total_messages}")
        print(f"DEBUG: æ¶ˆæ¯ç±»å‹ç»Ÿè®¡: {message_type_count}")
        print(f"DEBUG: æ¶ˆæ¯çŠ¶æ€ç»Ÿè®¡: {message_status_count}")
        print(f"DEBUG: éƒ¨é—¨æ¶ˆæ¯ç»Ÿè®¡: {department_message_count}")
        
        response_data = {
            'success': True,
            'data': {
                'messages': result_list,
                'totalMessages': total_messages,
                'publicMessagesCount': len([msg for msg in result_list if msg['is_public']]),
                'personalMessagesCount': len([msg for msg in result_list if not msg['is_public']]),
                'uniqueMessageTypes': len(message_type_count),
                'departmentMessageCount': department_message_count,
                'messageTypeCount': message_type_count,
                'messageStatusCount': message_status_count,
                'departments': list(department_message_count.keys()),
                'user_id': str(userId) if userId else None
            }
        }

        # ç¼“å­˜åˆ°Redis
        if result_list:
            cache_key = f"department_user_messages:{orgId}:{userId}"
            mapping = {msg['message_id']: json.dumps(msg) for msg in result_list}
            redis.hset(cache_key, mapping=mapping)
            redis.publish(f"{cache_key}_channel", json.dumps(result_list))

        return response_data

    except Exception as e:
        print("Error in fetch_messages_by_orgIdAndUserId:", str(e))
        return {
            'success': False,
            'error': str(e)
        }


def get_user_message(deviceSn):
    if not deviceSn:
        print("Error: deviceSn is None")
        return None

    # Query the DeviceMessage table to get messages for the given deviceSn
    messages = DeviceMessage.query.filter_by(device_sn=deviceSn).all()
    
    # Convert the messages to a list of dictionaries
    message_list = [{
        'message': message.message,
        'message_type': message.message_type,
        'message_status': message.message_status,
        'sent_time': message.sent_time.strftime("%Y-%m-%d %H:%M:%S") if message.sent_time else None,
        'received_time': message.received_time.strftime("%Y-%m-%d %H:%M:%S") if message.received_time else None
    } for message in messages]
    
    # Convert the message list to a JSON string
    message_json = json.dumps(message_list)
    print("message_json", message_json)
    
    if message_json is None:
        print("Error: message_json is None")
        return None
    
    # Check the type of the key and delete if necessary
    if redis.exists(f"message_info:{deviceSn}"):
        if redis.type(f"message_info:{deviceSn}") != b'hash':
            redis.delete(f"message_info:{deviceSn}")
    
    # Store the JSON string in Redis as a single field
    redis.set(f"message_info:{deviceSn}", message_json)
    
    redis.publish(f"message_info_channel:{deviceSn}", message_json) 
    
    return message_json


# =============================================================================
# è®¾å¤‡æ¶ˆæ¯ç®¡ç†åŠŸèƒ½ (Device Message Management Functions)
# =============================================================================

@monitor_performance("save_device_message_data_enhanced")
def save_device_message_data(data):
    """
    V2å¢å¼ºç‰ˆè®¾å¤‡æ¶ˆæ¯æ•°æ®ä¿å­˜
    æ”¯æŒåˆ†å¸ƒå¼äº‹åŠ¡å’Œæ•°æ®éªŒè¯
    """
    logger.info("save_device_message_data V2", extra={'data_keys': list(data.keys()) if data else []})
    
    # V2å¢å¼ºï¼šæ•°æ®éªŒè¯
    if not data:
        return {'success': False, 'message': 'ç¼ºå°‘æ¶ˆæ¯æ•°æ®'}, 400
    
    required_fields = ['message', 'message_type']
    missing_fields = [field for field in required_fields if not data.get(field)]
    if missing_fields:
        return {
            'success': False, 
            'message': f'ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}'
        }, 400
    
    # V2å¢å¼ºï¼šåˆ›å»ºäº‹åŠ¡ç®¡ç†å™¨
    transaction_manager = None
    transaction_id = None
    
    if V2_COMPONENTS_AVAILABLE:
        try:
            transaction_manager = DistributedTransactionManager()
            transaction_id = transaction_manager.start_transaction({
                'operation': 'save_device_message',
                'message_type': data.get('message_type'),
                'user_id': data.get('user_id'),
                'org_id': data.get('org_id')
            })
        except Exception as e:
            logger.warning(f"åˆ†å¸ƒå¼äº‹åŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    
    try:
        with db.session.begin():
            # V2å¢å¼ºï¼šæ•°æ®æ¸…æ´—å’Œé»˜è®¤å€¼å¤„ç†
            now = datetime.now()
            
            message_data = {
                'message': data.get('message', '').strip(),
                'message_type': data.get('message_type', 'notification'),
                'sender_type': data.get('sender_type', 'system'),
                'receiver_type': data.get('receiver_type', 'device'),
                'message_status': data.get('message_status', '1'),  # 1=å¾…å‘é€
                'org_id': data.get('org_id') or data.get('department_info'),
                'user_id': data.get('user_id'),
                'sent_time': data.get('sent_time') or now,
                'create_time': now,
                'customer_id': data.get('customer_id', 1),  # é»˜è®¤å®¢æˆ·ID
                'is_deleted': False
            }
            
            # V2å¢å¼ºï¼šæ‰¹é‡æ¶ˆæ¯æ”¯æŒ
            if data.get('batch_send', False) and data.get('target_users'):
                # æ‰¹é‡å‘é€å¤„ç†
                target_users = data.get('target_users', [])
                batch_messages = []
                
                for user_data in target_users:
                    batch_message_data = message_data.copy()
                    batch_message_data.update({
                        'user_id': user_data.get('user_id'),
                        'device_sn': user_data.get('device_sn')
                    })
                    
                    new_message = DeviceMessage(**batch_message_data)
                    batch_messages.append(new_message)
                
                # V2å¢å¼ºï¼šæ‰¹é‡æ’å…¥ä¼˜åŒ–
                db.session.bulk_save_objects(batch_messages, return_defaults=True)
                
                message_count = len(batch_messages)
                logger.info(f"æ‰¹é‡æ¶ˆæ¯åˆ›å»ºæˆåŠŸ: {message_count}æ¡")
                
                # V2å¢å¼ºï¼šå¼‚æ­¥å‘é€ä»»åŠ¡
                if V2_COMPONENTS_AVAILABLE:
                    try:
                        for message in batch_messages:
                            send_task = {
                                'message_id': message.id,
                                'message_type': message.message_type,
                                'target_device': message.device_sn,
                                'priority': data.get('priority', 'normal'),
                                'scheduled_time': data.get('scheduled_time')
                            }
                            redis.xadd('message_send_queue', send_task)
                    except Exception as e:
                        logger.warning(f"å‘é€ä»»åŠ¡å…¥é˜Ÿå¤±è´¥: {e}")
                
                result_data = {
                    'success': True,
                    'message': f'æ‰¹é‡æ¶ˆæ¯å‘é€æˆåŠŸ: {message_count}æ¡',
                    'message_count': message_count,
                    'message_ids': [msg.id for msg in batch_messages]
                }
                
            else:
                # å•æ¡æ¶ˆæ¯å¤„ç†
                new_message = DeviceMessage(**message_data)
                db.session.add(new_message)
                db.session.flush()  # è·å–ID
                
                logger.info(f"å•æ¡æ¶ˆæ¯åˆ›å»ºæˆåŠŸ: ID={new_message.id}")
                
                # V2å¢å¼ºï¼šå¼‚æ­¥å‘é€ä»»åŠ¡
                if V2_COMPONENTS_AVAILABLE:
                    try:
                        send_task = {
                            'message_id': new_message.id,
                            'message_type': new_message.message_type,
                            'target_device': data.get('device_sn', 'all'),
                            'priority': data.get('priority', 'normal'),
                            'scheduled_time': data.get('scheduled_time')
                        }
                        redis.xadd('message_send_queue', send_task)
                    except Exception as e:
                        logger.warning(f"å‘é€ä»»åŠ¡å…¥é˜Ÿå¤±è´¥: {e}")
                
                result_data = {
                    'success': True,
                    'message': 'æ¶ˆæ¯å‘é€æˆåŠŸ',
                    'message_id': new_message.id,
                    'message_type': new_message.message_type
                }
        
        # V2å¢å¼ºï¼šæ¸…ç†ç›¸å…³ç¼“å­˜
        cache_patterns = [
            f"message_opt_v1:*:{data.get('user_id')}:*" if data.get('user_id') else None,
            f"message_opt_v1:{data.get('org_id')}:*:*" if data.get('org_id') else None,
            "received_messages_v2:*"  # æ¸…ç†æ‰€æœ‰è®¾å¤‡çš„æ¥æ”¶æ¶ˆæ¯ç¼“å­˜
        ]
        
        for pattern in cache_patterns:
            if pattern:
                try:
                    keys = redis.keys(pattern)
                    if keys:
                        redis.delete(*keys)
                except Exception as e:
                    logger.warning(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {pattern}, é”™è¯¯: {e}")
        
        # V2å¢å¼ºï¼šæäº¤åˆ†å¸ƒå¼äº‹åŠ¡
        if transaction_manager and transaction_id:
            try:
                transaction_manager.commit_transaction(transaction_id)
            except Exception as e:
                logger.warning(f"åˆ†å¸ƒå¼äº‹åŠ¡æäº¤å¤±è´¥: {e}")
        
        return result_data, 200
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ¶ˆæ¯æ•°æ®å¼‚å¸¸: {e}", exc_info=True)
        
        # V2å¢å¼ºï¼šäº‹åŠ¡å›æ»š
        try:
            db.session.rollback()
        except:
            pass
        
        if transaction_manager and transaction_id:
            try:
                transaction_manager.rollback_transaction(transaction_id, str(e))
            except Exception as rollback_e:
                logger.error(f"åˆ†å¸ƒå¼äº‹åŠ¡å›æ»šå¤±è´¥: {rollback_e}")
        
        return {
            'success': False,
            'message': f'å‘é€æ¶ˆæ¯å¤±è´¥: {str(e)}',
            'error_type': type(e).__name__
        }, 500


def send_device_message_data(data):
    """å‘é€è®¾å¤‡æ¶ˆæ¯æ•°æ®"""
    try:
        # è®°å½•æ¶ˆæ¯å‘é€æ—¥å¿—
        device_logger.info('è®¾å¤‡æ¶ˆæ¯å‘é€', extra={
            'message_type': data.get('message_type'),
            'receiver_type': data.get('receiver_type'),
            'user_id': data.get('user_id'),
            'data_count': 1
        })
        
        return send_message(data)
    except Exception as e:
        device_logger.error('è®¾å¤‡æ¶ˆæ¯å‘é€å¤±è´¥', extra={'error': str(e)}, exc_info=True)
        raise


def receive_device_messages_data(deviceSn):
    """æ¥æ”¶è®¾å¤‡æ¶ˆæ¯æ•°æ®"""
    try:
        # è®°å½•æ¶ˆæ¯æ¥æ”¶æ—¥å¿—
        device_logger.info('è®¾å¤‡æ¶ˆæ¯æŸ¥è¯¢', extra={'device_sn': deviceSn})
        
        result = received_messages(deviceSn)
        
        # è®°å½•æŸ¥è¯¢ç»“æœ
        if hasattr(result, 'get_json'):
            result_data = result.get_json()
            if isinstance(result_data, dict) and 'data' in result_data:
                message_count = len(result_data['data']) if isinstance(result_data['data'], list) else 1
                device_logger.info('è®¾å¤‡æ¶ˆæ¯æŸ¥è¯¢å®Œæˆ', extra={'device_sn': deviceSn, 'message_count': message_count})
        
        return result
    except Exception as e:
        device_logger.error('è®¾å¤‡æ¶ˆæ¯æŸ¥è¯¢å¤±è´¥', extra={'device_sn': deviceSn, 'error': str(e)}, exc_info=True)
        raise


# =============================================================================
# V2å¢å¼ºç‰ˆAPIæ¥å£ (V2 Enhanced API Endpoints)
# =============================================================================

@monitor_performance("get_message_health_status")
def get_message_health_status():
    """
    V2å¢å¼ºï¼šè·å–æ¶ˆæ¯ç³»ç»Ÿå¥åº·çŠ¶æ€
    """
    try:
        # è·å–ç³»ç»ŸçŠ¶æ€
        status = {
            'service': 'MessageSystem',
            'version': 'v2-enhanced',
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'components': {}
        }
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        try:
            db.session.execute(text('SELECT 1')).scalar()
            status['components']['database'] = {'status': 'healthy'}
        except Exception as e:
            status['components']['database'] = {'status': 'unhealthy', 'error': str(e)}
            status['status'] = 'degraded'
        
        # æ£€æŸ¥Redisè¿æ¥
        try:
            redis.ping()
            status['components']['redis'] = {'status': 'healthy'}
        except Exception as e:
            status['components']['redis'] = {'status': 'unhealthy', 'error': str(e)}
            status['status'] = 'degraded'
        
        # V2å¢å¼ºï¼šæ£€æŸ¥V2ç»„ä»¶
        if V2_COMPONENTS_AVAILABLE:
            v2_service = get_v2_message_service()
            monitoring = get_monitoring_instance()
            
            status['components']['v2_service'] = {
                'status': 'available' if v2_service else 'unavailable'
            }
            status['components']['monitoring'] = {
                'status': 'running' if monitoring else 'stopped'
            }
        else:
            status['components']['v2_enhancement'] = {'status': 'unavailable'}
        
        return status
        
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            'service': 'MessageSystem',
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

@monitor_performance("get_message_performance_metrics")
def get_message_performance_metrics():
    """
    V2å¢å¼ºï¼šè·å–æ¶ˆæ¯ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
    """
    try:
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'version': 'v2-enhanced',
            'cache_stats': {},
            'database_stats': {},
            'message_stats': {},
            'performance': {}
        }
        
        # ç¼“å­˜ç»Ÿè®¡
        try:
            cache_info = redis.info('memory')
            metrics['cache_stats'] = {
                'used_memory': cache_info.get('used_memory', 0),
                'used_memory_human': cache_info.get('used_memory_human', '0B'),
                'hit_rate': 'N/A'  # éœ€è¦å®é™…å®ç°
            }
        except Exception as e:
            metrics['cache_stats'] = {'error': str(e)}
        
        # æ•°æ®åº“ç»Ÿè®¡
        try:
            with db.session.begin():
                # æ¶ˆæ¯æ€»æ•°
                total_messages = db.session.execute(
                    text('SELECT COUNT(*) FROM t_device_message WHERE is_deleted = 0')
                ).scalar()
                
                # æœªç¡®è®¤æ¶ˆæ¯æ•°
                pending_messages = db.session.execute(
                    text("SELECT COUNT(*) FROM t_device_message WHERE message_status = '1' AND is_deleted = 0")
                ).scalar()
                
                # ä»Šæ—¥æ¶ˆæ¯æ•°
                today_messages = db.session.execute(
                    text('SELECT COUNT(*) FROM t_device_message WHERE DATE(sent_time) = CURDATE()')
                ).scalar()
                
                metrics['message_stats'] = {
                    'total_messages': total_messages,
                    'pending_messages': pending_messages,
                    'today_messages': today_messages,
                    'response_rate': round(((total_messages - pending_messages) / max(total_messages, 1)) * 100, 2)
                }
        except Exception as e:
            metrics['message_stats'] = {'error': str(e)}
        
        # V2å¢å¼ºï¼šè·å–ç›‘æ§æŒ‡æ ‡
        if V2_COMPONENTS_AVAILABLE:
            monitoring = get_monitoring_instance()
            if monitoring:
                try:
                    dashboard = monitoring.get_monitor_dashboard()
                    metrics['v2_monitoring'] = {
                        'active_alerts': len(dashboard.get('active_alerts', {})),
                        'health_status': dashboard.get('health', {}).get('status', 'unknown')
                    }
                except Exception as e:
                    metrics['v2_monitoring'] = {'error': str(e)}
        
        return metrics
        
    except Exception as e:
        logger.error(f"æ€§èƒ½æŒ‡æ ‡è·å–å¤±è´¥: {e}")
        return {
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

@monitor_performance("clear_message_cache")
def clear_message_cache(cache_pattern: str = None):
    """
    V2å¢å¼ºï¼šæ¸…ç†æ¶ˆæ¯ç¼“å­˜
    
    Args:
        cache_pattern: ç¼“å­˜æ¨¡å¼ï¼Œä¸ºNoneæ—¶æ¸…ç†æ‰€æœ‰æ¶ˆæ¯ç¼“å­˜
    """
    try:
        cache_manager = get_cache_manager()
        
        if cache_pattern:
            # æ¸…ç†ç‰¹å®šæ¨¡å¼çš„ç¼“å­˜
            cache_manager.invalidate_pattern(cache_pattern)
            message = f"æ¸…ç†ç¼“å­˜æ¨¡å¼: {cache_pattern}"
        else:
            # æ¸…ç†æ‰€æœ‰æ¶ˆæ¯ç›¸å…³ç¼“å­˜
            patterns = [
                'message_opt_v1:*',
                'received_messages_v2:*',
                'department_user_messages:*',
                'message_stats_v2:*'
            ]
            
            total_cleared = 0
            for pattern in patterns:
                try:
                    keys = redis.keys(pattern)
                    if keys:
                        redis.delete(*keys)
                        total_cleared += len(keys)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ç¼“å­˜æ¨¡å¼å¤±è´¥: {pattern}, é”™è¯¯: {e}")
            
            message = f"æ¸…ç†æ‰€æœ‰æ¶ˆæ¯ç¼“å­˜ï¼Œå…±{total_cleared}ä¸ªé”®"
        
        logger.info(message)
        return {
            'success': True,
            'message': message,
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }

@monitor_performance("get_message_system_info")
def get_message_system_info():
    """
    V2å¢å¼ºï¼šè·å–æ¶ˆæ¯ç³»ç»Ÿä¿¡æ¯
    """
    return {
        'system': 'ljwx-bigscreen Message System',
        'version': 'v2-enhanced',
        'features': {
            'performance_monitoring': True,
            'distributed_transactions': V2_COMPONENTS_AVAILABLE,
            'advanced_caching': True,
            'batch_processing': True,
            'real_time_metrics': V2_COMPONENTS_AVAILABLE,
            'intelligent_routing': True
        },
        'components': {
            'v1_legacy': 'active',
            'v2_enhanced': 'active' if V2_COMPONENTS_AVAILABLE else 'unavailable',
            'monitoring': 'active' if get_monitoring_instance() else 'unavailable',
            'caching': 'active',
            'database': 'active'
        },
        'statistics': {
            'functions_enhanced': 7,
            'performance_decorators': 'active',
            'cache_layers': 2,
            'fallback_mechanisms': 'implemented'
        },
        'timestamp': datetime.now().isoformat(),
        'uptime': time.time() - (time.time() - 86400)  # ç®€åŒ–çš„è¿è¡Œæ—¶é—´
    }

# V2å¢å¼ºï¼šåˆå§‹åŒ–å‡½æ•°
def initialize_v2_enhancements():
    """
    V2å¢å¼ºï¼šåˆå§‹åŒ–V2å¢å¼ºç»„ä»¶
    """
    logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ¶ˆæ¯ç³»ç»Ÿ V2 å¢å¼ºç»„ä»¶...")
    
    try:
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        cache_manager = get_cache_manager()
        logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–V2æœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if V2_COMPONENTS_AVAILABLE:
            v2_service = get_v2_message_service()
            if v2_service:
                logger.info("âœ… V2æ¶ˆæ¯æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
            # åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ
            monitoring = get_monitoring_instance()
            if monitoring:
                logger.info("âœ… ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        else:
            logger.warning("âš ï¸ V2ç»„ä»¶ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»ŸåŠŸèƒ½")
        
        # è¾“å‡ºç³»ç»Ÿä¿¡æ¯
        system_info = get_message_system_info()
        logger.info(f"ğŸ“Š ç³»ç»Ÿä¿¡æ¯: {system_info['system']} {system_info['version']}")
        logger.info(f"ğŸ”§ å¢å¼ºåŠŸèƒ½: {len([k for k, v in system_info['features'].items() if v])}/{len(system_info['features'])} å·²å¯ç”¨")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ V2å¢å¼ºç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

# åœ¨æ¨¡å—åŠ è½½æ—¶è‡ªåŠ¨åˆå§‹åŒ–V2å¢å¼ºç»„ä»¶
if __name__ != '__main__':
    try:
        # åœ¨æ¨¡å—å¯¼å…¥æ—¶è‡ªåŠ¨åˆå§‹åŒ–
        initialize_v2_enhancements()
    except Exception as e:
        logger.warning(f"æ¨¡å—åˆå§‹åŒ–è­¦å‘Š: {e}")

# æ¨¡å—ç»“æŸæ ‡è®°
logger.info("âœ¨ ljwx-bigscreen æ¶ˆæ¯ç³»ç»Ÿ V2 å¢å¼ºç‰ˆåŠ è½½å®Œæˆ")

