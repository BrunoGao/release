from flask import jsonify, request
from .models import AlertInfo, AlertLog, DeviceInfo, db, AlertRules, UserInfo, UserOrg, OrgInfo, UserHealthData
import requests, json
import random
from .user import get_user_name
from .redis_helper import RedisHelper
import time
import threading
from sqlalchemy import and_, case, text
from datetime import datetime, timedelta
from decimal import Decimal
from .device import get_device_user_org_info
from .time_config import get_now #ç»Ÿä¸€æ—¶é—´é…ç½®
from typing import List, Dict, Optional, Tuple
import os
from dotenv import load_dotenv
import sys
import logging

logger = logging.getLogger(__name__)

# å¯¼å…¥ç»„ç»‡æ¶æ„ä¼˜åŒ–æŸ¥è¯¢æœåŠ¡
from .org_optimized import get_org_service, find_principals_optimized, find_escalation_chain_optimized
from .org_service import get_unified_org_service

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ä»¥å¯¼å…¥å¾®ä¿¡é…ç½®æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from wechat_config import get_wechat_config

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

redis = RedisHelper()

def get_all_alert_data_optimized(orgId=None, userId=None, startDate=None, endDate=None, latest_only=False, page=1, pageSize=None, severity_level=None, include_details=False):
    """
    ç»Ÿä¸€çš„å‘Šè­¦æ•°æ®æŸ¥è¯¢æ¥å£ï¼Œæ”¯æŒåˆ†é¡µå’Œä¼˜åŒ–æŸ¥è¯¢
    
    Args:
        orgId: ç»„ç»‡ID
        userId: ç”¨æˆ·ID  
        startDate: å¼€å§‹æ—¥æœŸ
        endDate: ç»“æŸæ—¥æœŸ
        latest_only: æ˜¯å¦åªæŸ¥è¯¢æœ€æ–°è®°å½•
        page: é¡µç 
        pageSize: æ¯é¡µå¤§å°
        severity_level: ä¸¥é‡ç¨‹åº¦
        include_details: æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯
    
    Returns:
        dict: åŒ…å«å‘Šè­¦æ•°æ®å’Œåˆ†é¡µä¿¡æ¯çš„å­—å…¸
    """
    try:
        import time
        from datetime import datetime, timedelta
        start_time = time.time()
        
        # å‚æ•°éªŒè¯å’Œç¼“å­˜é”®æ„å»º
        page = max(1, int(page or 1))
        if pageSize is not None:
            pageSize = min(int(pageSize), 1000)
        else:
            pageSize = None
        mode = 'latest' if latest_only else 'range'
        cache_key = f"alert_opt_v1:{orgId}:{userId}:{startDate}:{endDate}:{mode}:{page}:{pageSize}:{severity_level}:{include_details}"
        
        # ç¼“å­˜æ£€æŸ¥
        cached = redis.get_data(cache_key)
        if cached:
            result = json.loads(cached)
            result['performance'] = {'cached': True, 'response_time': round(time.time() - start_time, 3)}
            return result
        
        # ğŸš€ ä¼˜åŒ–ï¼šæ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼Œæ¶ˆé™¤OrgInfoçš„JOINæ“ä½œ
        query = db.session.query(
            AlertInfo.id,
            AlertInfo.alert_type,
            AlertInfo.severity_level,
            AlertInfo.alert_desc,
            AlertInfo.alert_status,
            AlertInfo.alert_timestamp,
            AlertInfo.responded_time,
            AlertInfo.device_sn,
            AlertInfo.health_id,
            AlertInfo.user_id,
            AlertInfo.org_id,
            AlertInfo.latitude,
            AlertInfo.longitude,
            AlertInfo.altitude,
            UserInfo.user_name,
            # ğŸ‰ ä¼˜åŒ–ï¼šç›´æ¥ä»UserInfoè·å–ç»„ç»‡åï¼Œæ— éœ€JOIN OrgInfoï¼
            UserInfo.org_name.label('org_name')
        ).outerjoin(
            UserInfo, AlertInfo.user_id == UserInfo.id
            # ğŸ‰ çœå»äº†OrgInfoçš„JOINæ“ä½œï¼Œå‡å°‘ä¸€æ¬¡è¡¨å…³è”ï¼
        )
        
        if userId:
            # å•ç”¨æˆ·æŸ¥è¯¢
            query = query.filter(AlertInfo.user_id == userId)
            
        elif orgId:
            # ç»„ç»‡æŸ¥è¯¢ - è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·çš„å‘Šè­¦
            from .org import fetch_users_by_orgId
            users = fetch_users_by_orgId(orgId)
            if not users:
                return {"success": True, "data": {"alertData": [], "totalRecords": 0, "pagination": {"currentPage": page, "pageSize": pageSize, "totalCount": 0, "totalPages": 0}}}
            
            user_ids = [int(user['id']) for user in users]
            query = query.filter(AlertInfo.user_id.in_(user_ids))
            
        else:
            return {"success": False, "message": "ç¼ºå°‘orgIdæˆ–userIdå‚æ•°", "data": {"alertData": [], "totalRecords": 0}}
        
        # æ—¶é—´èŒƒå›´è¿‡æ»¤
        if startDate:
            query = query.filter(AlertInfo.alert_timestamp >= startDate)
        if endDate:
            query = query.filter(AlertInfo.alert_timestamp <= endDate)
        
        # ä¸¥é‡ç¨‹åº¦è¿‡æ»¤
        if severity_level:
            if severity_level == 'high':
                query = query.filter(AlertInfo.severity_level.in_(['high', 'critical']))
            else:
                query = query.filter(AlertInfo.severity_level == severity_level)
        
        # ç»Ÿè®¡æ€»æ•°
        total_count = query.count()
        
        # æ’åºï¼šä¸¥é‡çº§åˆ«ä¼˜å…ˆï¼ŒçŠ¶æ€æ¬¡ä¹‹ï¼Œæ—¶é—´å€’åº
        severity_order = case(
            (AlertInfo.severity_level == 'critical', 1),
            (AlertInfo.severity_level == 'high', 2),
            (AlertInfo.severity_level == 'medium', 3),
            else_=4
        )
        status_order = case(
            (AlertInfo.alert_status == 'pending', 1),
            (AlertInfo.alert_status == 'responded', 2),
            else_=3
        )
        query = query.order_by(severity_order, status_order, AlertInfo.alert_timestamp.desc())
        
        # åˆ†é¡µå¤„ç†
        if pageSize is not None:
            offset = (page - 1) * pageSize
            query = query.offset(offset).limit(pageSize)
        
        if latest_only and not pageSize:
            query = query.limit(1)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        alerts = query.all()
        
        # æ ¼å¼åŒ–æ•°æ®
        alert_data_list = []
        for alert in alerts:
            alert_dict = {
                'id': alert.id,
                'alert_type': alert.alert_type,
                'severity_level': alert.severity_level,
                'alert_desc': alert.alert_desc,
                'alert_status': alert.alert_status,
                'alert_timestamp': alert.alert_timestamp.strftime('%Y-%m-%d %H:%M:%S') if alert.alert_timestamp else None,
                'responded_time': alert.responded_time.strftime('%Y-%m-%d %H:%M:%S') if alert.responded_time else None,
                'device_sn': alert.device_sn,
                'health_id': alert.health_id,
                'user_id': alert.user_id,
                'org_id': alert.org_id,
                'latitude': str(alert.latitude) if alert.latitude else '22.54036796',
                'longitude': str(alert.longitude) if alert.longitude else '114.01508952',
                'altitude': str(alert.altitude) if alert.altitude else '0',
                'user_name': alert.user_name or 'æœªçŸ¥ç”¨æˆ·',
                'org_name': alert.org_name or 'æœªçŸ¥ç»„ç»‡',
                'dept_name': alert.org_name or 'æœªçŸ¥ç»„ç»‡',  # å…¼å®¹å­—æ®µ
                'dept_id': alert.org_id
            }
            
            # å¦‚æœéœ€è¦åŒ…å«è¯¦ç»†ä¿¡æ¯
            if include_details:
                alert_dict['details'] = []  # å¯ä»¥åœ¨æ­¤å¤„æ·»åŠ å‘Šè­¦ç›¸å…³è¯¦ç»†ä¿¡æ¯
            
            alert_data_list.append(alert_dict)
        
        # æ„å»ºåˆ†é¡µä¿¡æ¯
        pagination = {
            'currentPage': page,
            'pageSize': pageSize,
            'totalCount': total_count,
            'totalPages': (total_count + pageSize - 1) // pageSize if pageSize else 1
        }
        
        # æ„å»ºç»“æœ
        result = {
            'success': True,
            'data': {
                'alertData': alert_data_list,
                'totalRecords': len(alert_data_list),
                'pagination': pagination
            },
            'performance': {
                'cached': False,
                'response_time': round(time.time() - start_time, 3),
                'query_time': round(time.time() - start_time, 3)
            }
        }
        
        # ç¼“å­˜ç»“æœ
        redis.set_data(cache_key, json.dumps(result, default=str), 300)
        
        return result
        
    except Exception as e:
        logger.error(f"å‘Šè­¦æŸ¥è¯¢å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'data': {'alertData': [], 'totalRecords': 0}
        }

class AlertService:
    """å‘Šè­¦ç®¡ç†ç»Ÿä¸€æœåŠ¡å°è£…ç±» - åŸºäºuserIdçš„æŸ¥è¯¢å’Œæ±‡æ€»"""
    
    def __init__(self):
        self.redis = redis
    
    def get_alerts_by_common_params(self, customer_id: int = None, org_id: int = None,
                                  user_id: int = None, start_date: str = None, 
                                  end_date: str = None, severity_level: str = None,
                                  page: int = 1, page_size: int = None, 
                                  include_details: bool = False) -> Dict:
        """
        åŸºäºç»Ÿä¸€å‚æ•°è·å–å‘Šè­¦ä¿¡æ¯ - æ•´åˆç°æœ‰get_all_alert_data_optimizedæ¥å£
        
        Args:
            customer_id: å®¢æˆ·ID (æ˜ å°„åˆ°orgId)
            org_id: ç»„ç»‡ID
            user_id: ç”¨æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            severity_level: ä¸¥é‡ç¨‹åº¦
            page: é¡µç 
            page_size: æ¯é¡µå¤§å°
            include_details: æ˜¯å¦åŒ…å«è¯¦ç»†ä¿¡æ¯
            
        Returns:
            å‘Šè­¦ä¿¡æ¯å­—å…¸
        """
        try:
            # å‚æ•°æ˜ å°„å’Œä¼˜å…ˆçº§å¤„ç†
            if user_id:
                result = get_all_alert_data_optimized(
                    orgId=None,
                    userId=user_id, 
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=False,
                    page=page,
                    pageSize=page_size,
                    severity_level=severity_level,
                    include_details=include_details
                )
                logger.info(f"åŸºäºuserIdæŸ¥è¯¢å‘Šè­¦æ•°æ®: user_id={user_id}")
                
            elif org_id:
                # ç»„ç»‡æŸ¥è¯¢ - è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·çš„å‘Šè­¦
                result = get_all_alert_data_optimized(
                    orgId=org_id,
                    userId=None,
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=False,
                    page=page,
                    pageSize=page_size,
                    severity_level=severity_level,
                    include_details=include_details
                )
                logger.info(f"åŸºäºorgIdæŸ¥è¯¢å‘Šè­¦æ•°æ®: org_id={org_id}")
                
            elif customer_id:
                # å®¢æˆ·æŸ¥è¯¢ - å°†customer_idä½œä¸ºorgIdå¤„ç†
                result = get_all_alert_data_optimized(
                    orgId=customer_id,
                    userId=None,
                    startDate=start_date,
                    endDate=end_date,
                    latest_only=False,
                    page=page,
                    pageSize=page_size,
                    severity_level=severity_level,
                    include_details=include_details
                )
                logger.info(f"åŸºäºcustomerIdæŸ¥è¯¢å‘Šè­¦æ•°æ®: customer_id={customer_id}")
                
            else:
                return {
                    'success': False,
                    'error': 'Missing required parameters: customer_id, org_id, or user_id',
                    'data': {'alerts': [], 'total_count': 0}
                }
            
            # ç»Ÿä¸€è¿”å›æ ¼å¼ï¼Œå…¼å®¹æ–°çš„æœåŠ¡æ¥å£
            if result.get('success', True):
                alert_data = result.get('data', {}).get('alertData', [])
                
                unified_result = {
                    'success': True,
                    'data': {
                        'alerts': alert_data,
                        'total_count': result.get('data', {}).get('totalRecords', len(alert_data)),
                        'pagination': result.get('data', {}).get('pagination', {}),
                        'query_params': {
                            'customer_id': customer_id,
                            'org_id': org_id,
                            'user_id': user_id,
                            'start_date': start_date,
                            'end_date': end_date,
                            'severity_level': severity_level,
                            'page': page,
                            'page_size': page_size,
                            'include_details': include_details
                        }
                    },
                    'performance': result.get('performance', {}),
                    'from_cache': result.get('performance', {}).get('cached', False)
                }
                
                return unified_result
            else:
                return result
                
        except Exception as e:
            logger.error(f"å‘Šè­¦æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'data': {'alerts': [], 'total_count': 0}
            }
    
    def _get_alerts_by_user_id(self, user_id: int, start_date: str = None,
                              end_date: str = None, severity_level: str = None) -> List[Dict]:
        """åŸºäºç”¨æˆ·IDæŸ¥è¯¢å‘Šè­¦"""
        try:
            query = db.session.query(
                AlertInfo.id,
                AlertInfo.alert_type,
                AlertInfo.severity_level,
                AlertInfo.alert_desc,
                AlertInfo.alert_status,
                AlertInfo.alert_timestamp,
                AlertInfo.responded_time,
                AlertInfo.device_sn,
                AlertInfo.health_id,
                AlertInfo.user_id,
                AlertInfo.org_id,
                AlertInfo.latitude,
                AlertInfo.longitude,
                AlertInfo.altitude,
                UserInfo.user_name,
                OrgInfo.name.label('org_name')
            ).outerjoin(
                UserInfo, AlertInfo.user_id == UserInfo.id
            ).outerjoin(
                OrgInfo, AlertInfo.org_id == OrgInfo.id
            ).filter(
                AlertInfo.user_id == user_id
            )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(AlertInfo.alert_timestamp >= start_date)
            if end_date:
                query = query.filter(AlertInfo.alert_timestamp <= end_date)
            if severity_level:
                query = query.filter(AlertInfo.severity_level == severity_level)
            
            results = query.order_by(AlertInfo.alert_timestamp.desc()).all()
            
            alerts = []
            for result in results:
                alerts.append(self._format_alert_data(result))
            
            return alerts
            
        except Exception as e:
            logger.error(f"åŸºäºç”¨æˆ·IDæŸ¥è¯¢å‘Šè­¦å¤±è´¥: {e}")
            return []
    
    def _get_alerts_by_org_id(self, org_id: int, customer_id: int = None,
                             start_date: str = None, end_date: str = None,
                             severity_level: str = None) -> List[Dict]:
        """åŸºäºç»„ç»‡IDæŸ¥è¯¢å‘Šè­¦"""
        try:
            # è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·
            from .org import fetch_users_by_orgId
            users = fetch_users_by_orgId(org_id, customer_id)
            
            if not users:
                return []
            
            user_ids = [int(user['id']) for user in users]
            
            query = db.session.query(
                AlertInfo.id,
                AlertInfo.alert_type,
                AlertInfo.severity_level,
                AlertInfo.alert_desc,
                AlertInfo.alert_status,
                AlertInfo.alert_timestamp,
                AlertInfo.responded_time,
                AlertInfo.device_sn,
                AlertInfo.health_id,
                AlertInfo.user_id,
                AlertInfo.org_id,
                AlertInfo.latitude,
                AlertInfo.longitude,
                AlertInfo.altitude,
                UserInfo.user_name,
                OrgInfo.name.label('org_name')
            ).outerjoin(
                UserInfo, AlertInfo.user_id == UserInfo.id
            ).outerjoin(
                OrgInfo, AlertInfo.org_id == OrgInfo.id
            ).filter(
                AlertInfo.user_id.in_(user_ids)
            )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(AlertInfo.alert_timestamp >= start_date)
            if end_date:
                query = query.filter(AlertInfo.alert_timestamp <= end_date)
            if severity_level:
                query = query.filter(AlertInfo.severity_level == severity_level)
            
            results = query.order_by(AlertInfo.alert_timestamp.desc()).all()
            
            alerts = []
            for result in results:
                alerts.append(self._format_alert_data(result))
            
            return alerts
            
        except Exception as e:
            logger.error(f"åŸºäºç»„ç»‡IDæŸ¥è¯¢å‘Šè­¦å¤±è´¥: {e}")
            return []
    
    def _get_alerts_by_customer_id(self, customer_id: int, start_date: str = None,
                                  end_date: str = None, severity_level: str = None) -> List[Dict]:
        """åŸºäºå®¢æˆ·IDæŸ¥è¯¢å‘Šè­¦"""
        try:
            # é€šè¿‡ç”¨æˆ·è¡¨çš„customer_idæŸ¥è¯¢
            query = db.session.query(
                AlertInfo.id,
                AlertInfo.alert_type,
                AlertInfo.severity_level,
                AlertInfo.alert_desc,
                AlertInfo.alert_status,
                AlertInfo.alert_timestamp,
                AlertInfo.responded_time,
                AlertInfo.device_sn,
                AlertInfo.health_id,
                AlertInfo.user_id,
                AlertInfo.org_id,
                AlertInfo.latitude,
                AlertInfo.longitude,
                AlertInfo.altitude,
                UserInfo.user_name,
                OrgInfo.name.label('org_name')
            ).join(
                UserInfo, AlertInfo.user_id == UserInfo.id
            ).outerjoin(
                OrgInfo, AlertInfo.org_id == OrgInfo.id
            ).filter(
                UserInfo.customer_id == customer_id
            )
            
            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_date:
                query = query.filter(AlertInfo.alert_timestamp >= start_date)
            if end_date:
                query = query.filter(AlertInfo.alert_timestamp <= end_date)
            if severity_level:
                query = query.filter(AlertInfo.severity_level == severity_level)
            
            results = query.order_by(AlertInfo.alert_timestamp.desc()).all()
            
            alerts = []
            for result in results:
                alerts.append(self._format_alert_data(result))
            
            return alerts
            
        except Exception as e:
            logger.error(f"åŸºäºå®¢æˆ·IDæŸ¥è¯¢å‘Šè­¦å¤±è´¥: {e}")
            return []
    
    def _format_alert_data(self, result) -> Dict:
        """æ ¼å¼åŒ–å‘Šè­¦æ•°æ®"""
        return {
            'id': result.id,
            'alert_type': result.alert_type,
            'severity_level': result.severity_level,
            'alert_desc': result.alert_desc,
            'alert_status': result.alert_status,
            'alert_timestamp': result.alert_timestamp.strftime('%Y-%m-%d %H:%M:%S') if result.alert_timestamp else None,
            'responded_time': result.responded_time.strftime('%Y-%m-%d %H:%M:%S') if result.responded_time else None,
            'device_sn': result.device_sn,
            'health_id': result.health_id,
            'user_id': result.user_id,
            'org_id': result.org_id,
            'latitude': str(result.latitude) if result.latitude else None,
            'longitude': str(result.longitude) if result.longitude else None,
            'altitude': str(result.altitude) if result.altitude else None,
            'user_name': result.user_name,
            'org_name': result.org_name
        }
    
    def get_alert_statistics_by_common_params(self, customer_id: int = None,
                                            org_id: int = None, user_id: int = None,
                                            start_date: str = None, end_date: str = None) -> Dict:
        """åŸºäºç»Ÿä¸€å‚æ•°è·å–å‘Šè­¦ç»Ÿè®¡"""
        try:
            cache_key = f"alert_stats_v2:{customer_id}:{org_id}:{user_id}:{start_date}:{end_date}"
            
            # ç¼“å­˜æ£€æŸ¥
            cached = self.redis.get_data(cache_key)
            if cached:
                return json.loads(cached)
            
            # è·å–å‘Šè­¦æ•°æ®
            alerts_result = self.get_alerts_by_common_params(
                customer_id, org_id, user_id, start_date, end_date
            )
            
            if not alerts_result.get('success'):
                return alerts_result
            
            alerts = alerts_result['data']['alerts']
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            total_alerts = len(alerts)
            severity_stats = {'high': 0, 'medium': 0, 'low': 0}
            status_stats = {'pending': 0, 'resolved': 0, 'ignored': 0}
            type_stats = {}
            
            for alert in alerts:
                # ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
                severity = alert.get('severity_level', 'low')
                if severity in severity_stats:
                    severity_stats[severity] += 1
                
                # çŠ¶æ€ç»Ÿè®¡
                status = alert.get('alert_status', 'pending')
                if status in status_stats:
                    status_stats[status] += 1
                
                # å‘Šè­¦ç±»å‹ç»Ÿè®¡
                alert_type = alert.get('alert_type', 'unknown')
                if alert_type not in type_stats:
                    type_stats[alert_type] = 0
                type_stats[alert_type] += 1
            
            # æŒ‰ç»„ç»‡ç»Ÿè®¡
            org_stats = {}
            for alert in alerts:
                org_name = alert.get('org_name', 'æœªçŸ¥ç»„ç»‡')
                if org_name not in org_stats:
                    org_stats[org_name] = {
                        'total': 0,
                        'high': 0,
                        'medium': 0,
                        'low': 0,
                        'pending': 0,
                        'resolved': 0
                    }
                
                org_stats[org_name]['total'] += 1
                severity = alert.get('severity_level', 'low')
                status = alert.get('alert_status', 'pending')
                
                if severity in ['high', 'medium', 'low']:
                    org_stats[org_name][severity] += 1
                if status in ['pending', 'resolved']:
                    org_stats[org_name][status] += 1
            
            result = {
                'success': True,
                'data': {
                    'overview': {
                        'total_alerts': total_alerts,
                        'severity_stats': severity_stats,
                        'status_stats': status_stats,
                        'type_stats': type_stats,
                        'resolution_rate': round(status_stats['resolved'] / total_alerts * 100, 2) if total_alerts > 0 else 0
                    },
                    'org_statistics': org_stats,
                    'query_params': {
                        'customer_id': customer_id,
                        'org_id': org_id,
                        'user_id': user_id,
                        'start_date': start_date,
                        'end_date': end_date
                    }
                }
            }
            
            # ç¼“å­˜ç»“æœ
            self.redis.set_data(cache_key, json.dumps(result, default=str), 180)
            
            return result
            
        except Exception as e:
            logger.error(f"å‘Šè­¦ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'data': {'overview': {}, 'org_statistics': {}}
            }

# å…¨å±€å®ä¾‹
_alert_service_instance = None

def get_unified_alert_service() -> AlertService:
    """è·å–ç»Ÿä¸€å‘Šè­¦æœåŠ¡å®ä¾‹"""
    global _alert_service_instance
    if _alert_service_instance is None:
        _alert_service_instance = AlertService()
    return _alert_service_instance

# å‘åå…¼å®¹çš„å‡½æ•°ï¼Œä¾›ç°æœ‰ä»£ç ä½¿ç”¨
def get_alerts_unified(customer_id: int = None, org_id: int = None,
                      user_id: int = None, start_date: str = None,
                      end_date: str = None, severity_level: str = None,
                      page: int = 1, page_size: int = None, 
                      include_details: bool = False) -> Dict:
    """ç»Ÿä¸€çš„å‘Šè­¦æŸ¥è¯¢æ¥å£ - æ•´åˆç°æœ‰get_all_alert_data_optimizedæ¥å£"""
    service = get_unified_alert_service()
    return service.get_alerts_by_common_params(
        customer_id, org_id, user_id, start_date, end_date, severity_level,
        page, page_size, include_details
    )

def get_alert_statistics_unified(customer_id: int = None, org_id: int = None,
                               user_id: int = None, start_date: str = None,
                               end_date: str = None) -> Dict:
    """ç»Ÿä¸€çš„å‘Šè­¦ç»Ÿè®¡æ¥å£"""
    service = get_unified_alert_service()
    return service.get_alert_statistics_by_common_params(customer_id, org_id, user_id, start_date, end_date)

# è·å–å¾®ä¿¡é…ç½®å®ä¾‹
wechat_config = get_wechat_config()

# ä¿ç•™åŸæœ‰çš„å˜é‡åä»¥å…¼å®¹ç°æœ‰ä»£ç 
app_id = wechat_config.app_id
app_secret = wechat_config.app_secret
WECHAT_API_URL = wechat_config.api_url
WECHAT_ACCESS_TOKEN = ""  # é€šè¿‡é…ç½®ç®¡ç†æ¨¡å—åŠ¨æ€è·å–
WECHAT_TEMPLATE_ID = wechat_config.template_id
WECHAT_USER_OPENID = wechat_config.user_openid
WECHAT_ALERT_ENABLED = wechat_config.enabled

def get_access_token(app_id, app_secret):
    # ä½¿ç”¨å¾®ä¿¡é…ç½®ç®¡ç†æ¨¡å—è·å–AccessToken
    return wechat_config.get_access_token()
    
def refresh_access_token():
    """å®šæœŸåˆ·æ–°AccessToken - å¢å¼ºé…ç½®æ£€æŸ¥å’Œé”™è¯¯æŠ‘åˆ¶"""
    global WECHAT_ACCESS_TOKEN
    last_error_time = 0 # ä¸Šæ¬¡é”™è¯¯æ—¶é—´
    error_interval = 3600 # é”™è¯¯æŠ‘åˆ¶é—´éš”1å°æ—¶
    
    while True:
        current_time = time.time()
        
        # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨
        if not wechat_config.is_enabled():
            time.sleep(3600)
            continue
            
        # ä½¿ç”¨é™é»˜æ¨¡å¼è·å–tokenï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        token = wechat_config.get_access_token(silent=True)
        if token:
            WECHAT_ACCESS_TOKEN = token
            last_error_time = 0 # é‡ç½®é”™è¯¯æ—¶é—´
        else:
            # ä»…åœ¨é—´éš”æ—¶é—´åæ‰è¾“å‡ºè·å–å¤±è´¥ä¿¡æ¯
            if current_time - last_error_time > error_interval:
                configured, msg = wechat_config.is_configured()
                if not configured:
                    print(f"å¾®ä¿¡é…ç½®æ£€æŸ¥: {msg}")
                else:
                    print("å¾®ä¿¡AccessTokenè·å–å¤±è´¥ï¼Œå°†åœ¨1å°æ—¶åé‡è¯•")
                last_error_time = current_time
                
        time.sleep(3600) # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
    
threading.Thread(target=refresh_access_token, daemon=True).start()    

def send_wechat_alert(alert_type, user_openid, user_name, severity_level):
    """å‘é€å¾®ä¿¡å‘Šè­¦æ¶ˆæ¯ - ä½¿ç”¨é…ç½®ç®¡ç†æ¨¡å—ç»Ÿä¸€å¤„ç†"""
    # ç›´æ¥ä½¿ç”¨é…ç½®ç®¡ç†æ¨¡å—çš„å‘é€æ–¹æ³•
    result = wechat_config.send_alert(alert_type, user_name, severity_level, user_openid)
    
    # å…¼å®¹åŸæœ‰çš„è¿”å›æ ¼å¼
    if result.get('success'):
        return result.get('data', result)
    else:
        return {"errcode": 1, "errmsg": result.get('message', 'å‘é€å¤±è´¥')}

def upload_alerts():
    data = request.get_json()
    userName = data.get('userName')
    phoneNumber = data.get('phoneNumber')
    alertType = data.get('alertType')
    timestamp = data.get('timestamp')
    latitude = data.get('latitude', random.uniform(-90, 90))
    longitude = data.get('longitude', random.uniform(-180, 180))
    device_sn = data.get('deviceSn') or data.get('device_sn')
    
    # è·å–è®¾å¤‡çš„ç”¨æˆ·å’Œç»„ç»‡ä¿¡æ¯
    device_user_org = get_device_user_org_info(device_sn)

    new_alert = AlertInfo(
        alert_type=alertType,
        device_sn=device_sn,
        alert_timestamp=get_now(), #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
        alert_desc=f"ç”¨æˆ·{userName}å‘ç”Ÿ{alertType}å‘Šè­¦",
        severity_level='medium',
        alert_status='pending',
        latitude=latitude,
        longitude=longitude,
        org_id=device_user_org.get('org_id') if device_user_org.get('success') else None,
        user_id=device_user_org.get('user_id') if device_user_org.get('success') else None
    )
    db.session.add(new_alert)
    db.session.commit()

    return jsonify({'message': 'Alert uploaded successfully'}), 201

def fetch_alerts_by_orgIdAndUserId(orgId=None, userId=None, severityLevel=None, customerId=None):
    """è·å–å‘Šè­¦ä¿¡æ¯ - ä½¿ç”¨AlertInfoè¡¨ä¸­çš„org_idå’Œuser_idå­—æ®µ"""
    try:
        print(f"æŸ¥è¯¢å‚æ•°: orgId={orgId}, userId={userId}, severityLevel={severityLevel}, customerId={customerId}")
        
        # ğŸš€ ä¼˜åŒ–ï¼šæ„å»ºåŸºç¡€æŸ¥è¯¢ï¼Œæ¶ˆé™¤OrgInfoçš„JOINæ“ä½œ
        query = db.session.query(
            AlertInfo.id,
            AlertInfo.alert_type,
            AlertInfo.severity_level,
            AlertInfo.alert_desc,
            AlertInfo.alert_status,
            AlertInfo.alert_timestamp,
            AlertInfo.responded_time,
            AlertInfo.device_sn,
            AlertInfo.health_id,
            AlertInfo.user_id,
            AlertInfo.org_id,
            AlertInfo.latitude,
            AlertInfo.longitude,
            AlertInfo.altitude,
            UserInfo.user_name,
            # ğŸ‰ ä¼˜åŒ–ï¼šç›´æ¥ä»UserInfoè·å–ç»„ç»‡åï¼Œæ— éœ€JOIN OrgInfoï¼
            UserInfo.org_name.label('org_name')
        ).outerjoin(
            UserInfo, AlertInfo.user_id == UserInfo.id
            # ğŸ‰ çœå»äº†OrgInfoçš„JOINæ“ä½œï¼Œå‡å°‘ä¸€æ¬¡è¡¨å…³è”ï¼
        )
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if userId:
            query = query.filter(AlertInfo.user_id == userId)
        elif orgId:
            query = query.filter(AlertInfo.org_id == orgId)
        
        # æ·»åŠ ä¸¥é‡çº§åˆ«è¿‡æ»¤
        if severityLevel:
            if severityLevel == 'high':
                query = query.filter(AlertInfo.severity_level.in_(['high', 'medium']))
            else:
                query = query.filter(AlertInfo.severity_level == severityLevel)
        
        # æ’åºï¼šä¸¥é‡çº§åˆ«ä¼˜å…ˆï¼ŒçŠ¶æ€æ¬¡ä¹‹ï¼Œæ—¶é—´å€’åº
        severity_order = case(
            (AlertInfo.severity_level == 'critical', 1),
            (AlertInfo.severity_level == 'high', 2),
            (AlertInfo.severity_level == 'medium', 3),
            else_=4
        )
        status_order = case(
            (AlertInfo.alert_status == 'pending', 1),
            (AlertInfo.alert_status == 'responded', 2),
            else_=3
        )
        
        alerts = query.order_by(severity_order, status_order, AlertInfo.alert_timestamp.desc()).all()
        
        # å¤„ç†ç»“æœæ•°æ®
        result_list = []
        alert_type_count = {}
        alert_level_count = {}
        alert_status_count = {}
        device_alert_count = {}
        
        for alert in alerts:
            alert_dict = {
                'alert_id': str(alert.id),
                'device_sn': alert.device_sn,
                'user_id': str(alert.user_id) if alert.user_id else None,
                'user_name': alert.user_name or 'æœªçŸ¥ç”¨æˆ·',
                'org_id': str(alert.org_id) if alert.org_id else None,
                'org_name': alert.org_name or 'æœªçŸ¥ç»„ç»‡',
                'health_id': str(alert.health_id) if alert.health_id else None,
                'alert_type': alert.alert_type,
                'severity_level': alert.severity_level,
                'alert_desc': alert.alert_desc,
                'alert_status': alert.alert_status,
                'alert_timestamp': alert.alert_timestamp.strftime("%Y-%m-%d %H:%M:%S") if alert.alert_timestamp else None,
                'responded_time': alert.responded_time.strftime("%Y-%m-%d %H:%M:%S") if alert.responded_time else None,
                'latitude': str(alert.latitude) if alert.latitude else '22.54036796',
                'longitude': str(alert.longitude) if alert.longitude else '114.01508952',
                'altitude': str(alert.altitude) if alert.altitude else '0'
            }
            result_list.append(alert_dict)
            
            # ç»Ÿè®¡è®¡æ•°
            alert_type_count[alert.alert_type] = alert_type_count.get(alert.alert_type, 0) + 1
            alert_level_count[alert.severity_level] = alert_level_count.get(alert.severity_level, 0) + 1
            alert_status_count[alert.alert_status] = alert_status_count.get(alert.alert_status, 0) + 1
            device_alert_count[alert.device_sn] = device_alert_count.get(alert.device_sn, 0) + 1
        
        # è·å–ç»„ç»‡åç§°
        org_name = None
        if orgId:
            org = db.session.query(OrgInfo).filter(OrgInfo.id == orgId).first()
            org_name = org.name if org else None
        
        response_data = {
            'success': True,
            'data': {
                'alerts': result_list,
                'totalAlerts': len(result_list),
                'alertTypeCount': alert_type_count,
                'alertLevelCount': alert_level_count,
                'alertStatusCount': alert_status_count,
                'deviceAlertCount': device_alert_count,
                'totalDevices': len(device_alert_count),
                'orgId': str(orgId) if orgId else None,
                'org_name': org_name,
                'userId': str(userId) if userId else None
            }
        }
        
        print(f"æŸ¥è¯¢ç»“æœ: å…±{len(result_list)}æ¡å‘Šè­¦")
        return response_data
        
    except Exception as e:
        print(f"æŸ¥è¯¢å‘Šè­¦å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'data': None
        }

def fetch_alerts_by_orgIdAndUserId1(orgId=None, userId=None, severityLevel=None):
    """
    è·å–å‘Šè­¦ä¿¡æ¯
    :param orgId: ç»„ç»‡IDï¼Œå¯é€‰
    :param userId: ç”¨æˆ·IDï¼Œå¯é€‰
    :param severityLevel: å‘Šè­¦çº§åˆ«ï¼Œå¯é€‰
    """
    try:
        from .admin_helper import is_admin_user  # å¯¼å…¥adminåˆ¤æ–­å‡½æ•°
        
        print("fetch_alerts_by_orgIdAndUserId.userId:", userId)
        print("fetch_alerts_by_orgIdAndUserId.orgId:", orgId)
        print("fetch_alerts_by_orgIdAndUserId.severityLevel:", severityLevel)
        # å¦‚æœæä¾›äº†userIdï¼Œä¼˜å…ˆä½¿ç”¨userIdæŸ¥è¯¢
        result_list = []
        device_sns = set()
        if userId:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜ç”¨æˆ·
            if is_admin_user(userId):
                org = db.session.query(OrgInfo).filter(OrgInfo.id == orgId).first() if orgId else None
                return {
                    'success': True,
                    'data': {
                        'alerts': [],
                        'totalAlerts': 0,
                        'alertTypeCount': {},
                        'alertLevelCount': {},
                        'alertStatusCount': {},
                        'deviceAlertCount': {},
                        'totalDevices': 0,
                        'orgId': str(orgId),
                        'org_name': org.name if org else None
                    }
                }
          
            # ç›´æ¥æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
            user = UserInfo.query.filter_by(id=userId).first()
            if user.device_sn:
                device_sns.add(user.device_sn)
            print('device_sns:',device_sns)
            # ä¿®å¤éƒ¨é—¨æŸ¥è¯¢
            dept = db.session.query(
                OrgInfo
            ).join(
                UserOrg,
                UserOrg.org_id == OrgInfo.id
            ).filter(
                UserOrg.user_id == userId
            ).first()
            
            if dept:
                # è·å–æ‰€æœ‰éƒ¨é—¨ä¿¡æ¯
                departments = {
                    str(dept.id): dept.name
                }
            else:
                departments = {}
        
        elif orgId:
            # ä½¿ç”¨ç»Ÿä¸€ç»„ç»‡æœåŠ¡è·å–å­éƒ¨é—¨ä¿¡æ¯
            try:
                org_service = get_unified_org_service()
                org_ids = org_service.get_org_descendants_ids(orgId)
                
                # è·å–æ‰€æœ‰éƒ¨é—¨ä¿¡æ¯
                departments = {
                    str(dept.id): dept.name for dept in OrgInfo.query.filter(
                        OrgInfo.id.in_(org_ids),
                        OrgInfo.is_deleted.is_(False),
                        OrgInfo.status == '1'
                    ).all()
                }
            except Exception as e:
                logger.error(f"è·å–éƒ¨é—¨ä¿¡æ¯å¤±è´¥: {str(e)}")
                departments = {}
        
            # è·å–ç»„ç»‡ä¸‹æ‰€æœ‰ç”¨æˆ·
            from .org import fetch_users_by_orgId
            users = fetch_users_by_orgId(orgId)
            
            # è·å–æ‰€æœ‰è®¾å¤‡çš„å‘Šè­¦
            
            for user in users:
                if user.get('device_sn'):
                    device_sns.add(user['device_sn'])

        if not device_sns:
            org = db.session.query(OrgInfo).filter(OrgInfo.id == orgId).first()
            return {
                'success': True,
                'data': {
                    'alerts': [],
                    'totalAlerts': 0,
                    'alertTypeCount': {},
                    'alertLevelCount': {},
                    'alertStatusCount': {},
                    'deviceAlertCount': {},
                    'totalDevices': 0,
                    'orgId': str(orgId),
                    'org_name': org.name if org else None
                }
            }

        # å®šä¹‰æ’åºé¡ºåº
        severity_order = case(
            (AlertInfo.severity_level == 'critical', 1),
            (AlertInfo.severity_level == 'high', 2),
            (AlertInfo.severity_level == 'medium', 3),
            else_=4
        )

        status_order = case(
            (AlertInfo.alert_status == 'pending', 1),
            (AlertInfo.alert_status == 'responded', 2),
            else_=3
        )

        # è·å–è®¾å¤‡ä¿¡æ¯
        device_query = db.session.query(DeviceInfo.serial_number).filter(   
            DeviceInfo.serial_number.in_(device_sns)  # ç¡®ä¿è®¾å¤‡å·åœ¨ç”¨æˆ·åˆ—è¡¨ä¸­
        )
        print('device_sns:',device_sns)
        # è·å–å‘Šè­¦ä¿¡æ¯
        alerts = db.session.query(
            AlertInfo.id,
            AlertInfo.alert_type,
            AlertInfo.severity_level,
            AlertInfo.alert_desc,
            AlertInfo.alert_status,
            AlertInfo.alert_timestamp,
            AlertInfo.responded_time,
            AlertInfo.device_sn,
            AlertInfo.health_id,
            UserInfo.id.label('user_id'),
            UserInfo.user_name,
            OrgInfo.id.label('dept_id'),
            OrgInfo.name.label('dept_name'),
            OrgInfo.ancestors,
            UserHealthData.latitude.label('latitude'),
            UserHealthData.longitude.label('longitude'),
            UserHealthData.altitude.label('altitude')
        ).outerjoin(
            UserInfo,
            AlertInfo.device_sn == UserInfo.device_sn
        ).outerjoin(
            UserOrg,
            UserInfo.id == UserOrg.user_id
        ).outerjoin(
            OrgInfo,
            UserOrg.org_id == OrgInfo.id
        ).outerjoin(
            UserHealthData,
            AlertInfo.health_id == UserHealthData.id
        ).filter(
            AlertInfo.device_sn.in_(device_query)  # ä½¿ç”¨å­æŸ¥è¯¢
        )
        #print('alerts before filter:',alerts)
       
        
        # ä¿®æ”¹ severityLevel è¿‡æ»¤é€»è¾‘
        if severityLevel:
            if severityLevel == 'high':
                # å¦‚æœæ˜¯highï¼Œæ˜¾ç¤ºhighå’Œmediumçº§åˆ«çš„å‘Šè­¦
                alerts = alerts.filter(
                    AlertInfo.severity_level.in_(['high', 'medium'])
                )
            else:
                # å…¶ä»–æƒ…å†µåªæ˜¾ç¤ºæŒ‡å®šçº§åˆ«çš„å‘Šè­¦
                alerts = alerts.filter(
                    AlertInfo.severity_level == severityLevel
                )

        alerts = alerts.order_by(
            severity_order,
            status_order,
            AlertInfo.alert_timestamp.desc()
        ).distinct().all()
        
        #print('alerts:',alerts)
      
        # å¤„ç†å‘Šè­¦æ•°æ®
     
        department_stats = {}  # éƒ¨é—¨ç»Ÿè®¡

        for alert in alerts:
            # è·å–éƒ¨é—¨å±‚çº§ä¿¡æ¯
            dept_hierarchy = []
            if alert.ancestors:
                ancestor_ids = alert.ancestors.split(',')
                dept_hierarchy = [departments.get(aid, 'Unknown') for aid in ancestor_ids]
            if alert.dept_name:
                dept_hierarchy.append(alert.dept_name)

            current_dept_id = str(alert.dept_id) if alert.dept_id else 'unknown'
            current_dept_name = alert.dept_name if alert.dept_name else 'Unknown Department'

            # v1.0.32 - æ„å»ºå‘Šè­¦å­—å…¸ï¼Œä¸ºç©ºåæ ‡æä¾›é»˜è®¤å€¼
            # ä¸ºæ²¡æœ‰åæ ‡çš„å‘Šè­¦æä¾›é»˜è®¤åæ ‡(æ·±åœ³åæ ‡)
            default_lat = '22.54036796'
            default_lng = '114.01508952'
            
            alert_dict = {
                'alert_id': str(alert.id),
                'device_sn': alert.device_sn,
                'alert_type': alert.alert_type,
                'severity_level': alert.severity_level,
                'alert_desc': alert.alert_desc,
                'alert_status': alert.alert_status,
                'alert_timestamp': alert.alert_timestamp.strftime("%Y-%m-%d %H:%M:%S") if alert.alert_timestamp else None,
                'responded_time': alert.responded_time.strftime("%Y-%m-%d %H:%M:%S") if alert.responded_time else None,
                'user_id': str(alert.user_id) if alert.user_id else None,
                'user_name': alert.user_name,
                'dept_id': str(alert.dept_id) if alert.dept_id else None,
                'dept_name': current_dept_name,
                'dept_hierarchy': dept_hierarchy,
                'latitude': str(alert.latitude) if alert.latitude else default_lat,
                'longitude': str(alert.longitude) if alert.longitude else default_lng,
                'altitude': str(alert.altitude) if alert.altitude else '0'
            }
            
            result_list.append(alert_dict)

            # ç»Ÿè®¡ä¿¡æ¯
            if current_dept_id not in department_stats:
                department_stats[current_dept_id] = {
                    'name': current_dept_name,
                    'total_alerts': 0,
                    'severity_stats': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0},
                    'status_stats': {'pending': 0, 'responded': 0, 'closed': 0},
                    'device_count': set()
                }

            dept_stat = department_stats[current_dept_id]
            dept_stat['total_alerts'] += 1
            dept_stat['severity_stats'][alert.severity_level] = dept_stat['severity_stats'].get(alert.severity_level, 0) + 1
            dept_stat['status_stats'][alert.alert_status] = dept_stat['status_stats'].get(alert.alert_status, 0) + 1
            dept_stat['device_count'].add(alert.device_sn)

        # è½¬æ¢è®¾å¤‡è®¡æ•°
        for dept_id, stats in department_stats.items():
            stats['device_count'] = len(stats['device_count'])

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        alert_type_count = {}
        alert_level_count = {}
        alert_status_count = {}
        device_alert_count = set()

        for alert in result_list:
            # æŒ‰ç±»å‹è®¡æ•°
            alert_type = alert['alert_type']
            alert_type_count[alert_type] = alert_type_count.get(alert_type, 0) + 1

            # æŒ‰çº§åˆ«è®¡æ•°
            severity_level = alert['severity_level']
            alert_level_count[severity_level] = alert_level_count.get(severity_level, 0) + 1

            # æŒ‰çŠ¶æ€è®¡æ•°
            alert_status = alert['alert_status']
            alert_status_count[alert_status] = alert_status_count.get(alert_status, 0) + 1

            # è®¾å¤‡è®¡æ•°ï¼ˆå»é‡ï¼‰
            device_alert_count.add(alert['device_sn'])

        # è·å–orgIdå¯¹åº”çš„éƒ¨é—¨åç§°
        org_name = "Unknown Organization"
        if orgId:
            org = db.session.query(OrgInfo).filter(OrgInfo.id == orgId).first()
            org_name = org.name if org else "Unknown Organization"

        return {
            'success': True,
            'data': {
                'alerts': result_list,
                'totalAlerts': len(result_list),
                'alertTypeCount': alert_type_count,
                'alertLevelCount': alert_level_count,
                'alertStatusCount': alert_status_count,
                'deviceAlertCount': dict(enumerate(device_alert_count)),
                'totalDevices': len(device_alert_count),
                'orgId': str(orgId) if orgId else None,
                'org_name': org_name,
                'departmentStats': department_stats
            }
        }

    except Exception as e:
        print(f"å‘Šè­¦æŸ¥è¯¢é”™è¯¯: {e}")
        return {
            'success': False,
            'error': f'å‘Šè­¦æŸ¥è¯¢å¤±è´¥: {str(e)}',
            'data': {
                'alerts': [],
                'totalAlerts': 0,
                'alertTypeCount': {},
                'alertLevelCount': {},
                'alertStatusCount': {},
                'deviceAlertCount': {},
                'totalDevices': 0,
                'orgId': str(orgId) if orgId else None,
                'org_name': None,
                'departmentStats': {}
            }
        }

def fetch_alerts(deviceSn, customerId):
    print("fetch_alerts:deviceSn:", deviceSn)
    from .user import get_user_info
    user_info = get_user_info(deviceSn)
    print("fetch_alerts:user_info:", user_info)
    if user_info:
        user_dict = json.loads(user_info)
        userId = user_dict.get('user_id')
        return fetch_alerts_by_orgIdAndUserId(orgId=None, userId=userId, severityLevel=None)
    else:
        return jsonify({"error": "User not found"}), 404

    try:
        severity_order = case(
            (AlertInfo.severity_level == 'critical', 1),
            (AlertInfo.severity_level == 'high', 2),
            (AlertInfo.severity_level == 'medium', 3),
            else_=4
        )

        status_order = case(
            (AlertInfo.alert_status == 'pending', 1),
            (AlertInfo.alert_status == 'responded', 2),
            else_=3
        )

        if deviceSn is None:
            subquery = db.session.query(DeviceInfo.serial_number).filter(DeviceInfo.customer_id == 1).subquery()
            alerts = AlertInfo.query.filter(AlertInfo.device_sn.in_(subquery)).order_by(
                status_order,
                severity_order,
                AlertInfo.update_time.desc()
            ).all()
        else:
            alerts = AlertInfo.query.filter_by(device_sn=deviceSn).order_by(
                status_order,
                severity_order,
                AlertInfo.update_time.desc()
            ).all()
        
        # Helper function to convert Decimal to float
        def convert_decimal(obj):
            if isinstance(obj, Decimal):
                return float(obj)  # or str(obj) if you prefer
            return obj

        alerts_data = [{
            'id': alert.id,
            'deviceSn': alert.device_sn,
            'alertType': alert.alert_type,
            'latitude': convert_decimal(alert.latitude),
            'longitude': convert_decimal(alert.longitude),
            'timestamp': alert.alert_timestamp.strftime("%Y-%m-%d %H:%M:%S"),
            'severityLevel': alert.severity_level,
            'alertStatus': alert.alert_status,
            'userName': get_user_name(alert.device_sn) if alert.device_sn else "Unknown"
        } for alert in alerts]
        
        # Calculate total number of alerts
        total_alerts = len(alerts)

        # Calculate total number of unique alert types
        unique_alert_types = len(set(alert.alert_type for alert in alerts))

        # Calculate counts for each alertStatus
        alert_status_counts = {}
        for alert in alerts:
            status = alert.alert_status
            if status in alert_status_counts:
                alert_status_counts[status] += 1
            else:
                alert_status_counts[status] = 1

        # Calculate counts for each alertType
        alert_type_counts = {}
        for alert in alerts:
            alert_type = alert.alert_type
            if alert_type in alert_type_counts:
                alert_type_counts[alert_type] = alert_type_counts.get(alert_type, 0) + 1
            else:
                alert_type_counts[alert_type] = 1

        # Calculate counts for each severityLevel
        severity_level_counts = {}
        for alert in alerts:
            severity_level = alert.severity_level
            if severity_level in severity_level_counts:
                severity_level_counts[severity_level] += 1
            else:
                severity_level_counts[severity_level] = 1

        response_data = {
            'success': True,
            'alerts': alerts_data,
            'totalAlerts': total_alerts,
            'uniqueAlertTypes': unique_alert_types,
            'alertStatusCounts': alert_status_counts,
            'alertTypeCounts': alert_type_counts,
            'severityLevelCounts': severity_level_counts
        }
        
        # Serialize the alerts_data list to a JSON string
        alerts_data_json = json.dumps(alerts_data, default=convert_decimal)
        #print("alerts_data_json:", alerts_data_json)
        if len(alerts_data_json) > 0:  # Check if alerts_data_json is not empty
            mapping = {str(alert['id']): json.dumps(alert) for alert in alerts_data}
            if mapping:  # Ensure mapping is not empty
                if deviceSn is None:
                    redis.hset(f"alert_info:all", mapping=mapping)
                    redis.publish("alert_info_channel", alerts_data_json)
                else:
                    redis.hset(f"alert_info:{deviceSn}", mapping=mapping)
                    redis.publish(f"alert_info_channel:{deviceSn}", alerts_data_json)

        return jsonify(response_data)
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    
def generate_alert_stats(alert_info):
    #print("generate_alert_stats:alert_info:", alert_info)

    try:
        # Calculate total number of alerts
        total_alerts = len(alert_info)

        # Initialize dictionaries for counts
        alert_status_counts = {}
        alert_type_counts = {}
        severity_level_counts = {}

        # Calculate counts for each category
        for alert in alert_info:
            # Count alert statuses
            alert_status_counts[alert['alertStatus']] = alert_status_counts.get(alert['alertStatus'], 0) + 1

            # Count alert types
            alert_type_counts[alert['alertType']] = alert_type_counts.get(alert['alertType'], 0) + 1

            # Count severity levels
            severity_level_counts[alert['severityLevel']] = severity_level_counts.get(alert['severityLevel'], 0) + 1

        # Calculate total number of unique alert types
        unique_alert_types = len(alert_type_counts)
        print("unique_alert_types:", unique_alert_types)
        print("alert_status_counts:", alert_status_counts)
        print("alert_type_counts:", alert_type_counts)
        print("severity_level_counts:", severity_level_counts)

        # Return a raw dictionary, not a Flask Response
        return {
            'alerts': alert_info,
            'totalAlerts': total_alerts,
            'uniqueAlertTypes': unique_alert_types,
            'alertStatusCounts': alert_status_counts,
            'alertTypeCounts': alert_type_counts,
            'severityLevelCounts': severity_level_counts
        }
    except Exception as e:
        print(f"Error: {str(e)}")
        return {'success': False, 'error': str(e)}  # Return raw error data

def fetch_alertType_stats():
    userName = request.args.get('userName')
    try:
        from sqlalchemy import func
        from datetime import datetime

        # Base query for alert type counts
        query = db.session.query(AlertInfo.alertType, func.count(AlertInfo.alertType).label('count'))

        if userName:
            query = query.filter(AlertInfo.userName == userName)

        alert_type_counts = query.group_by(AlertInfo.alertType).all()

        # Convert query results to dictionary list
        alert_type_data = [{'name': alert_type, 'value': count} for alert_type, count in alert_type_counts]

        # Calculate total number of alerts
        total_alerts_query = db.session.query(func.count(AlertInfo.id))
        if userName:
            total_alerts_query = total_alerts_query.filter(AlertInfo.userName == userName)
        total_alerts = total_alerts_query.scalar()

        # Calculate number of alerts added this month
        start_of_month = datetime(datetime.now().year, datetime.now().month, 1)
        monthly_alerts_query = db.session.query(func.count(AlertInfo.id)).filter(AlertInfo.timestamp >= start_of_month)
        if userName:
            monthly_alerts_query = monthly_alerts_query.filter(AlertInfo.userName == userName)
        monthly_alerts = monthly_alerts_query.scalar()

        return jsonify({
            'success': True,
            'alertTypeStats': alert_type_data,
            'totalAlerts': total_alerts,
            'monthlyAlerts': monthly_alerts
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    
    
def get_severity_level_mapping(severity):
    """
    å°†è‹±æ–‡å‘Šè­¦çº§åˆ«æ˜ å°„ä¸ºæ•°å­—çº§åˆ«
    medium -> ä¸‰çº§
    high -> äºŒçº§
    critical -> ä¸€çº§
    """
    severity_mapping = {
        'medium': 'ä¸‰çº§',
        'high': 'äºŒçº§',
        'critical': 'ä¸€çº§'
    }
    return severity_mapping.get(severity.lower(), 'æœªçŸ¥çº§åˆ«')

def deal_alert(alertId):
    """å‘Šè­¦å¤„ç†å‡½æ•° - æ ¹æ®notification_typeæ‰§è¡Œä¸åŒå¤„ç†é€»è¾‘"""
    print("deal_alert:alertId:", alertId)
    
    try:
        # è·å–å‘Šè­¦ä¿¡æ¯
        alert = AlertInfo.query.filter_by(id=alertId).first()
        if not alert:
            return jsonify({'success': False, 'message': 'å‘Šè­¦è®°å½•ä¸å­˜åœ¨'}), 404
            
        print(f"ğŸ“‹ å‘Šè­¦ä¿¡æ¯: device_sn={alert.device_sn}, rule_id={alert.rule_id}, alert_type={alert.alert_type}")
        
        # æ£€æŸ¥rule_idæ˜¯å¦å­˜åœ¨
        if not alert.rule_id:
            print("âš ï¸ å‘Šè­¦è®°å½•ç¼ºå°‘rule_idï¼Œä½¿ç”¨é»˜è®¤å¤„ç†æ–¹å¼")
            # ä½¿ç”¨é»˜è®¤è§„åˆ™å¤„ç†
            rule_data = {
                'id': None,
                'rule_type': alert.alert_type,
                'notification_type': 'message',  # é»˜è®¤æ¶ˆæ¯é€šçŸ¥
                'severity_level': alert.severity_level or 'medium',
                'alert_message': alert.alert_desc or f'{alert.alert_type}å‘Šè­¦'
            }
        else:
            # ä½¿ç”¨ORMæŸ¥è¯¢è·å–å‘Šè­¦è§„åˆ™ä¿¡æ¯
            rule=AlertRules.query.filter_by(id=alert.rule_id,is_deleted=False).first()
            
            if not rule:
                print(f"âš ï¸ å‘Šè­¦è§„åˆ™ID {alert.rule_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†æ–¹å¼")
                # ä½¿ç”¨é»˜è®¤è§„åˆ™å¤„ç†
                rule_data = {
                    'id': alert.rule_id,
                    'rule_type': alert.alert_type,
                    'notification_type': 'message',  # é»˜è®¤ä¸ºmessage
                    'severity_level': alert.severity_level or 'medium',
                    'alert_message': alert.alert_desc or f'{alert.alert_type}å‘Šè­¦'
                }
            else:
                # è§£æè§„åˆ™æ•°æ®
                rule_data = {
                    'id': rule.id,
                    'rule_type': rule.rule_type, 
                    'notification_type': rule.notification_type or 'message',  # é»˜è®¤ä¸ºmessage
                    'severity_level': rule.severity_level or 'medium',
                    'alert_message': rule.alert_message
                }
                
        print(f"ğŸ“‹ è§„åˆ™ä¿¡æ¯: ID={rule_data['id']}, notification_type={rule_data['notification_type']}")
            
        # è·å–è®¾å¤‡ç”¨æˆ·ä¿¡æ¯
        print(f"ğŸ“‹ è®¾å¤‡ç”¨æˆ·ä¿¡æ¯: device_sn={alert.device_sn}")
        user = UserInfo.query.filter_by(device_sn=alert.device_sn).first()
        print(f"ğŸ“‹ è®¾å¤‡ç”¨æˆ·ä¿¡æ¯: user={user}")
        if not user:
            return jsonify({'success': False, 'message': 'è®¾å¤‡ç”¨æˆ·ä¸å­˜åœ¨'}), 404
            
        userName = user.user_name
        userId = user.id
        mapped_severity = get_severity_level_mapping(alert.severity_level)
        
        # æ ¹æ®notification_typeå¤„ç†å‘Šè­¦
        wechat_result = None
        message_result = None
        websocket_result = None
        notification_type = rule_data['notification_type']
        
        # ğŸš¨ Criticalçº§åˆ«å‘Šè­¦å¢å¼ºå¤„ç†
        if alert.severity_level == 'critical':
            print(f"ğŸš¨ Criticalçº§åˆ«å‘Šè­¦ - æ‰§è¡Œå¢å¼ºå¤„ç†")
            
            # 1. WebSocketæ¨é€åˆ°å¤§å±
            try:
                from .bigScreen import socketio
                
                # æ„å»ºå‘Šè­¦æ¨é€æ•°æ®
                alert_data = {
                    'alert_id': alert.id,
                    'device_sn': alert.device_sn,
                    'alert_type': alert.alert_type,
                    'alert_desc': alert.alert_desc,
                    'severity_level': 'critical',
                    'alert_timestamp': alert.alert_timestamp.strftime('%Y-%m-%d %H:%M:%S') if alert.alert_timestamp else None,
                    'user_name': userName,
                    'user_id': userId,
                    'latitude': str(alert.latitude) if alert.latitude else None,
                    'longitude': str(alert.longitude) if alert.longitude else None
                }
                
                # é€šè¿‡WebSocketæ¨é€åˆ°å¤§å±é¡µé¢
                socketio.emit('critical_alert', alert_data, namespace='/')
                print(f"ğŸš¨ Criticalå‘Šè­¦å·²æ¨é€åˆ°å¤§å±: alert_id={alert.id}")
                websocket_result = True
                
            except Exception as ws_error:
                print(f"âš ï¸ WebSocketæ¨é€å¤±è´¥: {ws_error}")
                websocket_result = False
        
        if notification_type in ['wechat', 'both']:
            # å¾®ä¿¡æ¨é€
            from .wechat import send_message
            wechat_result = send_message(alert.alert_type, userName, mapped_severity)
            print("å¾®ä¿¡æ¨é€ç»“æœ:", wechat_result)
            
        if notification_type in ['message', 'both']:
            # æ’å…¥æ¶ˆæ¯è®°å½• - å¢å¼ºç‰ˆå±‚çº§é€šçŸ¥
            message_result = _insert_device_messages_enhanced(alert.device_sn, alert.alert_type, mapped_severity, userName, alert.severity_level)
            print("æ¶ˆæ¯æ’å…¥ç»“æœ:", message_result)
        
        # è®°å½•å¤„ç†æ—¥å¿—
        _create_alert_log_enhanced(alertId, userName, userId, notification_type, wechat_result, message_result, websocket_result)
        
        # æ›´æ–°å‘Šè­¦çŠ¶æ€
        if ((notification_type == 'wechat' and wechat_result and wechat_result.get('errcode') == 0) or
            (notification_type == 'message' and message_result) or
            (notification_type == 'both' and message_result and 
             (not wechat_result or wechat_result.get('errcode') == 0))):
            
            alert.alert_status = 'responded'
            alert.responded_time = get_now() #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
            db.session.commit()
            return jsonify({'success': True, 'message': f'å‘Šè­¦å·²é€šè¿‡{notification_type}å¤„ç†'})
        else:
            db.session.commit()
            return jsonify({'success': False, 'message': 'å‘Šè­¦å¤„ç†å¤±è´¥'}), 500
            
    except Exception as e:
        db.session.rollback()
        print(f"å‘Šè­¦å¤„ç†å¼‚å¸¸: {e}")
        return jsonify({'success': False, 'message': f'å‘Šè­¦å¤„ç†å¼‚å¸¸: {str(e)}'}), 500

def _insert_device_messages_enhanced(device_sn, alert_type, severity_level, user_name, alert_severity_level):
    """æ’å…¥è®¾å¤‡æ¶ˆæ¯è®°å½• - å¢å¼ºç‰ˆå±‚çº§é€šçŸ¥"""
    try:
        from .models import DeviceMessage, UserOrg, DeviceInfo, OrgInfo
        
        # æ ¹æ®device_snæŸ¥è¯¢org_idå’Œuser_id
        device = DeviceInfo.query.filter_by(serial_number=device_sn).first()
        if not device or not device.org_id or not device.user_id:
            print(f"è®¾å¤‡{device_sn}æœªç»‘å®šç»„ç»‡æˆ–ç”¨æˆ·")
            return False
            
        org_id = device.org_id
        user_id = device.user_id
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = f"è®¾å¤‡{device_sn}å‘ç”Ÿ{alert_type}å‘Šè­¦ï¼Œä¸¥é‡çº§åˆ«ï¼š{severity_level}ï¼Œè¯·åŠæ—¶å¤„ç†ã€‚"
        
        # åˆ›å»ºæ¶ˆæ¯è®°å½•
        message_records = []
        
        # 1. ç»™è®¾å¤‡ç”¨æˆ·çš„æ¶ˆæ¯
        user_message = DeviceMessage(
            device_sn=device_sn,
            message=message_content,
            org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
            user_id=str(user_id),
            message_type='warning',
            sender_type='system', 
            receiver_type='user',
            message_status='1',
            create_time=get_now()
        )
        message_records.append(user_message)
        
        # 2. ç»™éƒ¨é—¨ä¸»ç®¡çš„æ¶ˆæ¯ - ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢
        try:
            # è·å–ç§Ÿæˆ·ID (customer_id)
            customer_id = getattr(device, 'customer_id', 0)
            org_service = get_org_service()
            principals_data = org_service.find_org_managers(org_id, customer_id, "manager")
            
            for principal_data in principals_data:
                principal_user_id = principal_data['user_id']
                if principal_user_id != user_id:  # é¿å…é‡å¤ç»™åŒä¸€äººå‘æ¶ˆæ¯
                    principal_message = DeviceMessage(
                        device_sn=device_sn,
                        message=message_content + f"ï¼ˆè®¾å¤‡ç”¨æˆ·ï¼š{user_name}ï¼‰",
                        org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
                        user_id=str(principal_user_id),
                        message_type='warning',
                        sender_type='system',
                        receiver_type='manager',
                        message_status='1',
                        create_time=get_now()
                    )
                    message_records.append(principal_message)
        except Exception as e:
            print(f"ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {str(e)}")
            # å›é€€åˆ°åŸå§‹æŸ¥è¯¢æ–¹å¼
            principals = UserOrg.query.filter_by(org_id=org_id, principal='1', is_deleted=False).all()
            for principal in principals:
                if principal.user_id != user_id:  # é¿å…é‡å¤ç»™åŒä¸€äººå‘æ¶ˆæ¯
                    principal_message = DeviceMessage(
                        device_sn=device_sn,
                        message=message_content + f"ï¼ˆè®¾å¤‡ç”¨æˆ·ï¼š{user_name}ï¼‰",
                        org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
                        user_id=str(principal.user_id),
                        message_type='warning',
                        sender_type='system',
                        receiver_type='manager',
                        message_status='1',
                        create_time=get_now()
                    )
                    message_records.append(principal_message)
        
        # 3. å¦‚æœæ˜¯messageæ–¹å¼ä¸”æ²¡æœ‰éƒ¨é—¨ç®¡ç†å‘˜ï¼Œç»™ç§Ÿæˆ·çº§åˆ«ç®¡ç†å‘˜å‘æ¶ˆæ¯
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨é—¨ç®¡ç†å‘˜
            if not principals_data:
                # æŸ¥æ‰¾å½“å‰éƒ¨é—¨çš„çˆ¶çº§ç»„ç»‡(ç§Ÿæˆ·çº§åˆ«)
                current_org = OrgInfo.query.filter_by(id=org_id).first()
                if current_org and current_org.parent_id:
                    # ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢è·å–çˆ¶çº§ç»„ç»‡ç®¡ç†å‘˜
                    parent_principals_data = org_service.find_org_managers(
                        current_org.parent_id, customer_id, "manager")
                    
                    for parent_principal_data in parent_principals_data:
                        tenant_message = DeviceMessage(
                            device_sn=device_sn,
                            message=message_content + f"ï¼ˆè®¾å¤‡ç”¨æˆ·ï¼š{user_name}ï¼Œéƒ¨é—¨ï¼š{current_org.name}ï¼‰",
                            org_id=str(current_org.parent_id),  # ä¿®æ”¹: department_info -> org_id
                            user_id=str(parent_principal_data['user_id']),
                            message_type='warning',
                            sender_type='system',
                            receiver_type='tenant_admin',
                            message_status='1',
                            create_time=get_now()
                        )
                        message_records.append(tenant_message)
        except Exception as e:
            print(f"ç§Ÿæˆ·çº§åˆ«ç®¡ç†å‘˜æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        # æ‰¹é‡æ’å…¥æ¶ˆæ¯è®°å½•
        for record in message_records:
            db.session.add(record)
        db.session.flush()
        
        print(f"âœ… æˆåŠŸæ’å…¥{len(message_records)}æ¡æ¶ˆæ¯è®°å½•ï¼ˆå±‚çº§é€šçŸ¥ï¼‰")
        return True
        
    except Exception as e:
        print(f"âŒ æ’å…¥æ¶ˆæ¯è®°å½•å¤±è´¥: {e}")
        return False

def _insert_device_messages(device_sn, alert_type, severity_level, user_name):
    """æ’å…¥è®¾å¤‡æ¶ˆæ¯è®°å½•"""
    try:
        from .models import DeviceMessage, UserOrg, DeviceInfo
        
        # æ ¹æ®device_snæŸ¥è¯¢org_idå’Œuser_id
        device = DeviceInfo.query.filter_by(serial_number=device_sn).first()
        if not device or not device.org_id or not device.user_id:
            print(f"è®¾å¤‡{device_sn}æœªç»‘å®šç»„ç»‡æˆ–ç”¨æˆ·")
            return False
            
        org_id = device.org_id
        user_id = device.user_id
        
        # æŸ¥è¯¢è¯¥ç»„ç»‡çš„ä¸»ç®¡(principal=1) - ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢
        try:
            # è·å–ç§Ÿæˆ·ID (customer_id)
            customer_id = getattr(device, 'customer_id', 0)
            org_service = get_org_service()
            principals_data = org_service.find_org_managers(org_id, customer_id, "manager")
            principal_user_ids = [p['user_id'] for p in principals_data]
        except Exception as e:
            print(f"ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æŸ¥è¯¢: {str(e)}")
            # å›é€€åˆ°åŸå§‹æŸ¥è¯¢æ–¹å¼
            principals = UserOrg.query.filter_by(org_id=org_id, principal='1', is_deleted=False).all()
            principal_user_ids = [p.user_id for p in principals]
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = f"è®¾å¤‡{device_sn}å‘ç”Ÿ{alert_type}å‘Šè­¦ï¼Œä¸¥é‡çº§åˆ«ï¼š{severity_level}ï¼Œè¯·åŠæ—¶å¤„ç†ã€‚"
        
        # åˆ›å»ºæ¶ˆæ¯è®°å½•
        message_records = []
        
        # å¦‚æœç”¨æˆ·æœ¬äººæ˜¯ä¸»ç®¡ï¼Œåªæ’å…¥ä¸€æ¡è®°å½•
        if user_id in principal_user_ids:
            message = DeviceMessage(
                device_sn=device_sn,
                message=message_content,
                org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
                user_id=str(user_id),
                message_type='warning',
                sender_type='system',
                receiver_type='manager_and_user',
                message_status='1',
                create_time=get_now() #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
            )
            message_records.append(message)
        else:
            # ç”¨æˆ·å’Œä¸»ç®¡ä¸åŒï¼Œæ’å…¥ä¸¤æ¡è®°å½•
            # 1. ç»™ç”¨æˆ·çš„æ¶ˆæ¯
            user_message = DeviceMessage(
                device_sn=device_sn,
                message=message_content,
                org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
                user_id=str(user_id),
                message_type='warning',
                sender_type='system', 
                receiver_type='user',
                message_status='1',
                create_time=get_now() #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
            )
            message_records.append(user_message)
            
            # 2. ç»™ä¸»ç®¡çš„æ¶ˆæ¯
            for principal_id in principal_user_ids:
                principal_message = DeviceMessage(
                    device_sn=device_sn,
                    message=message_content + f"ï¼ˆè®¾å¤‡ç”¨æˆ·ï¼š{user_name}ï¼‰",
                    org_id=str(org_id),  # ä¿®æ”¹: department_info -> org_id
                    user_id=str(principal_id),
                    message_type='warning',
                    sender_type='system',
                    receiver_type='manager',
                    message_status='1',
                    create_time=get_now() #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
                )
                message_records.append(principal_message)
        
        # æ‰¹é‡æ’å…¥æ¶ˆæ¯è®°å½•
        for record in message_records:
            db.session.add(record)
        db.session.flush()  # æäº¤åˆ°æ•°æ®åº“ä½†ä¸ç»“æŸäº‹åŠ¡
        
        print(f"æˆåŠŸæ’å…¥{len(message_records)}æ¡æ¶ˆæ¯è®°å½•")
        return True
        
    except Exception as e:
        print(f"æ’å…¥æ¶ˆæ¯è®°å½•å¤±è´¥: {e}")
        return False

def _create_alert_log_enhanced(alert_id, user_name, user_id, notification_type, wechat_result, message_result, websocket_result):
    """åˆ›å»ºå‘Šè­¦å¤„ç†æ—¥å¿— - å¢å¼ºç‰ˆ"""
    try:
        from .models import AlertLog
        
        # ç¡®å®šå¤„ç†æ–¹å¼å’Œç»“æœ
        handled_via_list = []
        results = []
        
        if notification_type in ['wechat', 'both']:
            handled_via_list.append('WeChat')
            results.append('success' if wechat_result and wechat_result.get('errcode') == 0 else 'failed')
            
        if notification_type in ['message', 'both']:
            handled_via_list.append('Message')
            results.append('success' if message_result else 'failed')
            
        if websocket_result is not None:
            handled_via_list.append('WebSocket')
            results.append('success' if websocket_result else 'failed')
        
        handled_via = '+'.join(handled_via_list)
        result = 'success' if 'success' in results else 'failed'
        
        details = f"å‘Šè­¦é€šè¿‡{handled_via}å¤„ç†"
        if notification_type == 'both':
            details += f"ï¼Œå¾®ä¿¡ï¼š{'æˆåŠŸ' if wechat_result and wechat_result.get('errcode') == 0 else 'å¤±è´¥'}ï¼Œæ¶ˆæ¯ï¼š{'æˆåŠŸ' if message_result else 'å¤±è´¥'}"
        if websocket_result is not None:
            details += f"ï¼ŒWebSocketæ¨é€ï¼š{'æˆåŠŸ' if websocket_result else 'å¤±è´¥'}"
        
        alert_log = AlertLog(
            alert_id=alert_id,
            action='deal_alert_enhanced',
            action_user=user_name,
            action_user_id=user_id,
            details=details,
            handled_via=handled_via,
            result=result,
            action_timestamp=get_now()
        )
        db.session.add(alert_log)
        
    except Exception as e:
        print(f"åˆ›å»ºå‘Šè­¦æ—¥å¿—å¤±è´¥: {e}")

def _create_alert_log(alert_id, user_name, user_id, notification_type, wechat_result, message_result):
    """åˆ›å»ºå‘Šè­¦å¤„ç†æ—¥å¿—"""
    try:
        from .models import AlertLog
        
        # ç¡®å®šå¤„ç†æ–¹å¼å’Œç»“æœ
        handled_via_list = []
        results = []
        
        if notification_type in ['wechat', 'both']:
            handled_via_list.append('WeChat')
            results.append('success' if wechat_result and wechat_result.get('errcode') == 0 else 'failed')
            
        if notification_type in ['message', 'both']:
            handled_via_list.append('Message')
            results.append('success' if message_result else 'failed')
        
        handled_via = '+'.join(handled_via_list)
        result = 'success' if 'success' in results else 'failed'
        
        details = f"å‘Šè­¦é€šè¿‡{handled_via}å¤„ç†"
        if notification_type == 'both':
            details += f"ï¼Œå¾®ä¿¡ï¼š{'æˆåŠŸ' if wechat_result and wechat_result.get('errcode') == 0 else 'å¤±è´¥'}ï¼Œæ¶ˆæ¯ï¼š{'æˆåŠŸ' if message_result else 'å¤±è´¥'}"
        
        alert_log = AlertLog(
            alert_id=alert_id,
            action='deal_alert',
            action_user=user_name,
            action_user_id=user_id,
            details=details,
            handled_via=handled_via,
            result=result,
            action_timestamp=get_now() #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
        )
        db.session.add(alert_log)
        
    except Exception as e:
        print(f"åˆ›å»ºå‘Šè­¦æ—¥å¿—å¤±è´¥: {e}")

def generate_alert_chart_by_type(customerId):

    if not customerId:
        return jsonify({'success': False, 'error': 'Missing customerId parameter'}), 400
    subquery = db.session.query(DeviceInfo.serial_number).filter(DeviceInfo.customer_id == customerId).subquery()
    # Query using SQLAlchemy ORM
    alert_counts = db.session.query(
        db.func.count(AlertInfo.id).label('alertCount'),
        AlertInfo.alert_type
    ).filter(AlertInfo.device_sn.in_(subquery)).group_by(AlertInfo.alert_type).order_by(AlertInfo.alert_type).all()

    # Convert the result to a list of dictionaries
    alert_counts = [{'alertCount': count, 'alertType': alert_type} for count, alert_type in alert_counts]

    # Return the JSON response
    return jsonify({'success': True, 'data': alert_counts})


def gather_deal_alert(customerId):  # Get the severityLevel from query parameters
    # å­æŸ¥è¯¢ï¼šè·å–æ‰€æœ‰åŒ¹é…çš„è®¾å¤‡åºåˆ—å·
    subquery = db.session.query(DeviceInfo.serial_number).filter(DeviceInfo.customer_id == customerId)
    filter_query = and_(AlertInfo.alert_status == 'responded')

    query = (
        AlertInfo.query
        .filter(filter_query)
        .filter(AlertInfo.device_sn.in_(subquery))  # ä½¿ç”¨ç›´æ¥çš„å­æŸ¥è¯¢
    )

    alerts = query.all()
    
    # Calculate the number of alerts
    alert_count = len(alerts)
    
    # Return the count of alerts
    return jsonify({'success': True, 'alertCount': alert_count})
    

def generate_alert_json(orgId, userId, severityLevel):
    # è·å–å‘Šè­¦æ•°æ®
    alerts_response = fetch_alerts_by_orgIdAndUserId(orgId, userId, severityLevel)
    #print("generate_alert_json.alerts_response:", alerts_response)
    
    # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
    if not alerts_response.get('success'):
        return jsonify({
            "type": "FeatureCollection",
            "features": []
        })

    # ä»å“åº”ä¸­è·å–å‘Šè­¦åˆ—è¡¨
  
    alerts = alerts_response['data']['alerts']
    #print("generate_alert_json.alerts:", alerts)
    
    # æ ¼å¼åŒ–ä¸º GeoJSON
    features = []
    for alert in alerts:
        print("generate_alert_json.alert:", alert['alert_status'])
        # v1.0.32 - ä¿®å¤å‘Šè­¦ç‚¹è¿‡æ»¤é€»è¾‘ï¼šæ£€æŸ¥åæ ‡å’ŒçŠ¶æ€
        longitude = alert.get('longitude')
        latitude = alert.get('latitude') 
        status = alert.get('alert_status')
        print(f"ğŸ” æ£€æŸ¥å‘Šè­¦ç‚¹: ID={alert.get('alert_id')}, ç»åº¦={longitude}, çº¬åº¦={latitude}, çŠ¶æ€={status}")
        
        # æ”¹è¿›æ¡ä»¶åˆ¤æ–­ï¼šç¡®ä¿åæ ‡æœ‰æ•ˆä¸”çŠ¶æ€ä¸ºpending
        if (longitude and longitude != 'None' and longitude != '0' and 
            latitude and latitude != 'None' and latitude != '0' and 
            status == 'pending'):
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [
                        float(alert['longitude']) if alert['longitude'] is not None else 0.0,
                        float(alert['latitude']) if alert['latitude'] is not None else 0.0
                    ]
                },
                "properties": {
                    "id": alert['alert_id'],
                    "deviceSn": alert['device_sn'],
                    "alertType": alert['alert_type'],
                    "alertDesc": alert['alert_desc'],
                    "status": alert['alert_status'],
                    "severityLevel": alert['severity_level'],
                    "userName": alert['user_name'],
                    "timestamp": alert['alert_timestamp']
                }
            }
            features.append(feature)

    # æ„é€ æœ€ç»ˆçš„ GeoJSON
    alert_json = {
        "type": "FeatureCollection",
        "features": features
    }

    # è¿”å› JSON å“åº”
    return jsonify(alert_json)



def generate_alert_chart():
    customerId = request.args.get('customerId')
    timeDimension = request.args.get('timeDimension')  # New parameter for time dimension

    if not customerId:
        return jsonify({'success': False, 'error': 'Missing customerId parameter'}), 400

    # Subquery to get all serial numbers for the given customer_id
    subquery = db.session.query(DeviceInfo.serial_number).filter(DeviceInfo.customer_id == customerId).subquery()

    # Base query using SQLAlchemy ORM
    query = db.session.query(
        db.func.count(AlertInfo.id).label('alertCount'),
        AlertInfo.severity_level
    ).filter(
        AlertInfo.device_sn.in_(subquery)  # Add the filter for device_sn
    )

    # Modify query based on time dimension
    if timeDimension == 'day':
        query = query.add_columns(db.func.hour(AlertInfo.alert_timestamp).label('timeUnit'))
    elif timeDimension == 'week':
        query = query.add_columns(db.func.dayofweek(AlertInfo.alert_timestamp).label('timeUnit'))
    elif timeDimension == 'month':
        query = query.add_columns(db.func.day(AlertInfo.alert_timestamp).label('timeUnit'))
    else:
        return jsonify({'success': False, 'error': 'Invalid timeDimension parameter'}), 400

    query = query.group_by('timeUnit', AlertInfo.severity_level).order_by('timeUnit')

    alert_counts = query.all()

    # Convert the result to a list of dictionaries
    alert_counts = [{'alertCount': count, 'severityLevel': severity_level, 'timeUnit': time_unit} for count, severity_level, time_unit in alert_counts]

    # Return the JSON response
    return jsonify({'success': True, 'data': alert_counts})


def test_wechat_alert():
    # æµ‹è¯•æ•°æ®
    test_heart_rate = 140
    test_user_openid = WECHAT_USER_OPENID
    test_user_name = "æµ‹è¯•ç”¨æˆ·"
    
    # Debug prints to check values
    print(f"Testing alert for user: {test_user_name}, heart rate: {test_heart_rate}")

    # è°ƒç”¨ send_wechat_alert å‡½æ•°
    response = send_wechat_alert("å¿ƒç‡å¼‚å¸¸", WECHAT_USER_OPENID, "æµ‹è¯•ç”¨æˆ·", "äºŒçº§")

    # è¿”å›å“åº”ç»“æœ
    return jsonify(response)
def upload_common_event():
    try:
        data=request.json
        print(f"ğŸ“¡ [upload_common_event] æ¥å£è¢«è°ƒç”¨")
        print(f"ğŸ“¡ [upload_common_event] æ¥æ”¶åŸå§‹æ•°æ®:{data}")
        
        #æå–äº‹ä»¶ç±»å‹
        event_type=data.get('eventType','').split('.')[-1] #ä»com.tdtech.ohos.action.WEAR_STATUS_CHANGEDæå–WEAR_STATUS_CHANGED
        device_sn=data.get('deviceSn','')
        from .time_config import TimeConfig
        time_cfg = TimeConfig()
        alert_timestamp=data.get('timestamp', time_cfg.now().strftime('%Y-%m-%d %H:%M:%S'))
        
        # ä¼˜å…ˆä½¿ç”¨ç›´æ¥ä¼ é€’çš„å®¢æˆ·ä¿¡æ¯å‚æ•°
        customerId = data.get("customer_id")
        orgId = data.get("org_id") 
        userId = data.get("user_id")
        
        print(f"ğŸ“¡ [upload_common_event] å®¢æˆ·ä¿¡æ¯: customerId={customerId}, orgId={orgId}, userId={userId}")
        
        # å¦‚æœæ²¡æœ‰ç›´æ¥ä¼ é€’ç”¨æˆ·ä¿¡æ¯ï¼Œé€šè¿‡deviceSnæŸ¥è¯¢è·å–ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        if not customerId or not orgId or not userId:
            print(f"ğŸ“¡ [upload_common_event] å®¢æˆ·ä¿¡æ¯ä¸å®Œæ•´ï¼Œé€šè¿‡deviceSnæŸ¥è¯¢è·å–")
            device_user_org=get_device_user_org_info(device_sn)
            if not device_user_org.get('success'):
                return jsonify({"status":"error","message":f"æœªæ‰¾åˆ°{device_sn}çš„ç»„ç»‡æˆ–ç”¨æˆ·"}),400
            
            customerId = customerId or device_user_org.get('customer_id')
            orgId = orgId or device_user_org.get('org_id')
            userId = userId or device_user_org.get('user_id')
            
            print(f"ğŸ“¡ [upload_common_event] è¡¥å……åçš„å®¢æˆ·ä¿¡æ¯: customerId={customerId}, orgId={orgId}, userId={userId}")
        else:
            print(f"ğŸ“¡ [upload_common_event] ä½¿ç”¨ç›´æ¥ä¼ é€’çš„å®¢æˆ·ä¿¡æ¯")
        
        
        #æŸ¥è¯¢å‘Šè­¦è§„åˆ™
        rule=AlertRules.query.filter_by(rule_type=event_type,is_deleted=False).first()
        if not rule:return jsonify({"status":"error","message":f"æœªæ‰¾åˆ°{event_type}çš„å‘Šè­¦è§„åˆ™"}),400
        
        #åˆ›å»ºå‘Šè­¦è®°å½•
        alert=AlertInfo(
            rule_id=rule.id,alert_type=event_type,device_sn=device_sn,
            alert_desc=f"{rule.alert_message}(äº‹ä»¶å€¼:{data.get('eventValue','')})",
            severity_level=rule.severity_level,latitude=data.get('latitude',22.54036796),
            longitude=data.get('longitude',114.01508952),altitude=data.get('altitude',0),
            customer_id=customerId,
            org_id=orgId,
            user_id=userId,
            alert_timestamp=alert_timestamp
        )
        db.session.add(alert)
        db.session.flush() #è·å–alert.id
        
        #å¤„ç†å¥åº·æ•°æ®
        health_id=None
        if data.get('healthData'):
            print(f"ğŸ¥ å‘ç°healthDataå­—æ®µ: {data['healthData']}")
            
            # æ£€æŸ¥healthDataçš„ç»“æ„
            health_data = data['healthData']
            if isinstance(health_data, dict):
                print(f"ğŸ¥ healthDataæ˜¯å­—å…¸ç±»å‹ï¼Œé”®: {list(health_data.keys())}")
                
                # å°è¯•ä»ä¸åŒçš„å¯èƒ½è·¯å¾„æå–æ•°æ®
                actual_health_data = None
                if 'data' in health_data:
                    actual_health_data = health_data['data']
                    print(f"ğŸ¥ ä»healthData.dataæå–: {actual_health_data}")
                else:
                    actual_health_data = health_data
                    print(f"ğŸ¥ ç›´æ¥ä½¿ç”¨healthData: {actual_health_data}")
                
                # å¤„ç†å¥åº·æ•°æ®
                if actual_health_data:
                    from .user_health_data import process_single_health_data
                    print(f"ğŸ¥ å‡†å¤‡å¤„ç†å¥åº·æ•°æ®: {actual_health_data}")
                    health_id = process_single_health_data(actual_health_data)
                    print(f"ğŸ¥ å¥åº·æ•°æ®å¤„ç†ç»“æœï¼Œhealth_id: {health_id}")
                    if health_id:
                        alert.health_id = health_id
                else:
                    print("ğŸ¥ âŒ æ— æ³•æå–æœ‰æ•ˆçš„å¥åº·æ•°æ®")
            else:
                print(f"ğŸ¥ âŒ healthDataä¸æ˜¯å­—å…¸ç±»å‹: {type(health_data)}, å€¼: {health_data}")
        else:
            print("ğŸ¥ âŒ æ•°æ®ä¸­æ²¡æœ‰healthDataå­—æ®µ")
        
        db.session.commit()
        
        # ğŸš¨ Criticalçº§åˆ«å‘Šè­¦WebSocketå®æ—¶æ¨é€åˆ°å¤§å±
        if rule.severity_level == 'critical':
            try:
                from .bigScreen import socketio
                
                # æ„å»ºå‘Šè­¦æ¨é€æ•°æ®
                alert_data = {
                    'alert_id': alert.id,
                    'event_type': event_type,
                    'device_sn': device_sn,
                    'alert_desc': alert.alert_desc,
                    'severity_level': 'critical',
                    'alert_timestamp': alert_timestamp,
                    'user_name': device_user_org.get('user_name', 'æœªçŸ¥ç”¨æˆ·'),
                    'org_name': device_user_org.get('org_name', 'æœªçŸ¥ç»„ç»‡'),
                    'latitude': alert.latitude,
                    'longitude': alert.longitude,
                    'health_id': health_id
                }
                
                # é€šè¿‡WebSocketæ¨é€åˆ°å¤§å±é¡µé¢
                socketio.emit('critical_alert', alert_data, namespace='/')
                print(f"ğŸš¨ Criticalå‘Šè­¦å·²æ¨é€åˆ°å¤§å±: {alert_data}")
                
            except Exception as ws_error:
                print(f"âš ï¸ WebSocketæ¨é€å¤±è´¥: {ws_error}")
        
        return jsonify({
            "status":"success","message":"äº‹ä»¶å¤„ç†æˆåŠŸ","alert_id":alert.id,
            "event_type":event_type,"device_sn":device_sn,"health_id":health_id
        })
        
    except Exception as e:
        db.session.rollback()
        print(f"äº‹ä»¶å¤„ç†å¤±è´¥:{e}")
        return jsonify({"status":"error","message":f"äº‹ä»¶å¤„ç†å¤±è´¥:{str(e)}"}),500

def acknowledge_alert():
    """å‘Šè­¦ç¡®è®¤æ¥å£"""
    try:
        data = request.json
        alert_id = data.get('alert_id')
        
        if not alert_id:
            return jsonify({"status": "error", "message": "ç¼ºå°‘alert_idå‚æ•°"}), 400
        
        # æ›´æ–°å‘Šè­¦çŠ¶æ€ä¸ºå·²ç¡®è®¤
        alert = AlertInfo.query.filter_by(id=alert_id).first()
        if not alert:
            return jsonify({"status": "error", "message": "å‘Šè­¦ä¸å­˜åœ¨"}), 404
        
        # æ›´æ–°ç¡®è®¤çŠ¶æ€å’Œæ—¶é—´
        alert.status = 'acknowledged'
        alert.acknowledged_at = get_now()
        db.session.commit()
        
        return jsonify({
            "status": "success",
            "message": "å‘Šè­¦ç¡®è®¤æˆåŠŸ",
            "alert_id": alert_id
        })
        
    except Exception as e:
        db.session.rollback()
        print(f"å‘Šè­¦ç¡®è®¤å¤±è´¥: {e}")
        return jsonify({
            "status": "error", 
            "message": f"å‘Šè­¦ç¡®è®¤å¤±è´¥: {str(e)}"
        }), 500




# ä¿®æ”¹ alert.py ä¸­çš„ upload_common_event
def upload_common_event1():
    """ä¼ä¸šçº§é€šç”¨äº‹ä»¶ä¸Šä¼ æ¥å£ - ä½¿ç”¨ç»Ÿä¸€å‘Šè­¦å¤„ç†å™¨"""
    try:
        data = request.json 
        logger.info(f"äº‹ä»¶æ¥æ”¶:{data}")
        
        # ğŸ”¥æ”¹é€ ï¼šä½¿ç”¨ç»Ÿä¸€å‘Šè­¦å¤„ç†å™¨
        from .unified_alert_processor import get_unified_processor
        processor = get_unified_processor()
        
        # æäº¤åˆ°ç»Ÿä¸€å¤„ç†å™¨
        alert_id = processor.submit_event_alert(data)
        
        return jsonify({
            "status": "success",
            "message": "äº‹ä»¶å·²æäº¤åˆ°ç»Ÿä¸€å¤„ç†å™¨",
            "alert_id": alert_id,
            "event_type": data.get('eventType', ''),
            "device_sn": data.get('deviceSn', ''),
            "processing": "é˜Ÿåˆ—å¤„ç†ä¸­"
        })
            
    except Exception as e:
        logger.error(f"äº‹ä»¶æ¥æ”¶å¤±è´¥: {e}")
        return jsonify({
            "status": "error", 
            "message": f"äº‹ä»¶æ¥æ”¶å¤±è´¥: {str(e)}"
        }), 500

def upload_common_event2():
    """ä¼ä¸šçº§é€šç”¨äº‹ä»¶ä¸Šä¼ æ¥å£ - ä½¿ç”¨é˜Ÿåˆ—å¤„ç†æ¶æ„"""
    try:
        data = request.json 
        print("ğŸš€ä¼ä¸šçº§äº‹ä»¶æ¥æ”¶:", data)
        
        # ä½¿ç”¨æ–°çš„ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨
        from .system_event_alert import process_common_event
        result = process_common_event(data)
        
        # ç«‹å³è¿”å›ç»™å®¢æˆ·ç«¯ï¼Œåå°é˜Ÿåˆ—å¼‚æ­¥å¤„ç†
        if result['status'] == 'success':
            return jsonify({
                "status": "success",
                "message": result['message'],
                "event_type": data.get('eventType', ''),
                "device_sn": data.get('deviceSn', ''),
                "processing": "é˜Ÿåˆ—å¤„ç†ä¸­"
            })
        else:
            return jsonify({
                "status": "error",
                "message": result['message']
            }), 500
            
    except Exception as e:
        print(f"âŒä¼ä¸šçº§äº‹ä»¶æ¥æ”¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            "status": "error", 
            "message": f"äº‹ä»¶æ¥æ”¶å¤±è´¥: {str(e)}"
        }), 500


def fetch_alert_rules():
    # Attempt to read alert rules from Redis
    alert_rules_data = redis.get('alert_rules')
    
    if alert_rules_data:
        # If data is found in Redis, parse it and return
        alert_rules = json.loads(alert_rules_data)
    else:
        # If not found in Redis, query the database
        alert_rules = AlertRules.query.all()
        # Store the fetched rules in Redis for future use
        alert_rules_data = {rule.id: rule.to_dict() for rule in alert_rules}  # Assuming AlertRules has a to_dict method
        redis.set('alert_rules', json.dumps(alert_rules_data))
    
    return jsonify({'success': True, 'alert_rules': alert_rules})


# =============================================================================
# upload_common_event ä¼˜åŒ–ç‰ˆæœ¬å®ç°
# =============================================================================

import queue
import threading
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Any
from cachetools import TTLCache
import time

class EventQueryOptimizer:
    """æŸ¥è¯¢ä¼˜åŒ–å™¨ - ç¼“å­˜å’Œæ‰¹é‡æŸ¥è¯¢"""
    def __init__(self):
        self.device_cache = TTLCache(maxsize=10000, ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
        self.rule_cache = TTLCache(maxsize=1000, ttl=600)   # 10åˆ†é’Ÿç¼“å­˜
        self.cache_lock = threading.RLock()
        
    def get_device_info_cached(self, device_sn):
        """ç¼“å­˜è®¾å¤‡ä¿¡æ¯æŸ¥è¯¢"""
        with self.cache_lock:
            cache_key = f"device:{device_sn}"
            if cache_key in self.device_cache:
                return self.device_cache[cache_key]
        
        # æŸ¥è¯¢æ•°æ®åº“
        try:
            result = db.session.query(
                DeviceInfo.device_sn,
                DeviceInfo.user_id,
                DeviceInfo.org_id,
                DeviceInfo.customer_id,
                UserInfo.user_name,
                UserInfo.org_name
            ).join(
                UserInfo, DeviceInfo.user_id == UserInfo.id
            ).filter(
                DeviceInfo.device_sn == device_sn
            ).first()
            
            if result:
                device_info = {
                    'success': True,
                    'device_sn': result.device_sn,
                    'user_id': result.user_id,
                    'org_id': result.org_id,
                    'customer_id': result.customer_id,
                    'user_name': result.user_name,
                    'org_name': result.org_name
                }
                
                # æ›´æ–°ç¼“å­˜
                with self.cache_lock:
                    self.device_cache[cache_key] = device_info
                
                return device_info
            else:
                return {'success': False, 'message': 'è®¾å¤‡æœªæ‰¾åˆ°'}
                
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è®¾å¤‡ä¿¡æ¯å¤±è´¥: {e}")
            return {'success': False, 'message': 'æŸ¥è¯¢å¤±è´¥'}
    
    def get_alert_rule_cached(self, rule_type):
        """ç¼“å­˜å‘Šè­¦è§„åˆ™æŸ¥è¯¢"""
        with self.cache_lock:
            cache_key = f"rule:{rule_type}"
            if cache_key in self.rule_cache:
                return self.rule_cache[cache_key]
        
        # æŸ¥è¯¢æ•°æ®åº“
        try:
            rule = AlertRules.query.filter_by(rule_type=rule_type, is_deleted=False).first()
            
            # æ›´æ–°ç¼“å­˜
            with self.cache_lock:
                self.rule_cache[cache_key] = rule
            
            return rule
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å‘Šè­¦è§„åˆ™å¤±è´¥: {e}")
            return None

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
query_optimizer = EventQueryOptimizer()

class OptimizedEventProcessor:
    """ä¼˜åŒ–çš„äº‹ä»¶å¤„ç†å™¨"""
    def __init__(self):
        self.event_queue = queue.Queue(maxsize=5000)
        self.batch_size = 50
        self.max_wait_time = 2.0
        self.workers = 4
        self.executor = ThreadPoolExecutor(max_workers=self.workers)
        self.running = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_processed': 0,
            'total_failed': 0,
            'avg_processing_time': 0.0,
            'queue_size': 0
        }
        
    def start(self):
        """å¯åŠ¨å¤„ç†å™¨"""
        self.running = True
        for i in range(self.workers):
            self.executor.submit(self._worker_loop)
    
    def stop(self):
        """åœæ­¢å¤„ç†å™¨"""
        self.running = False
        self.executor.shutdown(wait=True)
    
    def submit_event(self, event_data):
        """æäº¤äº‹ä»¶åˆ°é˜Ÿåˆ—"""
        try:
            self.event_queue.put_nowait(event_data)
            return True
        except queue.Full:
            return False
    
    def _worker_loop(self):
        """å·¥ä½œçº¿ç¨‹ä¸»å¾ªç¯"""
        batch = []
        last_process_time = time.time()
        
        while self.running:
            try:
                # æ”¶é›†æ‰¹æ¬¡
                while len(batch) < self.batch_size and (time.time() - last_process_time) < self.max_wait_time:
                    try:
                        event = self.event_queue.get(timeout=0.5)
                        batch.append(event)
                    except queue.Empty:
                        break
                
                # å¤„ç†æ‰¹æ¬¡
                if batch:
                    self._process_batch(batch)
                    batch.clear()
                    last_process_time = time.time()
                    
            except Exception as e:
                logger.error(f"å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
                batch.clear()
    
    def _process_batch(self, events):
        """æ‰¹é‡å¤„ç†äº‹ä»¶"""
        start_time = time.time()
        processed_count = 0
        failed_count = 0
        
        try:
            # æ‰¹é‡æ•°æ®åº“æ“ä½œ
            alerts_to_insert = []
            health_data_to_process = []
            websocket_pushes = []
            
            for event_data in events:
                try:
                    data = event_data['data']
                    
                    # æå–äº‹ä»¶ä¿¡æ¯
                    event_type = data.get('eventType', '').split('.')[-1]
                    device_sn = data.get('deviceSn', '')
                    
                    # è·å–ç¼“å­˜çš„è®¾å¤‡ä¿¡æ¯
                    device_info = query_optimizer.get_device_info_cached(device_sn)
                    if not device_info.get('success'):
                        logger.warning(f"è®¾å¤‡ä¿¡æ¯è·å–å¤±è´¥: {device_sn}")
                        failed_count += 1
                        continue
                    
                    # è·å–ç¼“å­˜çš„å‘Šè­¦è§„åˆ™
                    rule = query_optimizer.get_alert_rule_cached(event_type)
                    if not rule:
                        logger.warning(f"å‘Šè­¦è§„åˆ™æœªæ‰¾åˆ°: {event_type}")
                        failed_count += 1
                        continue
                    
                    # å‡†å¤‡å‘Šè­¦æ•°æ®
                    alert_data = {
                        'rule_id': rule.id,
                        'alert_type': event_type,
                        'device_sn': device_sn,
                        'alert_desc': f"{rule.alert_message}(äº‹ä»¶å€¼:{data.get('eventValue', '')})",
                        'severity_level': rule.severity_level,
                        'latitude': data.get('latitude', 22.54036796),
                        'longitude': data.get('longitude', 114.01508952),
                        'altitude': data.get('altitude', 0),
                        'customer_id': device_info['customer_id'],
                        'org_id': device_info['org_id'],
                        'user_id': device_info['user_id'],
                        'alert_timestamp': data.get('timestamp', get_now().strftime('%Y-%m-%d %H:%M:%S'))
                    }
                    
                    alerts_to_insert.append(alert_data)
                    
                    # æ”¶é›†å¥åº·æ•°æ®
                    if data.get('healthData'):
                        health_data_to_process.append({
                            'health_data': data['healthData'],
                            'user_id': device_info['user_id'],
                            'device_sn': device_sn
                        })
                    
                    # æ”¶é›†éœ€è¦WebSocketæ¨é€çš„Criticalå‘Šè­¦
                    if rule.severity_level == 'critical':
                        websocket_pushes.append({
                            'event_type': event_type,
                            'device_sn': device_sn,
                            'alert_desc': alert_data['alert_desc'],
                            'severity_level': 'critical',
                            'alert_timestamp': alert_data['alert_timestamp'],
                            'user_name': device_info['user_name'],
                            'org_name': device_info['org_name'],
                            'latitude': alert_data['latitude'],
                            'longitude': alert_data['longitude']
                        })
                    
                    processed_count += 1
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å•ä¸ªäº‹ä»¶å¤±è´¥: {e}")
                    failed_count += 1
            
            # æ‰¹é‡æ’å…¥å‘Šè­¦
            if alerts_to_insert:
                try:
                    db.session.bulk_insert_mappings(AlertInfo, alerts_to_insert)
                    db.session.commit()
                    logger.info(f"æ‰¹é‡æ’å…¥å‘Šè­¦æˆåŠŸ: {len(alerts_to_insert)}æ¡")
                except Exception as e:
                    db.session.rollback()
                    logger.error(f"æ‰¹é‡æ’å…¥å‘Šè­¦å¤±è´¥: {e}")
                    failed_count += len(alerts_to_insert)
                    processed_count -= len(alerts_to_insert)
            
            # æ‰¹é‡å¤„ç†å¥åº·æ•°æ®
            if health_data_to_process:
                self._process_health_data_batch(health_data_to_process)
            
            # æ‰¹é‡WebSocketæ¨é€
            if websocket_pushes:
                self._batch_websocket_push(websocket_pushes)
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
            db.session.rollback()
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        processing_time = time.time() - start_time
        self.stats['total_processed'] += processed_count
        self.stats['total_failed'] += failed_count
        self.stats['avg_processing_time'] = (
            self.stats['avg_processing_time'] * 0.9 + processing_time * 0.1
        )
        self.stats['queue_size'] = self.event_queue.qsize()
        
        logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ{processed_count}æ¡, å¤±è´¥{failed_count}æ¡, è€—æ—¶{processing_time:.3f}s")
    
    def _process_health_data_batch(self, health_data_list):
        """æ‰¹é‡å¤„ç†å¥åº·æ•°æ®"""
        try:
            from .user_health_data import process_single_health_data
            
            for item in health_data_list:
                health_data = item['health_data']
                if isinstance(health_data, dict):
                    actual_data = health_data.get('data', health_data)
                    process_single_health_data(actual_data)
                    
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¥åº·æ•°æ®å¤±è´¥: {e}")
    
    def _batch_websocket_push(self, push_data_list):
        """æ‰¹é‡WebSocketæ¨é€"""
        try:
            from .bigScreen import socketio
            
            for data in push_data_list:
                socketio.emit('critical_alert', data, namespace='/')
            
            logger.info(f"æ‰¹é‡WebSocketæ¨é€å®Œæˆ: {len(push_data_list)}æ¡")
            
        except Exception as e:
            logger.error(f"æ‰¹é‡WebSocketæ¨é€å¤±è´¥: {e}")

# å…¨å±€å¤„ç†å™¨å®ä¾‹
event_processor = OptimizedEventProcessor()

def upload_common_event_v3():
    """ä¼˜åŒ–ç‰ˆæœ¬3 - å¼‚æ­¥é˜Ÿåˆ—å¤„ç† + ç¼“å­˜ä¼˜åŒ–"""
    try:
        start_time = time.time()
        data = request.json
        
        # å¿«é€Ÿæ•°æ®éªŒè¯
        if not data or not isinstance(data, dict):
            return jsonify({"status": "error", "message": "æ— æ•ˆçš„æ•°æ®æ ¼å¼"}), 400
        
        if not data.get('deviceSn') or not data.get('eventType'):
            return jsonify({"status": "error", "message": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        # ç”Ÿæˆäº‹ä»¶ID
        event_id = f"evt_{int(time.time()*1000)}_{threading.get_ident()}"
        
        # æ„é€ äº‹ä»¶æ•°æ®
        event_data = {
            'event_id': event_id,
            'data': data,
            'timestamp': time.time(),
            'source_ip': request.remote_addr
        }
        
        # æäº¤åˆ°é˜Ÿåˆ—
        if not event_processor.submit_event(event_data):
            return jsonify({
                "status": "error", 
                "message": "ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åé‡è¯•"
            }), 503
        
        # ç«‹å³è¿”å›æˆåŠŸ
        processing_time = round((time.time() - start_time) * 1000, 2)
        
        return jsonify({
            "status": "success",
            "message": "äº‹ä»¶å·²æ¥æ”¶ï¼Œæ­£åœ¨å¼‚æ­¥å¤„ç†",
            "event_id": event_id,
            "device_sn": data.get('deviceSn'),
            "event_type": data.get('eventType', '').split('.')[-1],
            "processing_time_ms": processing_time,
            "queue_size": event_processor.stats['queue_size']
        })
        
    except Exception as e:
        logger.error(f"æ¥æ”¶äº‹ä»¶å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": f"äº‹ä»¶æ¥æ”¶å¤±è´¥: {str(e)}"
        }), 500

def get_event_processor_stats():
    """è·å–äº‹ä»¶å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = event_processor.stats.copy()
        stats['cache_stats'] = {
            'device_cache_size': len(query_optimizer.device_cache),
            'rule_cache_size': len(query_optimizer.rule_cache),
            'device_cache_hits': getattr(query_optimizer.device_cache, 'hits', 0),
            'rule_cache_hits': getattr(query_optimizer.rule_cache, 'hits', 0)
        }
        
        return jsonify({
            "status": "success",
            "stats": stats
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}"
        }), 500

def generate_alerts(data, health_data_id):
    try:
        print(f"ğŸ” generate_alerts started with data keys: {list(data.keys()) if data else 'None'}")
        
        # ä»æ•°æ®åº“è·å–å‘Šè­¦è§„åˆ™å¹¶è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        alert_rules = AlertRules.query.all()
        alert_rules_dict = {}
        
        # å°† SQLAlchemy å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
        for rule in alert_rules:
            rule_dict = {
                'id': rule.id,
                'rule_type': rule.rule_type,
                'physical_sign': rule.physical_sign,
                'threshold_min': rule.threshold_min,
                'threshold_max': rule.threshold_max,
                'trend_duration': rule.trend_duration,
                'severity_level': rule.severity_level,
                'alert_message': rule.alert_message
            }
            alert_rules_dict[rule.id] = rule_dict

        # åˆå§‹åŒ–å¼‚å¸¸è®¡æ•°å™¨
        abnormal_counts = {}

        # éå†æ¯ä¸ªå‘Šè­¦è§„åˆ™
        for rule_id, rule in alert_rules_dict.items():
            if not rule.get('is_enabled', True):
                continue

            physical_sign = rule.get('physical_sign')
            
            # æ£€æŸ¥physical_signæ˜¯å¦ä¸ºç©º
            if not physical_sign:
                print(f"Skipping rule {rule_id}: missing physical_sign")
                continue
            
            # ä¿®å¤thresholdå€¼çš„ç©ºå€¼å¤„ç†
            try:
                threshold_min_value = rule.get('threshold_min')
                if threshold_min_value is None or threshold_min_value == '':
                    threshold_min = 0
                else:
                    threshold_min = float(threshold_min_value)
            except (TypeError, ValueError):
                print(f"Invalid threshold_min for rule {rule_id}: {rule.get('threshold_min')}")
                threshold_min = 0
                
            try:
                threshold_max_value = rule.get('threshold_max')
                if threshold_max_value is None or threshold_max_value == '':
                    threshold_max = float('inf')
                else:
                    threshold_max = float(threshold_max_value)
            except (TypeError, ValueError):
                print(f"Invalid threshold_max for rule {rule_id}: {rule.get('threshold_max')}")
                threshold_max = float('inf')
            
            try:
                trend_duration_value = rule.get('trend_duration')
                if trend_duration_value is None or trend_duration_value == '':
                    trend_duration = 1
                else:
                    trend_duration = int(trend_duration_value)
            except (TypeError, ValueError):
                print(f"Invalid trend_duration for rule {rule_id}: {rule.get('trend_duration')}")
                trend_duration = 1

            # Special handling for blood pressure
            if physical_sign == 'bloodPressure':
                systolic = data.get('pressureHigh')
                diastolic = data.get('pressureLow')
                try:
                    # ä¿®å¤ç©ºå€¼å¤„ç†ï¼šæ£€æŸ¥Noneå€¼å’Œç©ºå­—ç¬¦ä¸²
                    if systolic is None or systolic == '' or str(systolic).strip() == '':
                        systolic = None
                    else:
                        systolic = float(systolic)
                        
                    if diastolic is None or diastolic == '' or str(diastolic).strip() == '':
                        diastolic = None
                    else:
                        diastolic = float(diastolic)
                except (TypeError, ValueError) as e:
                    print(f"Invalid blood pressure values for rule {rule_id}: systolic={systolic}, diastolic={diastolic}, error={e}")
                    abnormal_counts[physical_sign] = 0  # Reset count if conversion fails
                    continue
                
                # Check if either systolic or diastolic is outside the thresholds
                if (systolic is not None and (systolic < threshold_min or systolic > threshold_max)) or \
                   (diastolic is not None and (diastolic < threshold_min or diastolic > threshold_max)):
                    
                    # Update abnormal count for this physical sign
                    abnormal_counts[physical_sign] = abnormal_counts.get(physical_sign, 0) + 1
                else:
                    abnormal_counts[physical_sign] = 0  # Reset count if within range

            else:
                # General case for other physical signs
                value = data.get(physical_sign)
                
                try:
                    # ä¿®å¤ç©ºå­—ç¬¦ä¸²å’ŒNoneå€¼çš„å¤„ç†
                    if value is None or value == '' or str(value).strip() == '':
                        value = None
                    else:
                        value = float(value)
                except (TypeError, ValueError) as e:
                    print(f"Invalid value for rule {rule_id}, physical_sign={physical_sign}: value={value}, error={e}")
                    abnormal_counts[physical_sign] = 0  # Reset count if conversion fails
                    continue

                if value is not None and (value < threshold_min or value > threshold_max):
                    # Update abnormal count for this physical sign
                    abnormal_counts[physical_sign] = abnormal_counts.get(physical_sign, 0) + 1
                else:
                    abnormal_counts[physical_sign] = 0  # Reset count if within range

            # If abnormal count exceeds the trend_duration, generate alert
            if abnormal_counts.get(physical_sign, 0) >= trend_duration:
                print("generate_alerts:abnormal_counts:", abnormal_counts)
                
                # è·å–è®¾å¤‡çš„ç”¨æˆ·å’Œç»„ç»‡ä¿¡æ¯
                device_user_org = get_device_user_org_info(data.get('deviceSn', 'Unknown'))
                
                # Create an alert
                alert_info_instance = AlertInfo(
                    rule_id=rule_id,
                    alert_type=rule['rule_type'],
                    device_sn=data.get('deviceSn', 'Unknown'),
                    alert_timestamp=get_now(), #ä½¿ç”¨ç»Ÿä¸€æ—¶é—´é…ç½®
                    alert_desc=rule['alert_message'],
                    severity_level=rule['severity_level'],
                    alert_status='pending',
                    health_id=health_data_id,
                    org_id=device_user_org.get('org_id') if device_user_org.get('success') else None,
                    user_id=device_user_org.get('user_id') if device_user_org.get('success') else None
                )
                print("generate_alerts:alert_info_instance:", alert_info_instance)
                db.session.add(alert_info_instance)

        db.session.commit()
        print(f"âœ… generate_alerts completed successfully")
        return jsonify({'success': True})

    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ Error in generate_alerts: {e}")
        print(f"ğŸ“‹ Full error details: {error_details}")
        print(f"ğŸ“Š Data passed to function: {data}")
        print(f"ğŸ†” Health data ID: {health_data_id}")
        db.session.rollback()
        return jsonify({'success': False, 'error': str(e)})

