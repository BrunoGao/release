"""
å®æ—¶å¥åº·åŸºçº¿ç”Ÿæˆå¼•æ“
ä½œä¸ºljwx-bootå®šæ—¶ä»»åŠ¡çš„å¤‡ä»½æ–¹æ¡ˆï¼Œåœ¨bigscreenä¸­å®ç°å®æ—¶ç”Ÿæˆé€»è¾‘

ä¾èµ–ç»Ÿä¸€çš„get_all_health_data_optimizedæŸ¥è¯¢æ–¹æ³•
"""
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from .redis_helper import RedisHelper
from .user_health_data import get_all_health_data_optimized
from .models import db, HealthBaseline
from sqlalchemy import text, and_
import json
import time

logger = logging.getLogger(__name__)

class RealTimeHealthBaselineEngine:
    """å®æ—¶å¥åº·åŸºçº¿ç”Ÿæˆå¼•æ“"""
    
    def __init__(self):
        self.redis = RedisHelper()
        
        # å¥åº·ç‰¹å¾é…ç½® - ä¸ljwx-bootä¿æŒä¸€è‡´
        self.HEALTH_FEATURES = [
            "heart_rate", "blood_oxygen", "temperature", "pressure_high", 
            "pressure_low", "stress", "step", "calorie", "distance", "sleep"
        ]
        
        # ç‰¹å¾å€¼èŒƒå›´é…ç½® - ä¸ljwx-bootä¿æŒä¸€è‡´
        self.FEATURE_RANGES = {
            "heart_rate": (30.0, 200.0),
            "blood_oxygen": (70.0, 100.0),
            "temperature": (30.0, 45.0),
            "pressure_high": (60.0, 250.0),
            "pressure_low": (40.0, 150.0),
            "stress": (0.0, 100.0),
            "step": (0.0, 50000.0),
            "calorie": (0.0, 5000.0),
            "distance": (0.0, 100.0),
            "sleep": (0.0, 24.0)
        }
        
        # æœ€å°æ ‡å‡†å·®é…ç½® - é¿å…é™¤é›¶é”™è¯¯
        self.MIN_STD_VALUES = {
            "heart_rate": 1.0,
            "blood_oxygen": 0.5,
            "temperature": 0.1,
            "pressure_high": 2.0,
            "pressure_low": 1.5,
            "stress": 1.0,
            "step": 100.0,
            "calorie": 50.0,
            "distance": 0.5,
            "sleep": 0.2
        }
    
    def generate_user_baseline_realtime(self, user_id: int, target_date: str = None, days_back: int = 30) -> Dict:
        """
        ç”Ÿæˆå•ä¸ªç”¨æˆ·çš„å¥åº·åŸºçº¿ï¼Œä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢ï¼Œç©ºå€¼æ—¶å®æ—¶ç”Ÿæˆ
        
        Args:
            user_id: ç”¨æˆ·ID
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºæ˜¨å¤©
            days_back: å‘å‰è®¡ç®—å¤©æ•°ï¼Œé»˜è®¤30å¤©
            
        Returns:
            Dict: åŒ…å«åŸºçº¿æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()
        
        if target_date is None:
            target_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ”„ å¼€å§‹è·å–ç”¨æˆ· {user_id} çš„å¥åº·åŸºçº¿ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
        
        try:
            # æ­¥éª¤1: ä¼˜å…ˆä»æ•°æ®åº“æŸ¥è¯¢å·²ç”Ÿæˆçš„åŸºçº¿
            db_result = self._query_database_baseline(user_id, target_date)
            if db_result['success'] and db_result['data']:
                logger.info(f"âœ… ç”¨æˆ· {user_id} ä»æ•°æ®åº“è·å–åŸºçº¿æˆåŠŸï¼Œç‰¹å¾æ•°é‡: {len(db_result['data'].get('baselines', {}))}")
                return db_result
            
            # æ­¥éª¤2: æ•°æ®åº“æ— æ•°æ®ï¼Œæ‰§è¡Œå®æ—¶ç”Ÿæˆ
            logger.info(f"ğŸ“Š ç”¨æˆ· {user_id} æ•°æ®åº“æ— åŸºçº¿æ•°æ®ï¼Œå¼€å§‹å®æ—¶ç”Ÿæˆ...")
            return self._generate_baseline_realtime(user_id, target_date, days_back, start_time)
            
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ· {user_id} åŸºçº¿è·å–å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'user_id': user_id,
                'target_date': target_date,
                'execution_time': round(time.time() - start_time, 3)
            }
    
    def _query_database_baseline(self, user_id: int, target_date: str) -> Dict:
        """ä»æ•°æ®åº“æŸ¥è¯¢å·²ç”Ÿæˆçš„å¥åº·åŸºçº¿"""
        try:
            # æŸ¥è¯¢å½“å‰æœ‰æ•ˆçš„åŸºçº¿è®°å½• - ä½¿ç”¨æ–°è¡¨ç»“æ„
            baseline_records = db.session.query(HealthBaseline).filter(
                and_(
                    HealthBaseline.user_id == user_id,
                    HealthBaseline.baseline_date == target_date,
                    HealthBaseline.is_current == 1,
                    HealthBaseline.baseline_type == 'personal',
                    HealthBaseline.is_deleted == 0
                )
            ).all()
            
            if not baseline_records:
                return {'success': True, 'data': None, 'source': 'database_empty'}
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            baseline_results = {}
            for record in baseline_records:
                feature_name = record.feature_name
                baseline_results[feature_name] = {
                    'identifier': user_id,
                    'feature_name': feature_name,
                    'baseline_date': target_date,
                    'mean_value': float(record.mean_value) if record.mean_value else 0.0,
                    'std_value': float(record.std_value) if record.std_value else 0.1,
                    'min_value': float(record.min_value) if record.min_value else 0.0,
                    'max_value': float(record.max_value) if record.max_value else 0.0,
                    'sample_count': record.sample_count or 0,
                    'quality_score': round((record.confidence_level or 0.95), 3),
                    'is_current': bool(record.is_current),
                    'generated_at': record.baseline_time.isoformat() if record.baseline_time else datetime.now().isoformat(),
                    'source': 'database'
                }
            
            # ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
            summary = {
                'user_id': user_id,
                'target_date': target_date,
                'data_source': 'database',
                'features_processed': len(baseline_results),
                'baseline_quality_score': self._calculate_baseline_quality(baseline_results),
                'generated_at': datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ“‹ ä»æ•°æ®åº“è·å–ç”¨æˆ· {user_id} åŸºçº¿: {len(baseline_results)} ä¸ªç‰¹å¾")
            
            return {
                'success': True,
                'data': {
                    'baselines': baseline_results,
                    'summary': summary
                },
                'source': 'database'
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®åº“åŸºçº¿æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e), 'source': 'database_error'}
    
    def _generate_baseline_realtime(self, user_id: int, target_date: str, days_back: int, start_time: float) -> Dict:
        """å®æ—¶ç”Ÿæˆå¥åº·åŸºçº¿ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        # è®¡ç®—æŸ¥è¯¢æ—¶é—´èŒƒå›´
        end_date = datetime.strptime(target_date, '%Y-%m-%d')
        start_date = end_date - timedelta(days=days_back)
        start_date_str = start_date.strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ”„ å¼€å§‹å®æ—¶ç”Ÿæˆç”¨æˆ· {user_id} å¥åº·åŸºçº¿ï¼Œæ•°æ®èŒƒå›´: {start_date_str} - {target_date}")
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„health dataæŸ¥è¯¢æ¥å£
            health_result = get_all_health_data_optimized(
                userId=user_id,
                startDate=start_date_str,
                endDate=target_date,
                latest_only=False,
                pageSize=None  # è·å–æ‰€æœ‰æ•°æ®ï¼Œä¸åˆ†é¡µ
            )
            
            if not health_result.get('success'):
                logger.warning(f"âš ï¸ ç”¨æˆ· {user_id} è·å–å¥åº·æ•°æ®å¤±è´¥: {health_result.get('message')}")
                return {
                    'success': False,
                    'error': health_result.get('message'),
                    'user_id': user_id,
                    'target_date': target_date
                }
            
            health_data = health_result.get('data', {}).get('healthData', [])
            total_records = len(health_data)
            
            if total_records < 5:
                logger.warning(f"âš ï¸ ç”¨æˆ· {user_id} æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘5æ¡è®°å½•ï¼Œå®é™…: {total_records}")
                return {
                    'success': False,
                    'error': f'æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘5æ¡è®°å½•ï¼Œå®é™…: {total_records}',
                    'user_id': user_id,
                    'target_date': target_date,
                    'data_count': total_records
                }
            
            # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
            df = self._convert_to_dataframe(health_data)
            
            # ä¸ºæ¯ä¸ªå¥åº·ç‰¹å¾ç”ŸæˆåŸºçº¿
            baseline_results = {}
            for feature in self.HEALTH_FEATURES:
                baseline = self._calculate_feature_baseline(df, feature, user_id, target_date)
                if baseline:
                    baseline_results[feature] = baseline
                    # æ ‡è®°ä¸ºå®æ—¶ç”Ÿæˆ
                    baseline_results[feature]['source'] = 'realtime'
            
            # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
            summary = {
                'user_id': user_id,
                'target_date': target_date,
                'data_source': 'realtime',
                'data_period': f"{start_date_str} to {target_date}",
                'total_records': total_records,
                'features_processed': len(baseline_results),
                'baseline_quality_score': self._calculate_baseline_quality(baseline_results),
                'generation_time': round(time.time() - start_time, 3),
                'generated_at': datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœ
            cache_key = f"realtime_baseline:user:{user_id}:{target_date}"
            cache_data = {
                'baselines': baseline_results,
                'summary': summary
            }
            self.redis.set_data(cache_key, json.dumps(cache_data, default=str), 3600)  # ç¼“å­˜1å°æ—¶
            
            logger.info(f"âœ… ç”¨æˆ· {user_id} å®æ—¶åŸºçº¿ç”Ÿæˆå®Œæˆ: {len(baseline_results)} ä¸ªç‰¹å¾ï¼Œè´¨é‡è¯„åˆ†: {summary['baseline_quality_score']:.2f}")
            
            return {
                'success': True,
                'data': {
                    'baselines': baseline_results,
                    'summary': summary
                },
                'source': 'realtime'
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ· {user_id} å®æ—¶åŸºçº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'user_id': user_id,
                'target_date': target_date,
                'execution_time': round(time.time() - start_time, 3)
            }
    
    def _convert_to_dataframe(self, health_data: List[Dict]) -> pd.DataFrame:
        """å°†å¥åº·æ•°æ®è½¬æ¢ä¸ºpandas DataFrame"""
        if not health_data:
            return pd.DataFrame()
        
        # æ ‡å‡†åŒ–å­—æ®µæ˜ å°„
        records = []
        for record in health_data:
            clean_record = {}
            
            # åŸºç¡€å­—æ®µ
            clean_record['user_id'] = record.get('user_id') or record.get('userId')
            clean_record['device_sn'] = record.get('device_sn') or record.get('deviceSn')
            clean_record['timestamp'] = record.get('timestamp') or record.get('create_time')
            clean_record['dept_name'] = record.get('dept_name') or record.get('deptName')
            clean_record['dept_id'] = record.get('dept_id') or record.get('deptId')
            
            # å¥åº·ç‰¹å¾å­—æ®µ
            for feature in self.HEALTH_FEATURES:
                value = record.get(feature)
                
                # å¤„ç†ç‰¹æ®Šæ˜ å°„
                if feature == 'heart_rate' and value is None:
                    value = record.get('heartRate') or record.get('heart_rate')
                elif feature == 'blood_oxygen' and value is None:
                    value = record.get('bloodOxygen') or record.get('blood_oxygen')
                elif feature == 'pressure_high' and value is None:
                    value = record.get('pressureHigh') or record.get('pressure_high')
                elif feature == 'pressure_low' and value is None:
                    value = record.get('pressureLow') or record.get('pressure_low')
                
                # æ•°æ®éªŒè¯å’Œæ¸…ç†
                if value is not None:
                    try:
                        value = float(value)
                        min_val, max_val = self.FEATURE_RANGES.get(feature, (0, 10000))
                        if min_val <= value <= max_val:
                            clean_record[feature] = value
                        else:
                            clean_record[feature] = None
                    except (ValueError, TypeError):
                        clean_record[feature] = None
                else:
                    clean_record[feature] = None
            
            records.append(clean_record)
        
        df = pd.DataFrame(records)
        
        # è½¬æ¢æ—¶é—´æˆ³
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        
        return df
    
    def _calculate_feature_baseline(self, df: pd.DataFrame, feature: str, identifier: int, target_date: str) -> Dict:
        """è®¡ç®—å•ä¸ªç‰¹å¾çš„åŸºçº¿ç»Ÿè®¡"""
        if feature not in df.columns:
            return None
        
        feature_data = df[feature].dropna()
        
        if len(feature_data) < 3:
            return None
        
        try:
            # åŸºç¡€ç»Ÿè®¡
            mean_val = float(feature_data.mean())
            std_val = max(float(feature_data.std()), self.MIN_STD_VALUES.get(feature, 0.1))
            min_val = float(feature_data.min())
            max_val = float(feature_data.max())
            count = int(len(feature_data))
            
            # æ•°æ®è´¨é‡æŒ‡æ ‡
            outlier_threshold = 3 * std_val
            outliers = len(feature_data[(feature_data < mean_val - outlier_threshold) | 
                                      (feature_data > mean_val + outlier_threshold)])
            quality_score = max(0, 1 - (outliers / count)) if count > 0 else 0
            
            baseline = {
                'identifier': identifier,
                'feature_name': feature,
                'baseline_date': target_date,
                'mean_value': round(mean_val, 2),
                'std_value': round(std_val, 2),
                'min_value': round(min_val, 2),
                'max_value': round(max_val, 2),
                'sample_count': count,
                'quality_score': round(quality_score, 3),
                'outlier_count': outliers,
                'is_current': True,
                'generated_at': datetime.now().isoformat()
            }
            
            return baseline
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®¡ç®—ç‰¹å¾ {feature} åŸºçº¿å¤±è´¥: {str(e)}")
            return None
    
    def _calculate_baseline_quality(self, baselines: Dict) -> float:
        """è®¡ç®—åŸºçº¿è´¨é‡è¯„åˆ†"""
        if not baselines:
            return 0.0
        
        total_score = 0
        for baseline in baselines.values():
            # åŸºäºæ ·æœ¬æ•°é‡å’Œæ•°æ®åˆ†å¸ƒçš„è´¨é‡è¯„åˆ†
            sample_count = baseline.get('sample_count', 0)
            std_value = baseline.get('std_value', 0)
            mean_value = baseline.get('mean_value', 0)
            
            # æ ·æœ¬æ•°é‡è¯„åˆ† (0-0.4)
            sample_score = min(0.4, sample_count / 100)
            
            # æ•°æ®åˆ†å¸ƒè¯„åˆ† (0-0.4)
            cv = std_value / mean_value if mean_value > 0 else 1
            distribution_score = max(0, 0.4 - cv * 0.1)
            
            # å®Œæ•´æ€§è¯„åˆ† (0-0.2)
            completeness_score = 0.2 if all(k in baseline for k in ['mean_value', 'std_value', 'sample_count']) else 0
            
            total_score += sample_score + distribution_score + completeness_score
        
        return round(total_score / len(baselines), 3) if baselines else 0.0

    def generate_org_baseline_realtime(self, org_id: int, target_date: str = None, days_back: int = 30) -> Dict:
        """
        ç”Ÿæˆç»„ç»‡çº§åŸºçº¿æ•°æ® - ç›´æ¥ä»t_health_baselineè¡¨æŸ¥è¯¢ç»„ç»‡çº§åŸºçº¿
        
        Args:
            org_id: ç»„ç»‡ID
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºæ˜¨å¤©
            days_back: å›æº¯å¤©æ•°ï¼Œé»˜è®¤30å¤©
            
        Returns:
            Dict: ç»„ç»‡åŸºçº¿æ•°æ®
        """
        start_time = time.time()
        
        if target_date is None:
            target_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆç»„ç»‡ {org_id} çš„å¥åº·åŸºçº¿ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
        
        try:
            # 1. é¦–å…ˆå°è¯•ä»t_health_baselineè¡¨ä¸­æŸ¥è¯¢ç»„ç»‡çº§åŸºçº¿æ•°æ®
            org_baseline_records = db.session.query(HealthBaseline).filter(
                and_(
                    HealthBaseline.org_id == str(org_id),
                    HealthBaseline.baseline_date == target_date,
                    HealthBaseline.baseline_type == 'org',
                    HealthBaseline.is_current == 1,
                    HealthBaseline.is_deleted == 0
                )
            ).all()
            
            if org_baseline_records:
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                org_baselines = {}
                for record in org_baseline_records:
                    feature_name = record.feature_name
                    org_baselines[feature_name] = {
                        'identifier': org_id,
                        'feature_name': feature_name,
                        'baseline_date': target_date,
                        'mean_value': float(record.mean_value) if record.mean_value else 0.0,
                        'std_value': float(record.std_value) if record.std_value else 0.1,
                        'min_value': float(record.min_value) if record.min_value else 0.0,
                        'max_value': float(record.max_value) if record.max_value else 0.0,
                        'sample_count': record.sample_count or 0,
                        'quality_score': round((record.confidence_level or 0.95), 3),
                        'is_current': bool(record.is_current),
                        'baseline_type': 'org',
                        'generated_at': record.baseline_time.isoformat() if record.baseline_time else datetime.now().isoformat(),
                        'source': 'database_org'
                    }
                
                # ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
                summary = {
                    'org_id': org_id,
                    'target_date': target_date,
                    'data_source': 'database_org',
                    'features_processed': len(org_baselines),
                    'baseline_quality_score': self._calculate_baseline_quality(org_baselines),
                    'generated_at': datetime.now().isoformat(),
                    'execution_time': round(time.time() - start_time, 3)
                }
                
                logger.info(f"âœ… ä»æ•°æ®åº“è·å–ç»„ç»‡ {org_id} åŸºçº¿: {len(org_baselines)} ä¸ªç‰¹å¾")
                
                return {
                    'success': True,
                    'data': {
                        'baselines': org_baselines,
                        'summary': summary,
                        'user_count': 0  # ç»„ç»‡çº§åŸºçº¿ä¸ç›´æ¥ç»Ÿè®¡ç”¨æˆ·æ•°
                    },
                    'source': 'database_org'
                }
            
            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»„ç»‡çº§åŸºçº¿ï¼Œå°è¯•æ±‡æ€»ç”¨æˆ·åŸºçº¿
            from .org import getUserIdsByOrgId
            user_ids = getUserIdsByOrgId(org_id)
            
            if not user_ids:
                return {
                    'success': False,
                    'error': f'ç»„ç»‡ {org_id} ä¸‹æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·',
                    'org_id': org_id,
                    'target_date': target_date
                }
            
            # 3. è·å–æ‰€æœ‰ç”¨æˆ·çš„åŸºçº¿æ•°æ®è¿›è¡Œæ±‡æ€»
            user_baselines = {}
            valid_users = 0
            
            for user_id in user_ids:
                try:
                    user_baseline_result = self.generate_user_baseline_realtime(user_id, target_date, days_back)
                    if user_baseline_result.get('success') and user_baseline_result.get('data'):
                        user_baselines[user_id] = user_baseline_result['data']['baselines']
                        valid_users += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ ç”¨æˆ· {user_id} åŸºçº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
                    continue
            
            if not user_baselines:
                return {
                    'success': False,
                    'error': f'ç»„ç»‡ {org_id} ä¸‹æ²¡æœ‰ç”¨æˆ·ç”Ÿæˆæœ‰æ•ˆçš„åŸºçº¿æ•°æ®',
                    'org_id': org_id,
                    'target_date': target_date,
                    'total_users': len(user_ids),
                    'valid_users': 0
                }
            
            # 4. æ±‡æ€»ç»„ç»‡çº§åŸºçº¿
            org_baselines = self._aggregate_baselines(user_baselines, 'org')
            
            # 5. è®¡ç®—è´¨é‡è¯„åˆ†
            quality_score = self._calculate_baseline_quality(org_baselines)
            
            # 6. ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
            summary = {
                'org_id': org_id,
                'target_date': target_date,
                'days_back': days_back,
                'data_source': 'realtime_aggregation',
                'total_users': len(user_ids),
                'valid_users': valid_users,
                'aggregated_features': len(org_baselines),
                'quality_score': quality_score,
                'generated_at': datetime.now().isoformat(),
                'execution_time': round(time.time() - start_time, 3)
            }
            
            logger.info(f"âœ… ç»„ç»‡ {org_id} åŸºçº¿ç”Ÿæˆå®Œæˆ: {valid_users}/{len(user_ids)} ç”¨æˆ·ï¼Œ{len(org_baselines)} ä¸ªç‰¹å¾")
            
            return {
                'success': True,
                'data': {
                    'baselines': org_baselines,
                    'summary': summary,
                    'user_count': valid_users
                },
                'source': 'realtime_aggregation'
            }
            
        except Exception as e:
            logger.error(f"âŒ ç»„ç»‡ {org_id} åŸºçº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'org_id': org_id,
                'target_date': target_date,
                'execution_time': round(time.time() - start_time, 3)
            }

    def generate_customer_baseline_realtime(self, customer_id: int, target_date: str = None, days_back: int = 30) -> Dict:
        """
        ç”Ÿæˆç§Ÿæˆ·çº§åŸºçº¿æ•°æ® - æ±‡æ€»ç§Ÿæˆ·ä¸‹æ‰€æœ‰ç»„ç»‡çš„åŸºçº¿
        
        Args:
            customer_id: ç§Ÿæˆ·ID
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºæ˜¨å¤©
            days_back: å›æº¯å¤©æ•°ï¼Œé»˜è®¤30å¤©
            
        Returns:
            Dict: ç§Ÿæˆ·åŸºçº¿æ•°æ®
        """
        start_time = time.time()
        
        if target_date is None:
            target_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆç§Ÿæˆ· {customer_id} çš„å¥åº·åŸºçº¿ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")
        
        try:
            # 1. è·å–ç§Ÿæˆ·ä¸‹çš„æ‰€æœ‰ç»„ç»‡ID
            from .org import findAllDescendants
            org_ids = findAllDescendants(customer_id)
            
            if not org_ids:
                return {
                    'success': False,
                    'error': f'ç§Ÿæˆ· {customer_id} ä¸‹æ²¡æœ‰æ‰¾åˆ°ç»„ç»‡',
                    'customer_id': customer_id,
                    'target_date': target_date
                }
            
            # 2. è·å–æ‰€æœ‰ç»„ç»‡çš„åŸºçº¿æ•°æ®
            org_baselines = {}
            valid_orgs = 0
            total_users = 0
            
            for org_id in org_ids:
                try:
                    org_baseline_result = self.generate_org_baseline_realtime(org_id, target_date, days_back)
                    if org_baseline_result.get('success') and org_baseline_result.get('data'):
                        org_baselines[org_id] = org_baseline_result['data']['baselines']
                        valid_orgs += 1
                        total_users += org_baseline_result['data'].get('user_count', 0)
                except Exception as e:
                    logger.warning(f"âš ï¸ ç»„ç»‡ {org_id} åŸºçº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
                    continue
            
            if not org_baselines:
                return {
                    'success': False,
                    'error': f'ç§Ÿæˆ· {customer_id} ä¸‹æ²¡æœ‰ç»„ç»‡ç”Ÿæˆæœ‰æ•ˆçš„åŸºçº¿æ•°æ®',
                    'customer_id': customer_id,
                    'target_date': target_date,
                    'total_orgs': len(org_ids),
                    'valid_orgs': 0
                }
            
            # 3. æ±‡æ€»ç§Ÿæˆ·çº§åŸºçº¿
            customer_baselines = self._aggregate_baselines(org_baselines, 'customer')
            
            # 4. è®¡ç®—è´¨é‡è¯„åˆ†
            quality_score = self._calculate_baseline_quality(customer_baselines)
            
            # 5. ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
            summary = {
                'customer_id': customer_id,
                'target_date': target_date,
                'days_back': days_back,
                'data_source': 'realtime_aggregation',
                'total_orgs': len(org_ids),
                'valid_orgs': valid_orgs,
                'total_users': total_users,
                'aggregated_features': len(customer_baselines),
                'quality_score': quality_score,
                'generated_at': datetime.now().isoformat(),
                'execution_time': round(time.time() - start_time, 3)
            }
            
            logger.info(f"âœ… ç§Ÿæˆ· {customer_id} åŸºçº¿ç”Ÿæˆå®Œæˆ: {valid_orgs}/{len(org_ids)} ç»„ç»‡ï¼Œ{total_users} ç”¨æˆ·ï¼Œ{len(customer_baselines)} ä¸ªç‰¹å¾")
            
            return {
                'success': True,
                'data': {
                    'baselines': customer_baselines,
                    'summary': summary,
                    'org_count': valid_orgs,
                    'user_count': total_users
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ç§Ÿæˆ· {customer_id} åŸºçº¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'customer_id': customer_id,
                'target_date': target_date,
                'execution_time': round(time.time() - start_time, 3)
            }

    def _aggregate_baselines(self, baselines_dict: Dict, level: str) -> Dict:
        """
        æ±‡æ€»åŸºçº¿æ•°æ®
        
        Args:
            baselines_dict: {entity_id: {feature: baseline_data}} æ ¼å¼çš„åŸºçº¿æ•°æ®
            level: æ±‡æ€»çº§åˆ« ('org' æˆ– 'customer')
            
        Returns:
            Dict: æ±‡æ€»åçš„åŸºçº¿æ•°æ®
        """
        if not baselines_dict:
            return {}
        
        # æ”¶é›†æ‰€æœ‰ç‰¹å¾çš„æ•°æ®
        feature_data = {}
        
        for entity_id, entity_baselines in baselines_dict.items():
            for feature, baseline_data in entity_baselines.items():
                if feature not in feature_data:
                    feature_data[feature] = {
                        'mean_values': [],
                        'std_values': [],
                        'min_values': [],
                        'max_values': [],
                        'sample_counts': []
                    }
                
                feature_data[feature]['mean_values'].append(baseline_data.get('mean_value', 0))
                feature_data[feature]['std_values'].append(baseline_data.get('std_value', 0))
                feature_data[feature]['min_values'].append(baseline_data.get('min_value', 0))
                feature_data[feature]['max_values'].append(baseline_data.get('max_value', 0))
                feature_data[feature]['sample_counts'].append(baseline_data.get('sample_count', 0))
        
        # è®¡ç®—æ±‡æ€»åŸºçº¿
        aggregated_baselines = {}
        
        for feature, data in feature_data.items():
            try:
                # ä½¿ç”¨åŠ æƒå¹³å‡ï¼ˆåŸºäºæ ·æœ¬æ•°é‡ï¼‰
                total_samples = sum(data['sample_counts'])
                if total_samples == 0:
                    continue
                
                weights = [count / total_samples for count in data['sample_counts']]
                
                aggregated_mean = sum(mean * weight for mean, weight in zip(data['mean_values'], weights))
                aggregated_std = np.sqrt(sum((std ** 2) * weight for std, weight in zip(data['std_values'], weights)))
                aggregated_min = min(data['min_values'])
                aggregated_max = max(data['max_values'])
                
                aggregated_baselines[feature] = {
                    'feature_name': feature,
                    'mean_value': round(float(aggregated_mean), 4),
                    'std_value': max(round(float(aggregated_std), 4), self.MIN_STD_VALUES.get(feature, 0.1)),
                    'min_value': round(float(aggregated_min), 4),
                    'max_value': round(float(aggregated_max), 4),
                    'sample_count': total_samples,
                    'entity_count': len(data['sample_counts']),
                    'aggregation_level': level,
                    'baseline_date': (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                    'source': f'realtime_{level}_aggregation'
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸ ç‰¹å¾ {feature} æ±‡æ€»å¤±è´¥: {str(e)}")
                continue
        
        return aggregated_baselines


# å…¨å±€å®ä¾‹
realtime_baseline_engine = RealTimeHealthBaselineEngine()


def get_user_baseline_realtime(user_id: int, target_date: str = None) -> Dict:
    """è·å–ç”¨æˆ·å®æ—¶åŸºçº¿ - å¯¹å¤–æ¥å£"""
    return realtime_baseline_engine.generate_user_baseline_realtime(user_id, target_date)


def get_baseline_status(identifier: int, identifier_type: str = 'user', target_date: str = None) -> Dict:
    """è·å–åŸºçº¿çŠ¶æ€ - å¯¹å¤–æ¥å£"""
    return realtime_baseline_engine.get_baseline_status(identifier, identifier_type, target_date)


# æ–°å¢ç»„ç»‡å’Œç§Ÿæˆ·çº§åŸºçº¿ç”Ÿæˆæ–¹æ³•
def get_org_baseline_realtime(org_id: int, target_date: str = None) -> Dict:
    """è·å–ç»„ç»‡å®æ—¶åŸºçº¿ - å¯¹å¤–æ¥å£"""
    return realtime_baseline_engine.generate_org_baseline_realtime(org_id, target_date)


def get_customer_baseline_realtime(customer_id: int, target_date: str = None) -> Dict:
    """è·å–ç§Ÿæˆ·å®æ—¶åŸºçº¿ - å¯¹å¤–æ¥å£"""
    return realtime_baseline_engine.generate_customer_baseline_realtime(customer_id, target_date)