#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¶ˆæ¯æœåŠ¡V2ä¿®å¤åç‰ˆæœ¬ - é«˜æ€§èƒ½å®ç°

ä¸»è¦ä¿®å¤:
1. åˆ†å¸ƒå¼äº‹åŠ¡æ”¯æŒ
2. ç¼“å­˜ä¸€è‡´æ€§æœºåˆ¶  
3. é˜²æ­¢N+1æŸ¥è¯¢
4. è¿æ¥æ± ä¼˜åŒ–
5. æ‰¹é‡æ“ä½œä¼˜åŒ–
6. ç†”æ–­å™¨å’Œé™çº§
7. ç›‘æ§æŒ‡æ ‡é›†æˆ

æ€§èƒ½ç›®æ ‡:
- æŸ¥è¯¢å“åº”æ—¶é—´: < 50ms
- ç¼“å­˜å‘½ä¸­ç‡: > 85%
- å¹¶å‘å¤„ç†: > 1000 TPS
- ç³»ç»Ÿå¯ç”¨æ€§: 99.9%

@Author: brunoGao  
@CreateTime: 2025-09-11
@Version: 2.0-Fixed
"""

import asyncio
import json
import time
import logging
import hashlib
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from contextlib import contextmanager
from dataclasses import dataclass, field
from functools import wraps

from sqlalchemy.orm import Session, sessionmaker
from sqlalchemy.engine import Engine
from sqlalchemy import and_, or_, func, text, desc
from sqlalchemy.exc import SQLAlchemyError, IntegrityError
import redis
from redis.exceptions import RedisError
import pymongo
from pymongo.errors import PyMongoError

# å¯¼å…¥ä¿®å¤åçš„æ¨¡å‹
from models.message_v2_fixed_model import (
    TDeviceMessageV2Fixed,
    TDeviceMessageDetailV2Fixed, 
    TMessageLifecycleV2Fixed,
    MessageV2QueryBuilder,
    MessageV2TransactionManager,
    MessageCacheKey,
    MessageCacheInvalidator,
    MessageTypeEnum,
    MessageStatusEnum,
    DeliveryStatusEnum,
    UrgencyEnum,
    EventTypeEnum,
    PlatformSourceEnum
)

logger = logging.getLogger(__name__)


# ==================== é…ç½®ç±» ====================

@dataclass
class MessageServiceConfig:
    """æ¶ˆæ¯æœåŠ¡é…ç½®"""
    
    # æ•°æ®åº“é…ç½®
    db_pool_size: int = 20
    db_pool_max_overflow: int = 30
    db_pool_timeout: int = 30
    db_pool_recycle: int = 3600
    
    # Redisé…ç½®  
    redis_pool_size: int = 10
    redis_socket_timeout: int = 5
    redis_socket_connect_timeout: int = 5
    
    # ç¼“å­˜é…ç½®
    default_cache_ttl: int = 300  # 5åˆ†é’Ÿ
    user_cache_ttl: int = 600     # 10åˆ†é’Ÿ
    stats_cache_ttl: int = 1800   # 30åˆ†é’Ÿ
    
    # æ€§èƒ½é…ç½®
    batch_size: int = 100
    max_concurrent_queries: int = 50
    query_timeout: int = 30
    
    # ç†”æ–­å™¨é…ç½®
    circuit_breaker_failure_threshold: int = 5
    circuit_breaker_recovery_timeout: int = 60
    circuit_breaker_expected_exception: tuple = (SQLAlchemyError, RedisError)


# ==================== æ€§èƒ½ç›‘æ§è£…é¥°å™¨ ====================

def monitor_performance(operation_name: str):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            operation_success = False
            
            try:
                result = func(*args, **kwargs)
                operation_success = True
                return result
            except Exception as e:
                logger.error(f"âŒ {operation_name} æ“ä½œå¤±è´¥: {str(e)}")
                # è¿™é‡Œå¯ä»¥é›†æˆç›‘æ§ç³»ç»Ÿï¼ˆå¦‚Prometheusï¼‰
                raise
            finally:
                duration = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                status = "success" if operation_success else "failed"
                logger.info(f"ğŸ“Š {operation_name} è€—æ—¶: {duration:.2f}ms, çŠ¶æ€: {status}")
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡ï¼ˆå¯ä»¥é›†æˆåˆ°ç›‘æ§ç³»ç»Ÿï¼‰
                # metrics.record_operation_duration(operation_name, duration, status)
                
        return wrapper
    return decorator


def circuit_breaker(failure_threshold: int = 5, recovery_timeout: int = 60):
    """ç†”æ–­å™¨è£…é¥°å™¨"""
    def decorator(func):
        func._failure_count = 0
        func._last_failure_time = 0
        func._circuit_open = False
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            now = time.time()
            
            # æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
            if func._circuit_open:
                if now - func._last_failure_time > recovery_timeout:
                    func._circuit_open = False
                    func._failure_count = 0
                    logger.info(f"ğŸ”„ ç†”æ–­å™¨æ¢å¤: {func.__name__}")
                else:
                    raise Exception(f"ğŸš« ç†”æ–­å™¨å¼€å¯ï¼ŒæœåŠ¡æš‚ä¸å¯ç”¨: {func.__name__}")
            
            try:
                result = func(*args, **kwargs)
                # æˆåŠŸæ—¶é‡ç½®å¤±è´¥è®¡æ•°
                func._failure_count = 0
                return result
            except Exception as e:
                func._failure_count += 1
                func._last_failure_time = now
                
                # è¾¾åˆ°å¤±è´¥é˜ˆå€¼æ—¶å¼€å¯ç†”æ–­å™¨
                if func._failure_count >= failure_threshold:
                    func._circuit_open = True
                    logger.error(f"âš¡ ç†”æ–­å™¨å¼€å¯: {func.__name__}, å¤±è´¥æ¬¡æ•°: {func._failure_count}")
                
                raise
        
        return wrapper
    return decorator


# ==================== ç¼“å­˜ç®¡ç†å™¨ ====================

class AdvancedCacheManager:
    """é«˜çº§ç¼“å­˜ç®¡ç†å™¨ - è§£å†³ç¼“å­˜ä¸€è‡´æ€§é—®é¢˜"""
    
    def __init__(self, redis_client: redis.Redis, config: MessageServiceConfig):
        self.redis = redis_client
        self.config = config
        self.cache_invalidator = MessageCacheInvalidator(redis_client)
    
    @monitor_performance("cache_get")
    def get(self, key: str, default=None):
        """è·å–ç¼“å­˜"""
        try:
            cached_data = self.redis.get(key)
            if cached_data:
                return json.loads(cached_data)
            return default
        except (RedisError, json.JSONDecodeError) as e:
            logger.warning(f"âš ï¸ ç¼“å­˜è·å–å¤±è´¥: {key}, é”™è¯¯: {e}")
            return default
    
    @monitor_performance("cache_set")
    def set(self, key: str, value: Any, ttl: int = None):
        """è®¾ç½®ç¼“å­˜"""
        try:
            ttl = ttl or self.config.default_cache_ttl
            serialized_value = json.dumps(value, default=str, ensure_ascii=False)
            self.redis.setex(key, ttl, serialized_value)
            return True
        except (RedisError, TypeError) as e:
            logger.warning(f"âš ï¸ ç¼“å­˜è®¾ç½®å¤±è´¥: {key}, é”™è¯¯: {e}")
            return False
    
    @monitor_performance("cache_delete")
    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        try:
            return self.redis.delete(key)
        except RedisError as e:
            logger.warning(f"âš ï¸ ç¼“å­˜åˆ é™¤å¤±è´¥: {key}, é”™è¯¯: {e}")
            return False
    
    def delete_pattern(self, pattern: str):
        """æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜"""
        try:
            keys = self.redis.keys(pattern)
            if keys:
                return self.redis.delete(*keys)
            return 0
        except RedisError as e:
            logger.warning(f"âš ï¸ æ¨¡å¼åˆ é™¤å¤±è´¥: {pattern}, é”™è¯¯: {e}")
            return 0
    
    @monitor_performance("cache_mget")
    def mget(self, keys: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡è·å–ç¼“å­˜"""
        try:
            values = self.redis.mget(keys)
            result = {}
            for key, value in zip(keys, values):
                if value:
                    try:
                        result[key] = json.loads(value)
                    except json.JSONDecodeError:
                        continue
            return result
        except RedisError as e:
            logger.warning(f"âš ï¸ æ‰¹é‡ç¼“å­˜è·å–å¤±è´¥: é”™è¯¯: {e}")
            return {}
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            info = self.redis.info('stats')
            return {
                'keyspace_hits': info.get('keyspace_hits', 0),
                'keyspace_misses': info.get('keyspace_misses', 0), 
                'hit_rate': info.get('keyspace_hits', 0) / max(info.get('keyspace_hits', 0) + info.get('keyspace_misses', 1), 1) * 100
            }
        except RedisError as e:
            logger.warning(f"âš ï¸ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {'hit_rate': 0}


# ==================== æ•°æ®åº“è¿æ¥ç®¡ç†å™¨ ====================

class DatabaseConnectionManager:
    """æ•°æ®åº“è¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self, engine: Engine, config: MessageServiceConfig):
        self.engine = engine
        self.config = config
        self.session_factory = sessionmaker(bind=engine)
    
    @contextmanager
    def get_session(self):
        """è·å–æ•°æ®åº“ä¼šè¯ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
        session = self.session_factory()
        try:
            yield session
        except Exception:
            session.rollback()
            raise
        finally:
            session.close()
    
    @contextmanager
    def get_transaction_session(self):
        """è·å–äº‹åŠ¡ä¼šè¯"""
        session = self.session_factory()
        try:
            session.begin()
            yield session
            session.commit()
        except Exception:
            session.rollback()
            raise
        finally:
            session.close()


# ==================== ä¸»è¦æœåŠ¡ç±» ====================

class MessageServiceV2Fixed:
    """æ¶ˆæ¯æœåŠ¡V2ä¿®å¤åç‰ˆæœ¬"""
    
    def __init__(
        self, 
        engine: Engine, 
        redis_client: redis.Redis,
        config: Optional[MessageServiceConfig] = None
    ):
        self.engine = engine
        self.redis = redis_client
        self.config = config or MessageServiceConfig()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.db_manager = DatabaseConnectionManager(engine, self.config)
        self.cache_manager = AdvancedCacheManager(redis_client, self.config)
        
        # çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(max_workers=self.config.max_concurrent_queries)
        
        logger.info("âœ… MessageServiceV2Fixed åˆå§‹åŒ–å®Œæˆ")
    
    # ==================== æ ¸å¿ƒæ¶ˆæ¯æ“ä½œ ====================
    
    @monitor_performance("create_message")
    @circuit_breaker(failure_threshold=5, recovery_timeout=60)
    def create_message(
        self, 
        message_data: Dict[str, Any],
        targets: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åˆ›å»ºæ¶ˆæ¯ - åˆ†å¸ƒå¼äº‹åŠ¡æ”¯æŒ"""
        
        try:
            with self.db_manager.get_session() as session:
                transaction_manager = MessageV2TransactionManager(session, self.redis)
                
                message_id = transaction_manager.create_message_with_transaction(
                    message_data, targets
                )
                
                # å¼‚æ­¥è§¦å‘æ¶ˆæ¯åˆ†å‘
                self.executor.submit(self._async_distribute_message, message_id)
                
                return {
                    'success': True,
                    'message_id': message_id,
                    'target_count': len(targets),
                    'message': 'æ¶ˆæ¯åˆ›å»ºæˆåŠŸ'
                }
                
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ¶ˆæ¯å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @monitor_performance("get_message_page")
    @circuit_breaker()
    def get_message_page(
        self,
        customer_id: int,
        page: int = 1,
        page_size: int = 20,
        filters: Optional[Dict[str, Any]] = None,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """è·å–æ¶ˆæ¯åˆ†é¡µåˆ—è¡¨ - ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""
        
        try:
            filters = filters or {}
            
            # æ„å»ºç¼“å­˜é”®
            if use_cache:
                cache_key = MessageCacheKey.build_message_list_key(
                    customer_id, page=page, page_size=page_size, **filters
                )
                
                cached_result = self.cache_manager.get(cache_key)
                if cached_result:
                    logger.debug(f"âœ… å‘½ä¸­ç¼“å­˜: {cache_key}")
                    return cached_result
            
            # æ•°æ®åº“æŸ¥è¯¢
            with self.db_manager.get_session() as session:
                query_builder = MessageV2QueryBuilder(session)
                
                result = query_builder.get_message_page_optimized(
                    customer_id, page, page_size, filters
                )
                
                # å¹¶è¡ŒåŠ è½½æ‰©å±•æ•°æ®
                if result.get('messages'):
                    self._enrich_message_list(result['messages'])
                
                # ç¼“å­˜ç»“æœ
                if use_cache and result.get('success', True):
                    self.cache_manager.set(cache_key, result, self.config.default_cache_ttl)
                
                return {
                    'success': True,
                    'data': result
                }
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ¶ˆæ¯åˆ†é¡µå¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @monitor_performance("batch_acknowledge_messages") 
    @circuit_breaker()
    def batch_acknowledge_messages(
        self,
        message_ids: List[int],
        device_sn: str,
        user_id: int,
        customer_id: int,
        additional_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç¡®è®¤æ¶ˆæ¯ - åˆ†å¸ƒå¼äº‹åŠ¡æ”¯æŒ"""
        
        try:
            with self.db_manager.get_session() as session:
                transaction_manager = MessageV2TransactionManager(session, self.redis)
                
                success = transaction_manager.batch_acknowledge_messages_with_transaction(
                    message_ids, device_sn, user_id, customer_id
                )
                
                if success:
                    # æ¸…ç†ç›¸å…³ç¼“å­˜
                    self.cache_manager.cache_invalidator.invalidate_user_message_cache(
                        customer_id, user_id
                    )
                    
                    return {
                        'success': True,
                        'acknowledged_count': len(message_ids),
                        'message': 'æ‰¹é‡ç¡®è®¤æˆåŠŸ'
                    }
                else:
                    return {
                        'success': False,
                        'error': 'æ‰¹é‡ç¡®è®¤å¤±è´¥'
                    }
                    
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡ç¡®è®¤æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @monitor_performance("get_message_statistics")
    def get_message_statistics(
        self,
        customer_id: int,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """è·å–æ¶ˆæ¯ç»Ÿè®¡ - å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ–"""
        
        try:
            filters = filters or {}
            
            # ç¼“å­˜é”®
            cache_key = f"message_stats:{customer_id}:{start_time}:{end_time}:{hash(str(filters))}"
            cached_result = self.cache_manager.get(cache_key)
            if cached_result:
                return cached_result
            
            with self.db_manager.get_session() as session:
                # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç»Ÿè®¡æŸ¥è¯¢
                futures = {}
                
                # 1. æ€»æ•°ç»Ÿè®¡
                futures['total_count'] = self.executor.submit(
                    self._get_total_message_count, session, customer_id, start_time, end_time
                )
                
                # 2. çŠ¶æ€åˆ†å¸ƒç»Ÿè®¡
                futures['status_distribution'] = self.executor.submit(
                    self._get_status_distribution, session, customer_id, start_time, end_time
                )
                
                # 3. ç±»å‹åˆ†å¸ƒç»Ÿè®¡
                futures['type_distribution'] = self.executor.submit(
                    self._get_type_distribution, session, customer_id, start_time, end_time
                )
                
                # 4. å“åº”æ—¶é—´ç»Ÿè®¡
                futures['response_time_stats'] = self.executor.submit(
                    self._get_response_time_stats, session, customer_id, start_time, end_time
                )
                
                # æ”¶é›†ç»“æœ
                results = {}
                for key, future in futures.items():
                    try:
                        results[key] = future.result(timeout=self.config.query_timeout)
                    except Exception as e:
                        logger.warning(f"âš ï¸ ç»Ÿè®¡æŸ¥è¯¢å¤±è´¥ {key}: {e}")
                        results[key] = None
                
                # æ„å»ºæœ€ç»ˆç»“æœ
                statistics = {
                    'success': True,
                    'data': {
                        'total_messages': results.get('total_count', 0),
                        'status_distribution': results.get('status_distribution', {}),
                        'type_distribution': results.get('type_distribution', {}),
                        'response_time_stats': results.get('response_time_stats', {}),
                        'query_time_range': {
                            'start_time': start_time.isoformat() if start_time else None,
                            'end_time': end_time.isoformat() if end_time else None
                        },
                        'generated_at': datetime.now(timezone.utc).isoformat()
                    }
                }
                
                # ç¼“å­˜ç»“æœ
                self.cache_manager.set(cache_key, statistics, self.config.stats_cache_ttl)
                
                return statistics
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ¶ˆæ¯ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @monitor_performance("get_user_messages")
    def get_user_messages(
        self,
        customer_id: int,
        user_id: int,
        device_sn: Optional[str] = None,
        limit: int = 50,
        message_status: Optional[str] = None
    ) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æ¶ˆæ¯ - è®¾å¤‡ç«¯ä¸“ç”¨"""
        
        try:
            # æ„å»ºç¼“å­˜é”®
            cache_key = f"user_messages:{customer_id}:{user_id}:{device_sn}:{limit}:{message_status}"
            cached_result = self.cache_manager.get(cache_key)
            if cached_result:
                return cached_result
            
            with self.db_manager.get_session() as session:
                query_builder = MessageV2QueryBuilder(session)
                
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                filters = {
                    'user_id': user_id,
                    'device_sn': device_sn,
                    'message_status': message_status
                }
                filters = {k: v for k, v in filters.items() if v is not None}
                
                # æ‰§è¡ŒæŸ¥è¯¢
                query = query_builder.build_optimized_message_query(customer_id, filters)
                messages = query.limit(limit).all()
                
                # è½¬æ¢ç»“æœ
                result = {
                    'success': True,
                    'data': {
                        'messages': [msg.to_cache_dict() for msg in messages],
                        'count': len(messages)
                    }
                }
                
                # ç¼“å­˜ç»“æœ
                self.cache_manager.set(cache_key, result, self.config.user_cache_ttl)
                
                return result
                
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    @monitor_performance("get_user_unread_count")
    def get_user_unread_count(self, customer_id: int, user_id: int) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æœªè¯»æ¶ˆæ¯è®¡æ•° - é«˜æ€§èƒ½æŸ¥è¯¢"""
        
        try:
            # ç¼“å­˜é”®
            cache_key = MessageCacheKey.build_user_unread_count_key(customer_id, user_id)
            cached_count = self.cache_manager.get(cache_key)
            if cached_count is not None:
                return {
                    'success': True,
                    'unread_count': cached_count,
                    'from_cache': True
                }
            
            with self.db_manager.get_session() as session:
                query_builder = MessageV2QueryBuilder(session)
                count = query_builder.get_user_unread_count_optimized(customer_id, user_id)
                
                # ç¼“å­˜ç»“æœï¼ˆè¾ƒçŸ­TTLï¼Œä¿è¯åŠæ—¶æ€§ï¼‰
                self.cache_manager.set(cache_key, count, 60)  # 1åˆ†é’Ÿç¼“å­˜
                
                return {
                    'success': True,
                    'unread_count': count,
                    'from_cache': False
                }
                
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·æœªè¯»è®¡æ•°å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    # ==================== ç§æœ‰è¾…åŠ©æ–¹æ³• ====================
    
    def _enrich_message_list(self, messages: List[Dict[str, Any]]):
        """å¹¶è¡ŒåŠ è½½æ¶ˆæ¯æ‰©å±•æ•°æ® - è§£å†³N+1æŸ¥è¯¢é—®é¢˜"""
        
        if not messages:
            return
        
        try:
            # æ”¶é›†éœ€è¦æŸ¥è¯¢çš„ID
            department_ids = list(set(msg.get('department_id') for msg in messages if msg.get('department_id')))
            user_ids = list(set(msg.get('user_id') for msg in messages if msg.get('user_id')))
            
            # å¹¶è¡ŒæŸ¥è¯¢æ‰©å±•æ•°æ®
            futures = {}
            if department_ids:
                futures['departments'] = self.executor.submit(
                    self._batch_get_department_names, department_ids
                )
            if user_ids:
                futures['users'] = self.executor.submit(
                    self._batch_get_user_names, user_ids
                )
            
            # ç­‰å¾…æŸ¥è¯¢å®Œæˆ
            department_map = {}
            user_map = {}
            
            if 'departments' in futures:
                department_map = futures['departments'].result(timeout=5)
            if 'users' in futures:
                user_map = futures['users'].result(timeout=5)
            
            # å¡«å……æ‰©å±•æ•°æ®
            for msg in messages:
                if msg.get('department_id'):
                    msg['department_name'] = department_map.get(msg['department_id'], 'æœªçŸ¥éƒ¨é—¨')
                if msg.get('user_id'):
                    msg['user_name'] = user_map.get(msg['user_id'], 'æœªçŸ¥ç”¨æˆ·')
                    
        except Exception as e:
            logger.warning(f"âš ï¸ æ‰©å±•æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    def _batch_get_department_names(self, department_ids: List[int]) -> Dict[int, str]:
        """æ‰¹é‡è·å–éƒ¨é—¨åç§°"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„éƒ¨é—¨æŸ¥è¯¢é€»è¾‘
            # ç¤ºä¾‹å®ç°
            return {dept_id: f"éƒ¨é—¨_{dept_id}" for dept_id in department_ids}
        except Exception as e:
            logger.warning(f"âš ï¸ æ‰¹é‡è·å–éƒ¨é—¨åç§°å¤±è´¥: {e}")
            return {}
    
    def _batch_get_user_names(self, user_ids: List[int]) -> Dict[int, str]:
        """æ‰¹é‡è·å–ç”¨æˆ·åç§°"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„ç”¨æˆ·æŸ¥è¯¢é€»è¾‘
            # ç¤ºä¾‹å®ç°
            return {user_id: f"ç”¨æˆ·_{user_id}" for user_id in user_ids}
        except Exception as e:
            logger.warning(f"âš ï¸ æ‰¹é‡è·å–ç”¨æˆ·åç§°å¤±è´¥: {e}")
            return {}
    
    def _async_distribute_message(self, message_id: int):
        """å¼‚æ­¥åˆ†å‘æ¶ˆæ¯"""
        try:
            with self.db_manager.get_session() as session:
                # è·å–æ¶ˆæ¯è¯¦æƒ…
                details = session.query(TDeviceMessageDetailV2Fixed).filter(
                    TDeviceMessageDetailV2Fixed.message_id == message_id,
                    TDeviceMessageDetailV2Fixed.delivery_status == DeliveryStatusEnum.PENDING
                ).all()
                
                # åˆ†å‘åˆ°å„ä¸ªæ¸ é“
                for detail in details:
                    self._distribute_to_channel(detail)
                    
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥åˆ†å‘æ¶ˆæ¯å¤±è´¥: message_id={message_id}, é”™è¯¯: {e}")
    
    def _distribute_to_channel(self, detail: TDeviceMessageDetailV2Fixed):
        """åˆ†å‘åˆ°æŒ‡å®šæ¸ é“"""
        try:
            # æ„å»ºæ¶ˆæ¯è´Ÿè½½
            payload = {
                'message_id': detail.message_id,
                'distribution_id': detail.distribution_id,
                'device_sn': detail.device_sn,
                'channel': detail.channel.value if hasattr(detail.channel, 'value') else detail.channel,
                'delivery_time': datetime.now(timezone.utc).isoformat()
            }
            
            # å‘å¸ƒåˆ°Redis
            channel_name = f"message:device:{detail.device_sn}"
            self.redis.publish(channel_name, json.dumps(payload, default=str))
            
            # æ›´æ–°çŠ¶æ€
            with self.db_manager.get_session() as session:
                detail.mark_as_delivered()
                session.merge(detail)
                session.commit()
                
        except Exception as e:
            logger.error(f"âŒ æ¸ é“åˆ†å‘å¤±è´¥: distribution_id={detail.distribution_id}, é”™è¯¯: {e}")
    
    # ç»Ÿè®¡æŸ¥è¯¢è¾…åŠ©æ–¹æ³•
    def _get_total_message_count(
        self, 
        session: Session, 
        customer_id: int, 
        start_time: Optional[datetime], 
        end_time: Optional[datetime]
    ) -> int:
        """è·å–æ€»æ¶ˆæ¯æ•°é‡"""
        query = session.query(func.count(TDeviceMessageV2Fixed.id)).filter(
            and_(
                TDeviceMessageV2Fixed.customer_id == customer_id,
                TDeviceMessageV2Fixed.is_deleted == 0
            )
        )
        
        if start_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time >= start_time)
        if end_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time <= end_time)
        
        return query.scalar() or 0
    
    def _get_status_distribution(
        self, 
        session: Session, 
        customer_id: int, 
        start_time: Optional[datetime], 
        end_time: Optional[datetime]
    ) -> Dict[str, int]:
        """è·å–çŠ¶æ€åˆ†å¸ƒ"""
        query = session.query(
            TDeviceMessageV2Fixed.message_status,
            func.count(TDeviceMessageV2Fixed.id)
        ).filter(
            and_(
                TDeviceMessageV2Fixed.customer_id == customer_id,
                TDeviceMessageV2Fixed.is_deleted == 0
            )
        )
        
        if start_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time >= start_time)
        if end_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time <= end_time)
        
        results = query.group_by(TDeviceMessageV2Fixed.message_status).all()
        return {str(status): count for status, count in results}
    
    def _get_type_distribution(
        self, 
        session: Session, 
        customer_id: int, 
        start_time: Optional[datetime], 
        end_time: Optional[datetime]
    ) -> Dict[str, int]:
        """è·å–ç±»å‹åˆ†å¸ƒ"""
        query = session.query(
            TDeviceMessageV2Fixed.message_type,
            func.count(TDeviceMessageV2Fixed.id)
        ).filter(
            and_(
                TDeviceMessageV2Fixed.customer_id == customer_id,
                TDeviceMessageV2Fixed.is_deleted == 0
            )
        )
        
        if start_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time >= start_time)
        if end_time:
            query = query.filter(TDeviceMessageV2Fixed.create_time <= end_time)
        
        results = query.group_by(TDeviceMessageV2Fixed.message_type).all()
        return {str(msg_type): count for msg_type, count in results}
    
    def _get_response_time_stats(
        self, 
        session: Session, 
        customer_id: int, 
        start_time: Optional[datetime], 
        end_time: Optional[datetime]
    ) -> Dict[str, Any]:
        """è·å–å“åº”æ—¶é—´ç»Ÿè®¡"""
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„å“åº”æ—¶é—´ç»Ÿè®¡é€»è¾‘
        return {
            'avg_response_time': 0,
            'max_response_time': 0,
            'min_response_time': 0
        }
    
    # ==================== è¿ç»´å’Œç›‘æ§æ–¹æ³• ====================
    
    def get_service_health(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡å¥åº·çŠ¶æ€"""
        health_status = {
            'service': 'MessageServiceV2Fixed',
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'components': {}
        }
        
        try:
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            with self.db_manager.get_session() as session:
                session.execute(text('SELECT 1')).fetchone()
                health_status['components']['database'] = {'status': 'healthy'}
        except Exception as e:
            health_status['components']['database'] = {'status': 'unhealthy', 'error': str(e)}
            health_status['status'] = 'degraded'
        
        try:
            # æ£€æŸ¥Redisè¿æ¥
            self.redis.ping()
            health_status['components']['redis'] = {'status': 'healthy'}
        except Exception as e:
            health_status['components']['redis'] = {'status': 'unhealthy', 'error': str(e)}
            health_status['status'] = 'degraded'
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = self.cache_manager.get_cache_stats()
        health_status['components']['cache'] = {
            'status': 'healthy' if cache_stats.get('hit_rate', 0) > 50 else 'degraded',
            'hit_rate': cache_stats.get('hit_rate', 0)
        }
        
        return health_status
    
    def cleanup_expired_messages(self) -> Dict[str, Any]:
        """æ¸…ç†è¿‡æœŸæ¶ˆæ¯"""
        try:
            with self.db_manager.get_transaction_session() as session:
                # æŸ¥æ‰¾è¿‡æœŸæ¶ˆæ¯
                expired_messages = session.query(TDeviceMessageV2Fixed).filter(
                    and_(
                        TDeviceMessageV2Fixed.expired_time < datetime.now(timezone.utc),
                        TDeviceMessageV2Fixed.message_status != MessageStatusEnum.EXPIRED,
                        TDeviceMessageV2Fixed.is_deleted == 0
                    )
                ).all()
                
                # æ‰¹é‡æ›´æ–°ä¸ºè¿‡æœŸçŠ¶æ€
                updated_count = 0
                for message in expired_messages:
                    message.mark_as_expired()
                    updated_count += 1
                
                # æ¸…ç†ç›¸å…³ç¼“å­˜
                for message in expired_messages:
                    self.cache_manager.cache_invalidator.invalidate_message_caches(
                        message.id, message.customer_id, message.user_id
                    )
                
                return {
                    'success': True,
                    'expired_count': updated_count,
                    'message': f'æˆåŠŸæ¸…ç† {updated_count} æ¡è¿‡æœŸæ¶ˆæ¯'
                }
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡æœŸæ¶ˆæ¯å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def __del__(self):
        """ææ„å‡½æ•° - æ¸…ç†èµ„æº"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)


# ==================== å·¥å‚å‡½æ•° ====================

def create_message_service_v2_fixed(
    engine: Engine,
    redis_client: redis.Redis,
    config: Optional[MessageServiceConfig] = None
) -> MessageServiceV2Fixed:
    """åˆ›å»ºæ¶ˆæ¯æœåŠ¡V2ä¿®å¤åå®ä¾‹"""
    
    return MessageServiceV2Fixed(engine, redis_client, config)


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    import redis
    from sqlalchemy import create_engine
    
    # åˆ›å»ºå¼•æ“
    engine = create_engine('sqlite:///test_message_v2_fixed.db', echo=True)
    
    # åˆ›å»ºRediså®¢æˆ·ç«¯
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    
    # åˆ›å»ºæœåŠ¡å®ä¾‹
    config = MessageServiceConfig(
        batch_size=50,
        default_cache_ttl=300,
        max_concurrent_queries=20
    )
    
    service = create_message_service_v2_fixed(engine, redis_client, config)
    
    # å¥åº·æ£€æŸ¥
    health = service.get_service_health()
    print("æœåŠ¡å¥åº·çŠ¶æ€:", json.dumps(health, indent=2, ensure_ascii=False))
    
    print("âœ… MessageServiceV2Fixed æµ‹è¯•å®Œæˆ")
    print("ä¸»è¦ç‰¹æ€§:")
    print("1. ğŸ”„ åˆ†å¸ƒå¼äº‹åŠ¡æ”¯æŒ")
    print("2. ğŸ’¾ ç¼“å­˜ä¸€è‡´æ€§æœºåˆ¶")
    print("3. âš¡ é˜²æ­¢N+1æŸ¥è¯¢")
    print("4. ğŸ›¡ï¸ ç†”æ–­å™¨å’Œé™çº§")
    print("5. ğŸ“Š æ€§èƒ½ç›‘æ§é›†æˆ")
    print("6. ğŸ”§ èµ„æºç®¡ç†ä¼˜åŒ–")