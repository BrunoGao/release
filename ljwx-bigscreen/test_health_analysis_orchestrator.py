#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¥åº·åˆ†æç¼–æ’å™¨æµ‹è¯•è„šæœ¬
Health Analysis Orchestrator Test Script

å®Œæ•´æµ‹è¯•æ‰€æœ‰æ¨¡å—çš„åŠŸèƒ½æ€§ã€å¯é æ€§å’Œæ€§èƒ½
- åŸºçº¿ç”Ÿæˆæµ‹è¯•
- è¯„åˆ†è®¡ç®—æµ‹è¯•
- é¢„æµ‹åˆ†ææµ‹è¯•
- å»ºè®®ç”Ÿæˆæµ‹è¯•
- å¥åº·ç”»åƒæµ‹è¯•
- é”™è¯¯å¤„ç†æµ‹è¯•
- æ€§èƒ½æµ‹è¯•

@Author: brunoGao
@CreateTime: 2025-09-12
"""

import sys
import os
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'ljwx-bigscreen', 'bigscreen', 'bigScreen'))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('test_health_orchestrator.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class HealthOrchestratorTester:
    """å¥åº·åˆ†æç¼–æ’å™¨æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_results = {
            'baseline_test': {'status': 'pending', 'details': {}},
            'score_test': {'status': 'pending', 'details': {}},
            'prediction_test': {'status': 'pending', 'details': {}},
            'recommendation_test': {'status': 'pending', 'details': {}},
            'profile_test': {'status': 'pending', 'details': {}},
            'error_handling_test': {'status': 'pending', 'details': {}},
            'performance_test': {'status': 'pending', 'details': {}},
            'system_metrics_test': {'status': 'pending', 'details': {}}
        }
        self.orchestrator = None
        
    def setup_orchestrator(self):
        """åˆå§‹åŒ–å¥åº·åˆ†æç¼–æ’å™¨"""
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–å¥åº·åˆ†æç¼–æ’å™¨...")
            
            # å¯¼å…¥ç¼–æ’å™¨
            from health_analysis_orchestrator import HealthAnalysisOrchestrator
            
            # åˆ›å»ºå®ä¾‹
            self.orchestrator = HealthAnalysisOrchestrator()
            logger.info("âœ… å¥åº·åˆ†æç¼–æ’å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def test_baseline_generation(self) -> bool:
        """æµ‹è¯•åŸºçº¿ç”ŸæˆåŠŸèƒ½"""
        logger.info("ğŸ“Š æµ‹è¯•åŸºçº¿ç”ŸæˆåŠŸèƒ½...")
        
        try:
            test_user_id = 1001
            test_org_id = 2001
            
            # æµ‹è¯•ç”¨æˆ·åŸºçº¿ç”Ÿæˆ
            result = self.orchestrator._generate_user_baseline(test_user_id, test_org_id)
            
            if result.get('success'):
                baseline = result.get('baseline', {})
                if baseline and len(baseline) > 0:
                    self.test_results['baseline_test']['status'] = 'passed'
                    self.test_results['baseline_test']['details'] = {
                        'features_count': len(baseline),
                        'features': list(baseline.keys()),
                        'sample_feature': next(iter(baseline.values())) if baseline else None
                    }
                    logger.info(f"âœ… åŸºçº¿ç”Ÿæˆæµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆäº† {len(baseline)} ä¸ªç‰¹å¾åŸºçº¿")
                    return True
                else:
                    self.test_results['baseline_test']['status'] = 'failed'
                    self.test_results['baseline_test']['details'] = {'error': 'åŸºçº¿æ•°æ®ä¸ºç©º'}
                    logger.warning("âš ï¸ åŸºçº¿ç”Ÿæˆæµ‹è¯•å¤±è´¥: åŸºçº¿æ•°æ®ä¸ºç©º")
                    return False
            else:
                self.test_results['baseline_test']['status'] = 'failed'
                self.test_results['baseline_test']['details'] = {'error': result.get('message', 'æœªçŸ¥é”™è¯¯')}
                logger.warning(f"âš ï¸ åŸºçº¿ç”Ÿæˆæµ‹è¯•å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return False
                
        except Exception as e:
            self.test_results['baseline_test']['status'] = 'error'
            self.test_results['baseline_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ åŸºçº¿ç”Ÿæˆæµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_health_scoring(self) -> bool:
        """æµ‹è¯•å¥åº·è¯„åˆ†åŠŸèƒ½"""
        logger.info("ğŸ¯ æµ‹è¯•å¥åº·è¯„åˆ†åŠŸèƒ½...")
        
        try:
            test_user_id = 1001
            test_org_id = 2001
            
            # å…ˆç”ŸæˆåŸºçº¿
            baseline_result = self.orchestrator._generate_user_baseline(test_user_id, test_org_id)
            
            if baseline_result.get('success'):
                # æµ‹è¯•è¯„åˆ†è®¡ç®—
                score_result = self.orchestrator._generate_user_health_score(test_user_id, test_org_id, baseline_result)
                
                if score_result.get('success'):
                    overall_score = score_result.get('overall_score', 0)
                    feature_scores = score_result.get('feature_scores', {})
                    health_level = score_result.get('health_level', 'unknown')
                    
                    self.test_results['score_test']['status'] = 'passed'
                    self.test_results['score_test']['details'] = {
                        'overall_score': overall_score,
                        'health_level': health_level,
                        'feature_count': len(feature_scores),
                        'valid_score_range': 0 <= overall_score <= 100
                    }
                    logger.info(f"âœ… å¥åº·è¯„åˆ†æµ‹è¯•é€šè¿‡ï¼Œæ€»åˆ†: {overall_score}ï¼Œç­‰çº§: {health_level}")
                    return True
                else:
                    self.test_results['score_test']['status'] = 'failed'
                    self.test_results['score_test']['details'] = {'error': score_result.get('message', 'è¯„åˆ†å¤±è´¥')}
                    return False
            else:
                self.test_results['score_test']['status'] = 'skipped'
                self.test_results['score_test']['details'] = {'reason': 'åŸºçº¿ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡è¯„åˆ†æµ‹è¯•'}
                return False
                
        except Exception as e:
            self.test_results['score_test']['status'] = 'error'
            self.test_results['score_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ å¥åº·è¯„åˆ†æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_health_prediction(self) -> bool:
        """æµ‹è¯•å¥åº·é¢„æµ‹åŠŸèƒ½"""
        logger.info("ğŸ”® æµ‹è¯•å¥åº·é¢„æµ‹åŠŸèƒ½...")
        
        try:
            test_user_id = 1001
            test_org_id = 2001
            
            # å…ˆç”ŸæˆåŸºçº¿
            baseline_result = self.orchestrator._generate_user_baseline(test_user_id, test_org_id)
            
            # æµ‹è¯•é¢„æµ‹åˆ†æ
            prediction_result = self.orchestrator._generate_user_health_prediction(test_user_id, test_org_id, baseline_result)
            
            if prediction_result.get('success'):
                prediction = prediction_result.get('prediction', {})
                overall_trend = prediction.get('overall_trend', 'unknown')
                risk_level = prediction.get('risk_level', 'unknown')
                feature_predictions = prediction.get('feature_predictions', {})
                
                self.test_results['prediction_test']['status'] = 'passed'
                self.test_results['prediction_test']['details'] = {
                    'overall_trend': overall_trend,
                    'risk_level': risk_level,
                    'predictions_count': len(feature_predictions),
                    'confidence': prediction.get('confidence', 0)
                }
                logger.info(f"âœ… å¥åº·é¢„æµ‹æµ‹è¯•é€šè¿‡ï¼Œè¶‹åŠ¿: {overall_trend}ï¼Œé£é™©: {risk_level}")
                return True
            else:
                self.test_results['prediction_test']['status'] = 'failed'
                self.test_results['prediction_test']['details'] = {'error': prediction_result.get('message', 'é¢„æµ‹å¤±è´¥')}
                logger.warning(f"âš ï¸ å¥åº·é¢„æµ‹æµ‹è¯•å¤±è´¥: {prediction_result.get('message', 'é¢„æµ‹å¤±è´¥')}")
                return False
                
        except Exception as e:
            self.test_results['prediction_test']['status'] = 'error'
            self.test_results['prediction_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ å¥åº·é¢„æµ‹æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_health_recommendations(self) -> bool:
        """æµ‹è¯•å¥åº·å»ºè®®åŠŸèƒ½"""
        logger.info("ğŸ’¡ æµ‹è¯•å¥åº·å»ºè®®åŠŸèƒ½...")
        
        try:
            test_user_id = 1001
            test_org_id = 2001
            
            # ç”ŸæˆåŸºç¡€æ•°æ®
            baseline_result = self.orchestrator._generate_user_baseline(test_user_id, test_org_id)
            score_result = self.orchestrator._generate_user_health_score(test_user_id, test_org_id, baseline_result)
            prediction_result = self.orchestrator._generate_user_health_prediction(test_user_id, test_org_id, baseline_result)
            
            # æµ‹è¯•å»ºè®®ç”Ÿæˆ
            recommendation_result = self.orchestrator._generate_user_health_recommendation(test_user_id, score_result, prediction_result)
            
            if recommendation_result.get('success'):
                recommendations = recommendation_result.get('recommendations', {})
                total_count = recommendation_result.get('total_recommendations', 0)
                
                # éªŒè¯å»ºè®®åˆ†ç±»
                expected_categories = ['immediate_actions', 'lifestyle_improvements', 'monitoring_suggestions', 
                                     'medical_consultations', 'prevention_tips']
                has_all_categories = all(cat in recommendations for cat in expected_categories)
                
                self.test_results['recommendation_test']['status'] = 'passed'
                self.test_results['recommendation_test']['details'] = {
                    'total_recommendations': total_count,
                    'categories': list(recommendations.keys()),
                    'has_all_categories': has_all_categories,
                    'category_counts': {cat: len(recommendations.get(cat, [])) for cat in expected_categories}
                }
                logger.info(f"âœ… å¥åº·å»ºè®®æµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆäº† {total_count} æ¡å»ºè®®")
                return True
            else:
                self.test_results['recommendation_test']['status'] = 'failed'
                self.test_results['recommendation_test']['details'] = {'error': recommendation_result.get('error', 'å»ºè®®ç”Ÿæˆå¤±è´¥')}
                return False
                
        except Exception as e:
            self.test_results['recommendation_test']['status'] = 'error'
            self.test_results['recommendation_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ å¥åº·å»ºè®®æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_health_profile(self) -> bool:
        """æµ‹è¯•å¥åº·ç”»åƒåŠŸèƒ½"""
        logger.info("ğŸ‘¤ æµ‹è¯•å¥åº·ç”»åƒåŠŸèƒ½...")
        
        try:
            test_user_id = 1001
            test_org_id = 2001
            
            # æµ‹è¯•å¥åº·ç”»åƒç”Ÿæˆ
            profile_result = self.orchestrator._generate_user_health_profile(test_user_id, test_org_id)
            
            if profile_result.get('success'):
                profile = profile_result.get('profile', {})
                
                # éªŒè¯ç”»åƒç»´åº¦
                expected_dimensions = ['cardiovascular', 'respiratory', 'metabolic', 
                                     'physical_activity', 'sleep_quality', 'stress_level', 'overall_status']
                has_all_dimensions = all(dim in profile for dim in expected_dimensions)
                
                self.test_results['profile_test']['status'] = 'passed'
                self.test_results['profile_test']['details'] = {
                    'dimensions': list(profile.keys()),
                    'has_all_dimensions': has_all_dimensions,
                    'data_points': profile_result.get('data_points', 0),
                    'overall_health_score': profile.get('overall_status', {}).get('overall_score', 0)
                }
                logger.info(f"âœ… å¥åº·ç”»åƒæµ‹è¯•é€šè¿‡ï¼ŒåŒ…å« {len(profile)} ä¸ªç»´åº¦")
                return True
            else:
                self.test_results['profile_test']['status'] = 'failed'
                self.test_results['profile_test']['details'] = {'error': profile_result.get('message', 'ç”»åƒç”Ÿæˆå¤±è´¥')}
                logger.warning(f"âš ï¸ å¥åº·ç”»åƒæµ‹è¯•å¤±è´¥: {profile_result.get('message', 'ç”»åƒç”Ÿæˆå¤±è´¥')}")
                return False
                
        except Exception as e:
            self.test_results['profile_test']['status'] = 'error'
            self.test_results['profile_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ å¥åº·ç”»åƒæµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_error_handling(self) -> bool:
        """æµ‹è¯•é”™è¯¯å¤„ç†åŠŸèƒ½"""
        logger.info("ğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†åŠŸèƒ½...")
        
        try:
            error_scenarios_passed = 0
            total_scenarios = 4
            
            # åœºæ™¯1: æ— æ•ˆç”¨æˆ·ID
            try:
                result = self.orchestrator._generate_user_baseline(-1, 1)
                if not result.get('success'):
                    error_scenarios_passed += 1
                    logger.info("âœ… æ— æ•ˆç”¨æˆ·IDé”™è¯¯å¤„ç†æ­£å¸¸")
            except Exception:
                error_scenarios_passed += 1
                logger.info("âœ… æ— æ•ˆç”¨æˆ·IDå¼‚å¸¸å¤„ç†æ­£å¸¸")
            
            # åœºæ™¯2: ç©ºæ•°æ®å¤„ç†
            try:
                result = self.orchestrator._calculate_baseline_statistics([])
                if isinstance(result, dict):
                    error_scenarios_passed += 1
                    logger.info("âœ… ç©ºæ•°æ®å¤„ç†æ­£å¸¸")
            except Exception:
                pass
            
            # åœºæ™¯3: ç³»ç»ŸæŒ‡æ ‡è·å–
            try:
                metrics = self.orchestrator.get_system_metrics()
                if isinstance(metrics, dict) and 'performance' in metrics:
                    error_scenarios_passed += 1
                    logger.info("âœ… ç³»ç»ŸæŒ‡æ ‡è·å–æ­£å¸¸")
            except Exception:
                pass
            
            # åœºæ™¯4: å¥åº·æ£€æŸ¥
            try:
                health = self.orchestrator._check_system_health()
                if isinstance(health, dict) and 'overall_status' in health:
                    error_scenarios_passed += 1
                    logger.info("âœ… ç³»ç»Ÿå¥åº·æ£€æŸ¥æ­£å¸¸")
            except Exception:
                pass
            
            success_rate = error_scenarios_passed / total_scenarios
            
            self.test_results['error_handling_test']['status'] = 'passed' if success_rate >= 0.75 else 'partial'
            self.test_results['error_handling_test']['details'] = {
                'scenarios_passed': error_scenarios_passed,
                'total_scenarios': total_scenarios,
                'success_rate': success_rate
            }
            
            logger.info(f"âœ… é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆï¼Œé€šè¿‡ç‡: {success_rate:.2%}")
            return success_rate >= 0.75
            
        except Exception as e:
            self.test_results['error_handling_test']['status'] = 'error'
            self.test_results['error_handling_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_performance(self) -> bool:
        """æµ‹è¯•æ€§èƒ½"""
        logger.info("âš¡ æµ‹è¯•æ€§èƒ½...")
        
        try:
            performance_metrics = {}
            
            # æµ‹è¯•å•ç”¨æˆ·åˆ†ææ€§èƒ½
            start_time = time.time()
            result = self.orchestrator._analyze_user(1001, 2001)
            single_user_time = time.time() - start_time
            
            performance_metrics['single_user_analysis_time'] = single_user_time
            performance_metrics['single_user_success'] = result.get('success', False)
            
            # è·å–ç³»ç»Ÿç»Ÿè®¡
            stats = self.orchestrator.get_analysis_stats()
            performance_metrics.update(stats)
            
            # æ€§èƒ½è¯„ä¼°
            performance_good = (
                single_user_time < 30 and  # å•ç”¨æˆ·åˆ†æå°‘äº30ç§’
                stats.get('error_rate', 100) < 50  # é”™è¯¯ç‡ä½äº50%
            )
            
            self.test_results['performance_test']['status'] = 'passed' if performance_good else 'warning'
            self.test_results['performance_test']['details'] = performance_metrics
            
            logger.info(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼Œå•ç”¨æˆ·åˆ†æè€—æ—¶: {single_user_time:.2f}ç§’")
            return performance_good
            
        except Exception as e:
            self.test_results['performance_test']['status'] = 'error'
            self.test_results['performance_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def test_system_metrics(self) -> bool:
        """æµ‹è¯•ç³»ç»ŸæŒ‡æ ‡æ”¶é›†"""
        logger.info("ğŸ“Š æµ‹è¯•ç³»ç»ŸæŒ‡æ ‡æ”¶é›†...")
        
        try:
            # è·å–ç³»ç»ŸæŒ‡æ ‡
            metrics = self.orchestrator.get_system_metrics()
            
            # éªŒè¯æŒ‡æ ‡å®Œæ•´æ€§
            required_sections = ['performance', 'health', 'configuration']
            has_required_sections = all(section in metrics for section in required_sections)
            
            # éªŒè¯å¥åº·çŠ¶æ€
            health_status = metrics.get('health', {}).get('overall_status', 'unknown')
            
            self.test_results['system_metrics_test']['status'] = 'passed'
            self.test_results['system_metrics_test']['details'] = {
                'has_required_sections': has_required_sections,
                'health_status': health_status,
                'sections': list(metrics.keys()),
                'uptime_seconds': metrics.get('performance', {}).get('uptime_seconds', 0)
            }
            
            logger.info(f"âœ… ç³»ç»ŸæŒ‡æ ‡æµ‹è¯•é€šè¿‡ï¼Œå¥åº·çŠ¶æ€: {health_status}")
            return True
            
        except Exception as e:
            self.test_results['system_metrics_test']['status'] = 'error'
            self.test_results['system_metrics_test']['details'] = {'exception': str(e)}
            logger.error(f"âŒ ç³»ç»ŸæŒ‡æ ‡æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸ¬ å¼€å§‹è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶...")
        
        start_time = time.time()
        test_passed = 0
        total_tests = len(self.test_results)
        
        # åˆå§‹åŒ–ç¼–æ’å™¨
        if not self.setup_orchestrator():
            return {
                'success': False,
                'message': 'ç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥',
                'test_results': self.test_results
            }
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_functions = [
            ('baseline_test', self.test_baseline_generation),
            ('score_test', self.test_health_scoring),
            ('prediction_test', self.test_health_prediction),
            ('recommendation_test', self.test_health_recommendations),
            ('profile_test', self.test_health_profile),
            ('error_handling_test', self.test_error_handling),
            ('performance_test', self.test_performance),
            ('system_metrics_test', self.test_system_metrics)
        ]
        
        for test_name, test_function in test_functions:
            try:
                logger.info(f"ğŸ”„ è¿è¡Œæµ‹è¯•: {test_name}")
                if test_function():
                    test_passed += 1
                    logger.info(f"âœ… {test_name} é€šè¿‡")
                else:
                    logger.warning(f"âš ï¸ {test_name} å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {test_name} å¼‚å¸¸: {e}")
        
        # æ¸…ç†èµ„æº
        try:
            self.orchestrator.cleanup()
        except Exception as e:
            logger.error(f"âš ï¸ èµ„æºæ¸…ç†å¼‚å¸¸: {e}")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        total_time = time.time() - start_time
        success_rate = test_passed / total_tests
        
        test_summary = {
            'success': success_rate >= 0.75,  # 75%é€šè¿‡ç‡è§†ä¸ºæˆåŠŸ
            'summary': {
                'total_tests': total_tests,
                'passed_tests': test_passed,
                'failed_tests': total_tests - test_passed,
                'success_rate': success_rate,
                'total_time_seconds': total_time
            },
            'test_results': self.test_results,
            'timestamp': datetime.now().isoformat(),
            'recommendations': self._generate_test_recommendations()
        }
        
        logger.info(f"ğŸ æµ‹è¯•å®Œæˆ! é€šè¿‡ç‡: {success_rate:.2%} ({test_passed}/{total_tests})")
        return test_summary
    
    def _generate_test_recommendations(self) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•å»ºè®®"""
        recommendations = []
        
        # æ ¹æ®æµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
        failed_tests = [name for name, result in self.test_results.items() 
                       if result['status'] in ['failed', 'error']]
        
        if failed_tests:
            recommendations.append(f"éœ€è¦ä¿®å¤å¤±è´¥çš„æµ‹è¯•: {', '.join(failed_tests)}")
        
        if self.test_results['performance_test']['status'] in ['warning', 'failed']:
            recommendations.append("å»ºè®®ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œå…³æ³¨å†…å­˜ä½¿ç”¨å’Œå¤„ç†æ—¶é—´")
        
        if self.test_results['error_handling_test']['status'] != 'passed':
            recommendations.append("å»ºè®®åŠ å¼ºé”™è¯¯å¤„ç†æœºåˆ¶")
        
        if not recommendations:
            recommendations.append("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼å»ºè®®å®šæœŸè¿è¡Œæµ‹è¯•ä»¥ç¡®ä¿ç¨³å®šæ€§")
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨å¥åº·åˆ†æç¼–æ’å™¨æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = HealthOrchestratorTester()
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_all_tests()
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*80)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    print(f"æ•´ä½“çŠ¶æ€: {'âœ… é€šè¿‡' if results['success'] else 'âŒ å¤±è´¥'}")
    print(f"é€šè¿‡ç‡: {results['summary']['success_rate']:.2%}")
    print(f"é€šè¿‡æµ‹è¯•: {results['summary']['passed_tests']}/{results['summary']['total_tests']}")
    print(f"æ€»è€—æ—¶: {results['summary']['total_time_seconds']:.2f}ç§’")
    
    print("\nğŸ“Š è¯¦ç»†æµ‹è¯•ç»“æœ:")
    for test_name, test_result in results['test_results'].items():
        status_icon = {
            'passed': 'âœ…',
            'failed': 'âŒ', 
            'error': 'ğŸ’¥',
            'warning': 'âš ï¸',
            'partial': 'ğŸŸ¡',
            'skipped': 'â­ï¸',
            'pending': 'â³'
        }.get(test_result['status'], 'â“')
        
        print(f"  {status_icon} {test_name}: {test_result['status']}")
    
    print("\nğŸ’¡ å»ºè®®:")
    for i, recommendation in enumerate(results['recommendations'], 1):
        print(f"  {i}. {recommendation}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
    with open('test_health_orchestrator_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    logger.info("ğŸ“„ è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° test_health_orchestrator_results.json")
    print("\n" + "="*80)
    
    return results['success']

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)