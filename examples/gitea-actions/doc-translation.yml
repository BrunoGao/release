name: ğŸ“š æ–‡æ¡£ç¿»è¯‘å’Œæ‘˜è¦ç”Ÿæˆ

on:
  push:
    branches: [ main, develop ]
    paths: 
      - 'docs/**/*.md'
      - 'content/**/*.md'
      - '*.md'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/**/*.md'
      - 'content/**/*.md'

env:
  # é…ç½®ç¯å¢ƒå˜é‡
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  REGISTRY_URL: 'localhost:5001'

jobs:
  # æ£€æµ‹å˜æ›´çš„æ–‡æ¡£æ–‡ä»¶
  detect-changes:
    name: ğŸ” æ£€æµ‹æ–‡æ¡£å˜æ›´
    runs-on: ubuntu-latest
    outputs:
      docs-changed: ${{ steps.changes.outputs.docs }}
      files-changed: ${{ steps.changes.outputs.files }}
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: æ£€æµ‹å˜æ›´æ–‡ä»¶
        id: changes
        run: |
          # è·å–å˜æ›´çš„markdownæ–‡ä»¶
          CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD | grep '\.md$' || true)
          echo "å˜æ›´çš„æ–‡æ¡£æ–‡ä»¶:"
          echo "$CHANGED_FILES"
          
          if [ -n "$CHANGED_FILES" ]; then
            echo "docs=true" >> $GITHUB_OUTPUT
            echo "files<<EOF" >> $GITHUB_OUTPUT
            echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "docs=false" >> $GITHUB_OUTPUT
          fi

  # æ–‡æ¡£ç¿»è¯‘ä»»åŠ¡
  translate-docs:
    name: ğŸŒ æ–‡æ¡£ç¿»è¯‘
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.docs-changed == 'true'
    strategy:
      matrix:
        target-lang: ['en', 'ja', 'ko']  # ç›®æ ‡è¯­è¨€
    
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: å®‰è£…ç¿»è¯‘ä¾èµ–
        run: |
          pip install --upgrade pip
          pip install openai anthropic googletrans==4.0.0rc1
          pip install markdown beautifulsoup4 pyyaml
          pip install langdetect jieba

      - name: é…ç½®ç¿»è¯‘è„šæœ¬
        run: |
          # åˆ›å»ºç¿»è¯‘è„šæœ¬
          cat > translate.py << 'EOF'
          #!/usr/bin/env python3
          import os
          import sys
          import re
          from pathlib import Path
          import markdown
          from bs4 import BeautifulSoup
          from googletrans import Translator
          import time
          import json

          def translate_markdown(file_path, target_lang):
              """ç¿»è¯‘Markdownæ–‡ä»¶"""
              print(f"ğŸ”„ ç¿»è¯‘æ–‡ä»¶: {file_path} -> {target_lang}")
              
              with open(file_path, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              # è§£æå‰ç½®å…ƒæ•°æ® (Front Matter)
              front_matter = ""
              main_content = content
              
              if content.startswith('---'):
                  parts = content.split('---', 2)
                  if len(parts) >= 3:
                      front_matter = f"---{parts[1]}---\n"
                      main_content = parts[2]
              
              # ç¿»è¯‘ä¸»è¦å†…å®¹
              translator = Translator()
              
              # åˆ†æ®µç¿»è¯‘ï¼Œé¿å…APIé™åˆ¶
              paragraphs = main_content.split('\n\n')
              translated_paragraphs = []
              
              for para in paragraphs:
                  if para.strip():
                      # è·³è¿‡ä»£ç å—
                      if para.startswith('```') or para.startswith('    '):
                          translated_paragraphs.append(para)
                          continue
                      
                      try:
                          # ç¿»è¯‘æ–‡æœ¬
                          result = translator.translate(para, dest=target_lang, src='auto')
                          translated_paragraphs.append(result.text)
                          time.sleep(0.1)  # é¿å…APIé™åˆ¶
                      except Exception as e:
                          print(f"âš ï¸ ç¿»è¯‘å¤±è´¥: {e}")
                          translated_paragraphs.append(para)  # ä¿æŒåŸæ–‡
                  else:
                      translated_paragraphs.append(para)
              
              # ç»„åˆç»“æœ
              translated_content = front_matter + '\n\n'.join(translated_paragraphs)
              
              # ä¿å­˜ç¿»è¯‘ç»“æœ
              output_path = Path(file_path).parent / f"{Path(file_path).stem}.{target_lang}.md"
              with open(output_path, 'w', encoding='utf-8') as f:
                  f.write(translated_content)
              
              print(f"âœ… ç¿»è¯‘å®Œæˆ: {output_path}")
              return output_path

          def main():
              target_lang = sys.argv[1]
              changed_files = sys.argv[2].split('\n') if len(sys.argv) > 2 else []
              
              translated_files = []
              
              for file_path in changed_files:
                  if file_path.strip() and file_path.endswith('.md'):
                      try:
                          output = translate_markdown(file_path.strip(), target_lang)
                          translated_files.append(str(output))
                      except Exception as e:
                          print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
              
              # è¾“å‡ºç»“æœä¾›åç»­æ­¥éª¤ä½¿ç”¨
              with open(f'translated-files-{target_lang}.json', 'w') as f:
                  json.dump(translated_files, f)

          if __name__ == "__main__":
              main()
          EOF
          
          chmod +x translate.py

      - name: æ‰§è¡Œç¿»è¯‘
        run: |
          python translate.py ${{ matrix.target-lang }} "${{ needs.detect-changes.outputs.files-changed }}"

      - name: ä¸Šä¼ ç¿»è¯‘ç»“æœ
        uses: actions/upload-artifact@v3
        with:
          name: translated-docs-${{ matrix.target-lang }}
          path: |
            **/*.${{ matrix.target-lang }}.md
            translated-files-${{ matrix.target-lang }}.json

  # ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
  generate-summary:
    name: ğŸ“‹ ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.docs-changed == 'true'
    
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: å®‰è£…æ‘˜è¦ç”Ÿæˆä¾èµ–
        run: |
          pip install --upgrade pip
          pip install transformers torch
          pip install openai anthropic
          pip install markdown beautifulsoup4
          pip install jieba nltk

      - name: åˆ›å»ºæ‘˜è¦ç”Ÿæˆè„šæœ¬
        run: |
          cat > summarize.py << 'EOF'
          #!/usr/bin/env python3
          import os
          import sys
          import re
          from pathlib import Path
          import markdown
          from bs4 import BeautifulSoup
          import json
          from datetime import datetime

          def extract_text_from_markdown(file_path):
              """ä»Markdownæ–‡ä»¶æå–çº¯æ–‡æœ¬"""
              with open(file_path, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              # ç§»é™¤Front Matter
              if content.startswith('---'):
                  parts = content.split('---', 2)
                  if len(parts) >= 3:
                      content = parts[2]
              
              # è½¬æ¢ä¸ºHTMLå†æå–æ–‡æœ¬
              html = markdown.markdown(content)
              soup = BeautifulSoup(html, 'html.parser')
              text = soup.get_text()
              
              # æ¸…ç†æ–‡æœ¬
              text = re.sub(r'\s+', ' ', text).strip()
              return text

          def generate_simple_summary(text, max_sentences=3):
              """ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆåŸºäºå¥å­é‡è¦æ€§ï¼‰"""
              sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]+', text)
              sentences = [s.strip() for s in sentences if s.strip()]
              
              if len(sentences) <= max_sentences:
                  return '. '.join(sentences) + '.'
              
              # ç®€å•çš„é‡è¦æ€§è¯„åˆ†ï¼šå¥å­é•¿åº¦å’Œå…³é”®è¯
              keywords = ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ', 'ä¸»è¦', 'é¦–å…ˆ', 'æ€»ç»“', 'æ¦‚è¿°']
              
              scored_sentences = []
              for i, sentence in enumerate(sentences):
                  score = len(sentence)  # åŸºç¡€åˆ†æ•°ï¼šå¥å­é•¿åº¦
                  
                  # ä½ç½®åŠ åˆ†
                  if i < 3:  # å¼€å¤´å¥å­
                      score += 100
                  if i >= len(sentences) - 3:  # ç»“å°¾å¥å­
                      score += 50
                  
                  # å…³é”®è¯åŠ åˆ†
                  for keyword in keywords:
                      if keyword in sentence:
                          score += 50
                  
                  scored_sentences.append((score, sentence))
              
              # æ’åºå¹¶é€‰æ‹©å‰Nä¸ªå¥å­
              scored_sentences.sort(reverse=True)
              top_sentences = [s[1] for s in scored_sentences[:max_sentences]]
              
              return '. '.join(top_sentences) + '.'

          def create_summary_report(changed_files):
              """åˆ›å»ºæ‘˜è¦æŠ¥å‘Š"""
              report = {
                  'generated_at': datetime.now().isoformat(),
                  'total_files': len(changed_files),
                  'summaries': {}
              }
              
              for file_path in changed_files:
                  if file_path.strip() and file_path.endswith('.md'):
                      try:
                          print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}")
                          text = extract_text_from_markdown(file_path.strip())
                          
                          if len(text) > 100:  # åªå¯¹æœ‰è¶³å¤Ÿå†…å®¹çš„æ–‡ä»¶ç”Ÿæˆæ‘˜è¦
                              summary = generate_simple_summary(text)
                              report['summaries'][file_path] = {
                                  'original_length': len(text),
                                  'summary': summary,
                                  'word_count': len(text.split())
                              }
                              print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ")
                          else:
                              print(f"â­ï¸ æ–‡ä»¶å†…å®¹å¤ªçŸ­ï¼Œè·³è¿‡")
                      except Exception as e:
                          print(f"âŒ å¤„ç†å¤±è´¥: {e}")
                          report['summaries'][file_path] = {
                              'error': str(e)
                          }
              
              return report

          def main():
              changed_files = sys.argv[1].split('\n') if len(sys.argv) > 1 else []
              
              print(f"ğŸ” å¤„ç† {len(changed_files)} ä¸ªå˜æ›´æ–‡ä»¶")
              
              report = create_summary_report(changed_files)
              
              # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
              with open('summary-report.json', 'w', encoding='utf-8') as f:
                  json.dump(report, f, ensure_ascii=False, indent=2)
              
              # ç”ŸæˆMarkdownæ‘˜è¦
              with open('SUMMARY.md', 'w', encoding='utf-8') as f:
                  f.write(f"# ğŸ“‹ æ–‡æ¡£æ‘˜è¦æŠ¥å‘Š\n\n")
                  f.write(f"**ç”Ÿæˆæ—¶é—´**: {report['generated_at']}\n")
                  f.write(f"**å¤„ç†æ–‡ä»¶æ•°**: {report['total_files']}\n\n")
                  
                  for file_path, summary_data in report['summaries'].items():
                      f.write(f"## ğŸ“„ {file_path}\n\n")
                      
                      if 'error' in summary_data:
                          f.write(f"âŒ **å¤„ç†å¤±è´¥**: {summary_data['error']}\n\n")
                      else:
                          f.write(f"**å­—æ•°**: {summary_data['word_count']}\n")
                          f.write(f"**åŸæ–‡é•¿åº¦**: {summary_data['original_length']} å­—ç¬¦\n\n")
                          f.write(f"**æ‘˜è¦**: {summary_data['summary']}\n\n")
                          f.write("---\n\n")
              
              print("âœ… æ‘˜è¦æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

          if __name__ == "__main__":
              main()
          EOF
          
          chmod +x summarize.py

      - name: ç”Ÿæˆæ‘˜è¦
        run: |
          python summarize.py "${{ needs.detect-changes.outputs.files-changed }}"

      - name: ä¸Šä¼ æ‘˜è¦æŠ¥å‘Š
        uses: actions/upload-artifact@v3
        with:
          name: summary-report
          path: |
            SUMMARY.md
            summary-report.json

  # æ„å»ºæ–‡æ¡£ç½‘ç«™
  build-docs:
    name: ğŸ—ï¸ æ„å»ºæ–‡æ¡£ç½‘ç«™
    runs-on: ubuntu-latest
    needs: [translate-docs, generate-summary]
    if: always() && needs.detect-changes.outputs.docs-changed == 'true'
    
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4

      - name: ä¸‹è½½æ‰€æœ‰ç¿»è¯‘ç»“æœ
        uses: actions/download-artifact@v3
        with:
          path: ./artifacts

      - name: è®¾ç½®Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: å®‰è£…ä¾èµ–
        run: |
          # å¦‚æœé¡¹ç›®æœ‰package.json
          if [ -f "package.json" ]; then
            npm ci
          else
            # åˆ›å»ºç®€å•çš„é™æ€ç«™ç‚¹æ„å»º
            npm init -y
            npm install --save-dev @11ty/eleventy markdown-it
          fi

      - name: æ•´ç†ç¿»è¯‘æ–‡ä»¶
        run: |
          # å°†ç¿»è¯‘æ–‡ä»¶ç§»åŠ¨åˆ°æ­£ç¡®ä½ç½®
          mkdir -p docs/translations
          
          # å¤åˆ¶ç¿»è¯‘ç»“æœ
          find ./artifacts -name "*.md" -exec cp {} docs/translations/ \;
          
          # å¤åˆ¶æ‘˜è¦æŠ¥å‘Š
          if [ -f "./artifacts/summary-report/SUMMARY.md" ]; then
            cp ./artifacts/summary-report/SUMMARY.md docs/
          fi

      - name: æ„å»ºæ–‡æ¡£ç«™ç‚¹
        run: |
          # åˆ›å»ºç®€å•çš„æ„å»ºè„šæœ¬
          cat > build.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const { execSync } = require('child_process');

          // åˆ›å»ºè¾“å‡ºç›®å½•
          if (!fs.existsSync('dist')) {
            fs.mkdirSync('dist', { recursive: true });
          }

          // å¤åˆ¶æ‰€æœ‰markdownæ–‡ä»¶
          function copyMarkdownFiles(sourceDir, targetDir) {
            if (!fs.existsSync(sourceDir)) return;
            
            const files = fs.readdirSync(sourceDir, { withFileTypes: true });
            
            for (const file of files) {
              const sourcePath = path.join(sourceDir, file.name);
              const targetPath = path.join(targetDir, file.name);
              
              if (file.isDirectory()) {
                if (!fs.existsSync(targetPath)) {
                  fs.mkdirSync(targetPath, { recursive: true });
                }
                copyMarkdownFiles(sourcePath, targetPath);
              } else if (file.name.endsWith('.md')) {
                fs.copyFileSync(sourcePath, targetPath);
                console.log(`ğŸ“„ å¤åˆ¶: ${sourcePath} -> ${targetPath}`);
              }
            }
          }

          // å¤åˆ¶æ–‡æ¡£æ–‡ä»¶
          copyMarkdownFiles('docs', 'dist');
          copyMarkdownFiles('.', 'dist');

          console.log('âœ… æ–‡æ¡£ç«™ç‚¹æ„å»ºå®Œæˆ');
          EOF
          
          node build.js

      - name: æ„å»ºDockeré•œåƒ
        run: |
          # åˆ›å»ºDockerfile
          cat > Dockerfile << 'EOF'
          FROM nginx:alpine
          
          # å¤åˆ¶æ–‡æ¡£æ–‡ä»¶
          COPY dist/ /usr/share/nginx/html/
          
          # è‡ªå®šä¹‰nginxé…ç½®
          RUN echo 'server { \
              listen 80; \
              server_name localhost; \
              location / { \
                  root /usr/share/nginx/html; \
                  index index.html index.md; \
                  try_files $uri $uri/ $uri.html $uri.md =404; \
              } \
              location ~ \.md$ { \
                  add_header Content-Type text/plain; \
              } \
          }' > /etc/nginx/conf.d/default.conf
          
          EXPOSE 80
          CMD ["nginx", "-g", "daemon off;"]
          EOF
          
          # æ„å»ºé•œåƒ
          docker build -t ${{ env.REGISTRY_URL }}/lingjing-docs:latest .
          docker build -t ${{ env.REGISTRY_URL }}/lingjing-docs:${{ github.sha }} .

      - name: æ¨é€é•œåƒåˆ°ç§æœ‰ä»“åº“
        run: |
          # æ¨é€é•œåƒ
          docker push ${{ env.REGISTRY_URL }}/lingjing-docs:latest
          docker push ${{ env.REGISTRY_URL }}/lingjing-docs:${{ github.sha }}
          
          echo "âœ… é•œåƒæ¨é€å®Œæˆ:"
          echo "  - ${{ env.REGISTRY_URL }}/lingjing-docs:latest"
          echo "  - ${{ env.REGISTRY_URL }}/lingjing-docs:${{ github.sha }}"

      - name: éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
        run: |
          # åœæ­¢æ—§å®¹å™¨
          docker stop lingjing-docs || true
          docker rm lingjing-docs || true
          
          # å¯åŠ¨æ–°å®¹å™¨
          docker run -d \
            --name lingjing-docs \
            --network cicd-network \
            -p 8090:80 \
            ${{ env.REGISTRY_URL }}/lingjing-docs:latest
          
          echo "ğŸš€ æ–‡æ¡£ç½‘ç«™å·²éƒ¨ç½²åˆ°: http://localhost:8090"

  # é€šçŸ¥ä»»åŠ¡
  notify:
    name: ğŸ“¬ å‘é€é€šçŸ¥
    runs-on: ubuntu-latest
    needs: [detect-changes, translate-docs, generate-summary, build-docs]
    if: always()
    
    steps:
      - name: æ±‡æ€»ç»“æœ
        run: |
          echo "ğŸ“Š CI/CD æ‰§è¡Œç»“æœæ±‡æ€»:"
          echo ""
          echo "ğŸ” æ–‡æ¡£å˜æ›´æ£€æµ‹: ${{ needs.detect-changes.result }}"
          echo "ğŸŒ æ–‡æ¡£ç¿»è¯‘: ${{ needs.translate-docs.result }}"
          echo "ğŸ“‹ æ‘˜è¦ç”Ÿæˆ: ${{ needs.generate-summary.result }}"
          echo "ğŸ—ï¸ ç«™ç‚¹æ„å»º: ${{ needs.build-docs.result }}"
          echo ""
          
          if [ "${{ needs.build-docs.result }}" == "success" ]; then
            echo "âœ… æ–‡æ¡£ç½‘ç«™å·²æ›´æ–°: http://localhost:8090"
            echo "ğŸ“¦ Dockeré•œåƒ: localhost:5001/lingjing-docs:latest"
          fi
          
          # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å‘é€é‚®ä»¶ã€é’‰é’‰ã€å¾®ä¿¡ç­‰é€šçŸ¥é€»è¾‘ 